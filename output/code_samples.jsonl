{"source": "/Users/pedropacheco/Projects/dev/langflow.current/src/backend/base/langflow/initial_setup/starter_projects/memory_chatbot.py", "section": "file", "content": "from langflow.components.helpers.memory import MemoryComponent\nfrom langflow.components.inputs import ChatInput\nfrom langflow.components.models import OpenAIModelComponent\nfrom langflow.components.outputs import ChatOutput\nfrom langflow.components.prompts import PromptComponent\nfrom langflow.graph import Graph\n\n\ndef memory_chatbot_graph(template: str | None = None):\n    if template is None:\n        template = \"\"\"{context}\n\n    User: {user_message}\n    AI: \"\"\"\n    memory_component = MemoryComponent()\n    chat_input = ChatInput()\n    prompt_component = PromptComponent()\n    prompt_component.set(\n        template=template, user_message=chat_input.message_response, context=memory_component.retrieve_messages_as_text\n    )\n    openai_component = OpenAIModelComponent()\n    openai_component.set(input_value=prompt_component.build_prompt)\n\n    chat_output = ChatOutput()\n    chat_output.set(input_value=openai_component.text_response)\n\n    return Graph(chat_input, chat_output)\n", "metadata": {"parser": "no_parser"}, "content_type": "file", "vector": null}
{"source": "/Users/pedropacheco/Projects/dev/langflow.current/src/backend/base/langflow/initial_setup/starter_projects/basic_prompting.py", "section": "file", "content": "from langflow.components.inputs import ChatInput\nfrom langflow.components.models import OpenAIModelComponent\nfrom langflow.components.outputs import ChatOutput\nfrom langflow.components.prompts import PromptComponent\nfrom langflow.graph import Graph\n\n\ndef basic_prompting_graph(template: str | None = None):\n    if template is None:\n        template = \"\"\"Answer the user as if you were a pirate.\n\nUser: {user_input}\n\nAnswer:\n\"\"\"\n    chat_input = ChatInput()\n    prompt_component = PromptComponent()\n    prompt_component.set(\n        template=template,\n        user_input=chat_input.message_response,\n    )\n\n    openai_component = OpenAIModelComponent()\n    openai_component.set(input_value=prompt_component.build_prompt)\n\n    chat_output = ChatOutput()\n    chat_output.set(input_value=openai_component.text_response)\n\n    return Graph(start=chat_input, end=chat_output)\n", "metadata": {"parser": "no_parser"}, "content_type": "file", "vector": null}
{"source": "/Users/pedropacheco/Projects/dev/langflow.current/src/backend/base/langflow/initial_setup/starter_projects/complex_agent.py", "section": "file", "content": "from langflow.components.crewai.crewai import CrewAIAgentComponent\nfrom langflow.components.crewai.hierarchical_crew import HierarchicalCrewComponent\nfrom langflow.components.crewai.hierarchical_task import HierarchicalTaskComponent\nfrom langflow.components.inputs import ChatInput\nfrom langflow.components.models import OpenAIModelComponent\nfrom langflow.components.outputs import ChatOutput\nfrom langflow.components.prompts import PromptComponent\nfrom langflow.components.tools import SearchAPIComponent, YfinanceToolComponent\nfrom langflow.graph import Graph\n\n\ndef complex_agent_graph():\n    llm = OpenAIModelComponent(model_name=\"gpt-4o-mini\")\n    manager_llm = OpenAIModelComponent(model_name=\"gpt-4o\")\n    search_api_tool = SearchAPIComponent()\n    yahoo_search_tool = YfinanceToolComponent()\n    dynamic_agent = CrewAIAgentComponent()\n    chat_input = ChatInput()\n    role_prompt = PromptComponent(_display_name=\"Role Prompt\")\n    role_prompt.set(\n        template=\"\"\"Define a Role that could execute or answer well the user's query.\n\nUser's query: {query}\n\nRole should be two words max. Something like \"Researcher\" or \"Software Developer\".\n\"\"\"\n    )\n\n    goal_prompt = PromptComponent(_display_name=\"Goal Prompt\")\n    goal_prompt.set(\n        template=\"\"\"Define the Goal of this Role, given the User's Query.\nUser's query: {query}\n\nRole: {role}\n\nThe goal should be concise and specific.\nGoal:\n\"\"\",\n        query=chat_input.message_response,\n        role=role_prompt.build_prompt,\n    )\n    backstory_prompt = PromptComponent(_display_name=\"Backstory Prompt\")\n    backstory_prompt.set(\n        template=\"\"\"Define a Backstory of this Role and Goal, given the User's Query.\nUser's query: {query}\n\nRole: {role}\nGoal: {goal}\n\nThe backstory should be specific and well aligned with the rest of the information.\nBackstory:\"\"\",\n        query=chat_input.message_response,\n        role=role_prompt.build_prompt,\n        goal=goal_prompt.build_prompt,\n    )\n    dynamic_agent.set(\n        tools=[search_api_tool.build_tool, yahoo_search_tool.build_tool],\n        llm=llm.build_model,\n        role=role_prompt.build_prompt,\n        goal=goal_prompt.build_prompt,\n        backstory=backstory_prompt.build_prompt,\n    )\n\n    response_prompt = PromptComponent()\n    response_prompt.set(\n        template=\"\"\"User's query:\n{query}\n\nRespond to the user with as much as information as you can about the topic. Delete if needed.\nIf it is just a general query (e.g a greeting) you can respond them directly.\"\"\",\n        query=chat_input.message_response,\n    )\n    manager_agent = CrewAIAgentComponent()\n    manager_agent.set(\n        llm=manager_llm.build_model,\n        role=\"Manager\",\n        goal=\"You can answer general questions from the User and may call others for help if needed.\",\n        backstory=\"You are polite and helpful. You've always been a beacon of politeness.\",\n    )\n    task = HierarchicalTaskComponent()\n    task.set(\n        task_description=response_prompt.build_prompt,\n        expected_output=\"Succinct response that answers the User's query.\",\n    )\n    crew_component = HierarchicalCrewComponent()\n    crew_component.set(\n        tasks=task.build_task, agents=[dynamic_agent.build_output], manager_agent=manager_agent.build_output\n    )\n    chat_output = ChatOutput()\n    chat_output.set(input_value=crew_component.build_output)\n\n    return Graph(\n        start=chat_input,\n        end=chat_output,\n        flow_name=\"Sequential Tasks Agent\",\n        description=\"This Agent runs tasks in a predefined sequence.\",\n    )\n", "metadata": {"parser": "no_parser"}, "content_type": "file", "vector": null}
{"source": "/Users/pedropacheco/Projects/dev/langflow.current/src/backend/base/langflow/initial_setup/starter_projects/document_qa.py", "section": "file", "content": "from langflow.components.data import FileComponent\nfrom langflow.components.inputs import ChatInput\nfrom langflow.components.models import OpenAIModelComponent\nfrom langflow.components.outputs import ChatOutput\nfrom langflow.components.processing import ParseDataComponent\nfrom langflow.components.prompts import PromptComponent\nfrom langflow.graph import Graph\n\n\ndef document_qa_graph(template: str | None = None):\n    if template is None:\n        template = \"\"\"Answer user's questions based on the document below:\n\n---\n\n{Document}\n\n---\n\nQuestion:\n{Question}\n\nAnswer:\n\"\"\"\n    file_component = FileComponent()\n    parse_data_component = ParseDataComponent()\n    parse_data_component.set(data=file_component.load_files)\n\n    chat_input = ChatInput()\n    prompt_component = PromptComponent()\n    prompt_component.set(\n        template=template,\n        context=parse_data_component.parse_data,\n        question=chat_input.message_response,\n    )\n\n    openai_component = OpenAIModelComponent()\n    openai_component.set(input_value=prompt_component.build_prompt)\n\n    chat_output = ChatOutput()\n    chat_output.set(input_value=openai_component.text_response)\n\n    return Graph(start=chat_input, end=chat_output)\n", "metadata": {"parser": "no_parser"}, "content_type": "file", "vector": null}
{"source": "/Users/pedropacheco/Projects/dev/langflow.current/src/backend/base/langflow/initial_setup/starter_projects/sequential_tasks_agent.py", "section": "file", "content": "from langflow.components.crewai.sequential_crew import SequentialCrewComponent\nfrom langflow.components.crewai.sequential_task_agent import SequentialTaskAgentComponent\nfrom langflow.components.inputs import TextInputComponent\nfrom langflow.components.models import OpenAIModelComponent\nfrom langflow.components.outputs import ChatOutput\nfrom langflow.components.prompts import PromptComponent\nfrom langflow.components.tools import SearchAPIComponent\nfrom langflow.graph import Graph\n\n\ndef sequential_tasks_agent_graph():\n    llm = OpenAIModelComponent()\n    search_api_tool = SearchAPIComponent()\n\n    text_input = TextInputComponent(_display_name=\"Topic\")\n    text_input.set(input_value=\"Agile\")\n\n    # Document Prompt for Researcher\n    document_prompt_component = PromptComponent()\n    document_prompt_component.set(\n        template=\"\"\"Topic: {topic}\n\nBuild a document about this topic.\"\"\",\n        topic=text_input.text_response,\n    )\n\n    # Researcher Task Agent\n    researcher_task_agent = SequentialTaskAgentComponent()\n    researcher_task_agent.set(\n        role=\"Researcher\",\n        goal=\"Search Google to find information to complete the task.\",\n        backstory=\"Research has always been your thing. You can quickly find things on the web because of your skills.\",\n        tools=[search_api_tool.build_tool],\n        llm=llm.build_model,\n        task_description=document_prompt_component.build_prompt,\n        expected_output=\"Bullet points and small phrases about the research topic.\",\n    )\n\n    # Revision Prompt for Editor\n    revision_prompt_component = PromptComponent()\n    revision_prompt_component.set(\n        template=\"\"\"Topic: {topic}\n\nRevise this document.\"\"\",\n        topic=text_input.text_response,\n    )\n\n    # Editor Task Agent\n    editor_task_agent = SequentialTaskAgentComponent()\n    editor_task_agent.set(\n        role=\"Editor\",\n        goal=\"You should edit the information provided by the Researcher to make it more palatable and to not contain \"\n        \"misleading information.\",\n        backstory=\"You are the editor of the most reputable journal in the world.\",\n        llm=llm.build_model,\n        task_description=revision_prompt_component.build_prompt,\n        expected_output=\"Small paragraphs and bullet points with the corrected content.\",\n        previous_task=researcher_task_agent.build_agent_and_task,\n    )\n\n    # Blog Prompt for Comedian\n    blog_prompt_component = PromptComponent()\n    blog_prompt_component.set(\n        template=\"\"\"Topic: {topic}\n\nBuild a fun blog post about this topic.\"\"\",\n        topic=text_input.text_response,\n    )\n\n    # Comedian Task Agent\n    comedian_task_agent = SequentialTaskAgentComponent()\n    comedian_task_agent.set(\n        role=\"Comedian\",\n        goal=\"You write comedic content based on the information provided by the editor.\",\n        backstory=\"Your formal occupation is Comedian-in-Chief. \"\n        \"You write jokes, do standup comedy, and write funny articles.\",\n        llm=llm.build_model,\n        task_description=blog_prompt_component.build_prompt,\n        expected_output=\"A small blog about the topic.\",\n        previous_task=editor_task_agent.build_agent_and_task,\n    )\n\n    crew_component = SequentialCrewComponent()\n    crew_component.set(\n        tasks=comedian_task_agent.build_agent_and_task,\n    )\n\n    # Set up the output component\n    chat_output = ChatOutput()\n    chat_output.set(input_value=crew_component.build_output)\n\n    # Create the graph\n    return Graph(\n        start=text_input,\n        end=chat_output,\n        flow_name=\"Sequential Tasks Agent\",\n        description=\"This Agent runs tasks in a predefined sequence.\",\n    )\n", "metadata": {"parser": "no_parser"}, "content_type": "file", "vector": null}
{"source": "/Users/pedropacheco/Projects/dev/langflow.current/src/backend/base/langflow/initial_setup/starter_projects/__init__.py", "section": "file", "content": "from .basic_prompting import basic_prompting_graph\nfrom .blog_writer import blog_writer_graph\nfrom .complex_agent import complex_agent_graph\nfrom .document_qa import document_qa_graph\nfrom .hierarchical_tasks_agent import hierarchical_tasks_agent_graph\nfrom .memory_chatbot import memory_chatbot_graph\nfrom .sequential_tasks_agent import sequential_tasks_agent_graph\nfrom .vector_store_rag import vector_store_rag_graph\n\n__all__ = [\n    \"basic_prompting_graph\",\n    \"blog_writer_graph\",\n    \"complex_agent_graph\",\n    \"document_qa_graph\",\n    \"hierarchical_tasks_agent_graph\",\n    \"memory_chatbot_graph\",\n    \"sequential_tasks_agent_graph\",\n    \"vector_store_rag_graph\",\n]\n", "metadata": {"parser": "no_parser"}, "content_type": "file", "vector": null}
{"source": "/Users/pedropacheco/Projects/dev/langflow.current/src/backend/base/langflow/initial_setup/starter_projects/hierarchical_tasks_agent.py", "section": "file", "content": "from langflow.components.crewai.crewai import CrewAIAgentComponent\nfrom langflow.components.crewai.hierarchical_crew import HierarchicalCrewComponent\nfrom langflow.components.crewai.hierarchical_task import HierarchicalTaskComponent\nfrom langflow.components.inputs import ChatInput\nfrom langflow.components.models import OpenAIModelComponent\nfrom langflow.components.outputs import ChatOutput\nfrom langflow.components.prompts import PromptComponent\nfrom langflow.components.tools import SearchAPIComponent\nfrom langflow.graph import Graph\n\n\ndef hierarchical_tasks_agent_graph():\n    llm = OpenAIModelComponent(model_name=\"gpt-4o-mini\")\n    manager_llm = OpenAIModelComponent(model_name=\"gpt-4o\")\n    search_api_tool = SearchAPIComponent()\n    researcher_agent = CrewAIAgentComponent()\n    chat_input = ChatInput()\n    researcher_agent.set(\n        tools=[search_api_tool.build_tool],\n        llm=llm.build_model,\n        role=\"Researcher\",\n        goal=\"Search for information about the User's query and answer as best as you can\",\n        backstory=\"You are a reliable researcher and journalist \",\n    )\n\n    editor_agent = CrewAIAgentComponent()\n\n    editor_agent.set(\n        llm=llm.build_model,\n        role=\"Editor\",\n        goal=\"Evaluate the information for misleading or biased data.\",\n        backstory=\"You are a reliable researcher and journalist \",\n    )\n\n    response_prompt = PromptComponent()\n    response_prompt.set(\n        template=\"\"\"User's query:\n{query}\n\nRespond to the user with as much as information as you can about the topic. Delete if needed.\nIf it is just a general query (e.g a greeting) you can respond them directly.\"\"\",\n        query=chat_input.message_response,\n    )\n    manager_agent = CrewAIAgentComponent()\n    manager_agent.set(\n        llm=manager_llm.build_model,\n        role=\"Manager\",\n        goal=\"You can answer general questions from the User and may call others for help if needed.\",\n        backstory=\"You are polite and helpful. You've always been a beacon of politeness.\",\n    )\n    task = HierarchicalTaskComponent()\n    task.set(\n        task_description=response_prompt.build_prompt,\n        expected_output=\"Succinct response that answers the User's query.\",\n    )\n    crew_component = HierarchicalCrewComponent()\n    crew_component.set(\n        tasks=task.build_task,\n        agents=[researcher_agent.build_output, editor_agent.build_output],\n        manager_agent=manager_agent.build_output,\n    )\n    chat_output = ChatOutput()\n    chat_output.set(input_value=crew_component.build_output)\n\n    return Graph(\n        start=chat_input,\n        end=chat_output,\n        flow_name=\"Sequential Tasks Agent\",\n        description=\"This Agent runs tasks in a predefined sequence.\",\n    )\n", "metadata": {"parser": "no_parser"}, "content_type": "file", "vector": null}
{"source": "/Users/pedropacheco/Projects/dev/langflow.current/src/backend/base/langflow/initial_setup/starter_projects/blog_writer.py", "section": "file", "content": "from textwrap import dedent\n\nfrom langflow.components.data import URLComponent\nfrom langflow.components.inputs import TextInputComponent\nfrom langflow.components.models import OpenAIModelComponent\nfrom langflow.components.outputs import ChatOutput\nfrom langflow.components.processing import ParseDataComponent\nfrom langflow.components.prompts import PromptComponent\nfrom langflow.graph import Graph\n\n\ndef blog_writer_graph(template: str | None = None):\n    if template is None:\n        template = dedent(\"\"\"Reference 1:\n\n{references}\n\n---\n\n{instructions}\n\nBlog:\n\"\"\")\n    url_component = URLComponent()\n    url_component.set(urls=[\"https://langflow.org/\", \"https://docs.langflow.org/\"])\n    parse_data_component = ParseDataComponent()\n    parse_data_component.set(data=url_component.fetch_content)\n\n    text_input = TextInputComponent(_display_name=\"Instructions\")\n    text_input.set(\n        input_value=\"Use the references above for style to write a new blog/tutorial about Langflow and AI. \"\n        \"Suggest non-covered topics.\"\n    )\n\n    prompt_component = PromptComponent()\n    prompt_component.set(\n        template=template,\n        instructions=text_input.text_response,\n        references=parse_data_component.parse_data,\n    )\n\n    openai_component = OpenAIModelComponent()\n    openai_component.set(input_value=prompt_component.build_prompt)\n\n    chat_output = ChatOutput()\n    chat_output.set(input_value=openai_component.text_response)\n\n    return Graph(start=text_input, end=chat_output)\n", "metadata": {"parser": "no_parser"}, "content_type": "file", "vector": null}
{"source": "/Users/pedropacheco/Projects/dev/langflow.current/src/backend/base/langflow/initial_setup/starter_projects/vector_store_rag.py", "section": "file", "content": "from textwrap import dedent\n\nfrom langflow.components.data import FileComponent\nfrom langflow.components.embeddings import OpenAIEmbeddingsComponent\nfrom langflow.components.inputs import ChatInput\nfrom langflow.components.models import OpenAIModelComponent\nfrom langflow.components.outputs import ChatOutput\nfrom langflow.components.processing import ParseDataComponent\nfrom langflow.components.processing.split_text import SplitTextComponent\nfrom langflow.components.prompts import PromptComponent\nfrom langflow.components.vectorstores import AstraDBVectorStoreComponent\nfrom langflow.graph import Graph\n\n\ndef ingestion_graph():\n    # Ingestion Graph\n    file_component = FileComponent()\n    text_splitter = SplitTextComponent()\n    text_splitter.set(data_inputs=file_component.load_files)\n    openai_embeddings = OpenAIEmbeddingsComponent()\n    vector_store = AstraDBVectorStoreComponent()\n    vector_store.set(\n        embedding_model=openai_embeddings.build_embeddings,\n        ingest_data=text_splitter.split_text,\n    )\n\n    return Graph(file_component, vector_store)\n\n\ndef rag_graph():\n    # RAG Graph\n    openai_embeddings = OpenAIEmbeddingsComponent()\n    chat_input = ChatInput()\n    rag_vector_store = AstraDBVectorStoreComponent()\n    rag_vector_store.set(\n        search_query=chat_input.message_response,\n        embedding_model=openai_embeddings.build_embeddings,\n    )\n\n    parse_data = ParseDataComponent()\n    parse_data.set(data=rag_vector_store.search_documents)\n    prompt_component = PromptComponent()\n    prompt_component.set(\n        template=dedent(\"\"\"Given the following context, answer the question.\n                         Context:{context}\n\n                         Question: {question}\n                         Answer:\"\"\"),\n        context=parse_data.parse_data,\n        question=chat_input.message_response,\n    )\n\n    openai_component = OpenAIModelComponent()\n    openai_component.set(input_value=prompt_component.build_prompt)\n\n    chat_output = ChatOutput()\n    chat_output.set(input_value=openai_component.text_response)\n\n    return Graph(start=chat_input, end=chat_output)\n\n\ndef vector_store_rag_graph():\n    return ingestion_graph() + rag_graph()\n", "metadata": {"parser": "no_parser"}, "content_type": "file", "vector": null}
