{'title: Create custom Python components\nslug: /components-custom-components': 'Custom components extend Langflow\'s functionality through Python classes that inherit from `Component`. This enables integration of new features, data manipulation, external services, and specialized tools.\nIn Langflow\'s node-based environment, each node is a "component" that performs discrete functions. Custom components are Python classes which define:\n**Inputs** — Data or parameters your component requires.\n**Outputs** — Data your component provides to downstream nodes.\n**Logic** — How you process inputs to produce outputs.\nThe benefits of creating custom components include unlimited extensibility, reusability, automatic UI field generation based on inputs, and type-safe connections between nodes.\nCreate custom components for performing specialized tasks, calling APIs, or adding advanced logic.\nCustom components in Langflow are built upon:\nThe Python class that inherits from `Component`.\nClass-level attributes that identify and describe the component.\nInput and output lists that determine data flow.\nInternal variables for logging and advanced logic.', 'Class-level attributes': "Define these attributes to control a custom component's appearance and behavior:\n**display_name**: A user-friendly label in the node header.\n**description**: A brief summary shown in tooltips.\n**icon**: A visual identifier from Langflow's icon library.\n**name**: A unique internal identifier.\n**documentation**: An optional link to external docs.", 'Structure of a custom component': 'A **Langflow custom component** goes beyond a simple class with inputs and outputs. It includes an internal structure with optional lifecycle steps, output generation, front-end interaction, and logic organization.\nA basic component:\nInherits from `langflow.custom.Component`.\nDeclares metadata like `display_name`, `description`, `icon`, and more.\nDefines `inputs` and `outputs` lists.\nImplements methods matching output specifications.\nA minimal custom component skeleton contains the following:', 'Internal Lifecycle and Execution Flow': "Langflow's engine manages:\n**Instantiation**:  A component is created and internal structures are initialized.\n**Assigning Inputs**: Values from the UI or connections are assigned to component fields.\n**Validation and Setup**: Optional hooks like `_pre_run_setup`.\n**Outputs Generation**: `run()` or `build_results()` triggers output methods.\n**Optional Hooks**:\n`initialize_data` or `_pre_run_setup` can run setup logic before the component's main execution.\n`__call__`, `run()`, or `_run()` can be overridden to customize how the component is called or to define custom execution logic.", 'Inputs and outputs': 'Custom component inputs are defined with properties like:\n`name`, `display_name`\nOptional: `info`, `value`, `advanced`, `is_list`, `tool_mode`, `real_time_refresh`\nFor example:\n`StrInput`: simple text input.\n`DropdownInput`: selectable options.\n`HandleInput`: specialized connections.\nCustom component `Output` properties define:\n`name`, `display_name`, `method`\nOptional: `info`\nFor more information, see [Custom component inputs and outputs](/components-custom-components#custom-component-inputs-and-outputs).', 'Associated Methods': 'Each output is linked to a method:\nThe output method name must match the method name.\nThe method typically returns objects like Message, Data, or DataFrame.\nThe method can use inputs with `self.<input_name>`.\nFor example:', 'Components with multiple outputs': 'A component can define multiple outputs.\nEach output can have a different corresponding method.\nFor example:', 'Common internal patterns': '', '`_pre_run_setup()`': 'To initialize a custom component with counters set:', 'Override `run` or `_run`': 'You can override `async def _run(self): ...` to define custom execution logic, although the default behavior from the base class usually covers most cases.', 'Store data in `self.ctx`': "Use `self.ctx` as a shared storage for data or counters across the component's execution flow:", 'Directory structure requirements': "By default, Langflow looks for custom components in the `langflow/components` directory.\nIf you're creating custom components in a different location using the [LANGFLOW_COMPONENTS_PATH](/environment-variables#LANGFLOW_COMPONENTS_PATH) environment variable, components must be organized in a specific directory structure to be properly loaded and displayed in the UI:\nComponents must be placed inside **category folders**, not directly in the base directory.\nThe category folder name determines where the component appears in the UI menu.\nFor example, to add a component to the **Helpers** menu, place it in a `helpers` subfolder:\nYou can have **multiple category folders** to organize components into different menus:\nThis folder structure is required for Langflow to properly discover and load your custom components. Components placed directly in the base directory will not be loaded.", 'Custom component inputs and outputs': 'Inputs and outputs define how data flows through the component, how it appears in the UI, and how connections to other components are validated.', 'Inputs': 'Inputs are defined in a class-level `inputs` list. When Langflow loads the component, it uses this list to render fields and handles in the UI. Users or other components provide values or connections to fill these inputs.\nAn input is usually an instance of a class from `langflow.io` (such as `StrInput`, `DataInput`, or `MessageTextInput`). The most common constructor parameters are:\n**`name`**: The internal variable name, accessed via `self.<name>`.\n**`display_name`**: The label shown to users in the UI.\n**`info`** *(optional)*: A tooltip or short description.\n**`value`** *(optional)*: The default value.\n**`advanced`** *(optional)*: If `True`, moves the field into the "Advanced" section.\n**`required`** *(optional)*: If `True`, forces the user to provide a value.\n**`is_list`** *(optional)*: If `True`, allows multiple values.\n**`input_types`** *(optional)*: Restricts allowed connection types (e.g., `["Data"]`, `["LanguageModel"]`).\nHere are the most commonly used input classes and their typical usage.\n**Text Inputs**: For simple text entries.\n**`StrInput`** creates a single-line text field.\n**`MultilineInput`** creates a multi-line text area.\n**Numeric and Boolean Inputs**: Ensures users can only enter valid numeric or boolean data.\n**`BoolInput`**, **`IntInput`**, and **`FloatInput`** provide fields for boolean, integer, and float values, ensuring type consistency.\n**Dropdowns**: For selecting from predefined options, useful for modes or levels.\n**`DropdownInput`**\n**Secrets**: A specialized input for sensitive data, ensuring input is hidden in the UI.\n**`SecretStrInput`** for API keys and passwords.\n**Specialized Data Inputs**: Ensures type-checking and color-coded connections in the UI.\n**`DataInput`** expects a `Data` object (typically with `.data` and optional `.text`).\n**`MessageInput`** expects a `Message` object, used in chat or agent-based flows.\n**`MessageTextInput`** simplifies access to the `.text` field of a `Message`.\n**Handle-Based Inputs**: Used to connect outputs of specific types, ensuring correct pipeline connections.\n**`HandleInput`**\n**File Uploads**: Allows users to upload files directly through the UI or receive file paths from other components.\n**`FileInput`**\n**Lists**: Set `is_list=True` to accept multiple values, ideal for batch or grouped operations.\nThis example defines three inputs: a text field (`StrInput`), a boolean toggle (`BoolInput`), and a dropdown selection (`DropdownInput`).', 'Outputs': 'Outputs are defined in a class-level `outputs` list. When Langflow renders a component, each output becomes a connector point in the UI. When you connect something to an output, Langflow automatically calls the corresponding method and passes the returned object to the next component.\nAn output is usually an instance of `Output` from `langflow.io`, with common parameters:\n**`name`**: The internal variable name.\n**`display_name`**: The label shown in the UI.\n**`method`**: The name of the method called to produce the output.\n**`info`** *(optional)*: Help text shown on hover.\nThe method must exist in the class, and it is recommended to annotate its return type for better type checking.\nYou can also set a `self.status` message inside the method to show progress or logs.\n**Common Return Types**:\n**`Message`**: Structured chat messages.\n**`Data`**: Flexible object with `.data` and optional `.text`.\n**`DataFrame`**: Pandas-based tables (`langflow.schema.DataFrame`).\n**Primitive types**: `str`, `int`, `bool` (not recommended if you need type/color consistency).\nIn this example, the `DataToDataFrame` component defines its output using the outputs list. The `df_out` output is linked to the `build_df` method, so when connected in the UI, Langflow calls this method and passes its returned DataFrame to the next node. This demonstrates how each output maps to a method that generates the actual output data.', 'Tool mode': "You can configure a Custom Component to work as a **Tool** by setting the parameter `tool_mode=True`. This allows the component to be used in Langflow's Tool Mode workflows, such as by Agent components.\nLangflow currently supports the following input types for Tool Mode:\n`DataInput`\n`DataFrameInput`\n`PromptInput`\n`MessageTextInput`\n`MultilineInput`\n`DropdownInput`", 'Typed annotations': 'In Langflow, **typed annotations** allow Langflow to visually guide users and maintain flow consistency.\nTyped annotations provide:\n**Color-coding**: Outputs like `-> Data` or `-> Message` get distinct colors.\n**Validation**: Langflow blocks incompatible connections automatically.\n**Readability**: Developers can quickly understand data flow.\n**Development tools**: Better code suggestions and error checking in your code editor.', 'Common Return Types': '**`Message`**\nFor chat-style outputs.\nIn the UI, connects only to Message-compatible inputs.\n**`Data`**\nFor structured data like dicts or partial texts.\nIn the UI, connects only with DataInput.\n**`DataFrame`**\nFor tabular data\nIn the UI, connects only to DataFrameInput.\n**Primitive Types (`str`, `int`, `bool`)**\nReturning primitives is allowed but wrapping in Data or Message is recommended for better UI consistency.', 'Tips for typed annotations': 'When using typed annotations, consider the following best practices:\n**Always Annotate Outputs**: Specify return types like `-> Data`, `-> Message`, or `-> DataFrame` to enable proper UI color-coding and validation.\n**Wrap Raw Data**: Use `Data`, `Message`, or `DataFrame` wrappers instead of returning plain structures.\n**Use Primitives Carefully**: Direct `str` or `int` returns are fine for simple flows, but wrapping improves flexibility.\n**Annotate Helpers Too**: Even if internal, typing improves maintainability and clarity.\n**Handle Edge Cases**: Prefer returning structured `Data` with error fields when needed.\n**Stay Consistent**: Use the same types across your components to make flows predictable and easier to build.', 'Enable dynamic fields': "In **Langflow**, dynamic fields allow inputs to change or appear based on user interactions. You can make an input dynamic by setting `dynamic=True`.\nOptionally, setting `real_time_refresh=True` triggers the `update_build_config` method to adjust the input's visibility or properties in real time, creating a contextual UI that only displays relevant fields based on the user's choices.\nIn this example, the operator field triggers updates via `real_time_refresh=True`.\nThe `regex_pattern` field is initially hidden and controlled via `dynamic=True`.", 'Implement `update_build_config`': "When a field with `real_time_refresh=True` is modified, Langflow calls the `update_build_config` method, passing the updated field name, value, and the component's configuration to dynamically adjust the visibility or properties of other fields based on user input.\nThis example will show or hide the `regex_pattern` field when the user selects a different operator.", 'Additional Dynamic Field Controls': 'You can also modify other properties within `update_build_config`, such as:\n`required`: Set `build_config["some_field"]["required"] = True/False`\n`advanced`: Set `build_config["some_field"]["advanced"] = True`\n`options`: Modify dynamic dropdown options.', 'Tips for Managing Dynamic Fields': 'When working with dynamic fields, consider the following best practices to ensure a smooth user experience:\n**Minimize field changes**: Hide only fields that are truly irrelevant to avoid confusing users.\n**Test behavior**: Ensure that adding or removing fields doesn\'t accidentally erase user input.\n**Preserve data**: Use `build_config["some_field"]["show"] = False` to hide fields without losing their values.\n**Clarify logic**: Add `info` notes to explain why fields appear or disappear based on conditions.\n**Keep it manageable**: If the dynamic logic becomes too complex, consider breaking it into smaller components, unless it serves a clear purpose in a single node.', 'Error handling and logging': 'In Langflow, robust error handling ensures that your components behave predictably, even when unexpected situations occur, such as invalid inputs, external API failures, or internal logic errors.', 'Error handling techniques': '**Raise Exceptions**:\nIf a critical error occurs, you can raise standard Python exceptions such as `ValueError`, or specialized exceptions like `ToolException`. Langflow will automatically catch these and display appropriate error messages in the UI, helping users quickly identify what went wrong.\n**Return Structured Error Data**:\nInstead of stopping a flow abruptly, you can return a Data object containing an "error" field. This approach allows the flow to continue operating and enables downstream components to detect and handle the error gracefully.', 'Improve debugging and flow management': '**Use `self.status`**:\nEach component has a status field where you can store short messages about the execution result—such as success summaries, partial progress, or error notifications. These appear directly in the UI, making troubleshooting easier for users.\n**Stop specific outputs with `self.stop(...)`**:\nYou can halt individual output paths when certain conditions fail, without affecting the entire component. This is especially useful when working with components that have multiple output branches.\n**Log events**:\nYou can log key execution details inside components. Logs are displayed in the "Logs" or "Events" section of the component\'s detail view and can be accessed later through the flow\'s debug panel or exported files, providing a clear trace of the component\'s behavior for easier debugging.', 'Tips for error handling and logging': 'To build more reliable components, consider the following best practices:\n**Validate inputs early**: Catch missing or invalid inputs at the start to prevent broken logic.\n**Summarize with `self.status`**: Use short success or error summaries to help users understand results quickly.\n**Keep logs concise**: Focus on meaningful messages to avoid cluttering the UI.\n**Return structured errors**: When appropriate, return `Data(data={"error": ...})` instead of raising exceptions to allow downstream handling.\n**Stop outputs selectively**: Only halt specific outputs with `self.stop(...)` if necessary, to preserve correct flow behavior elsewhere.', 'Contribute custom components to Langflow': 'See [How to Contribute](/contributing-components) to contribute your custom component to Langflow.'}
{'title: Bundles\nslug: /components-bundle-components': "**Bundles** are third-party components grouped by provider.\nFor more information on bundled components, see the component provider's documentation."}
{'title: Inputs and outputs\nslug: /components-io': 'import Icon from "@site/src/components/icon";', 'Input and output components in Langflow': 'Input and output components define where data enters and exits your flow.\nBoth components accept user input and return a `Message` object, but serve different purposes.\nThe **Text Input** component accepts a text string input and returns a `Message` object containing only the input text. The output does not appear in the **Playground**.\nThe **Chat Input** component accepts multiple input types including text, files, and metadata, and returns a `Message` object containing the text along with sender information, session ID, and file attachments.\nThe **Chat Input** component provides an interactive chat interface in the **Playground**.', 'Chat Input': 'This component collects user input as `Text` strings from the chat and wraps it in a [Message](/concepts-objects#message-object) object that includes the input text, sender information, session ID, file attachments, and styling properties.\nIt can optionally store the message in a chat history.\n**Inputs**\nName\nDisplay Name\nInfo\ninput_value\nText\nThe Message to be passed as input.\nshould_store_message\nStore Messages\nStore the message in the history.\nsender\nSender Type\nThe type of sender.\nsender_name\nSender Name\nThe name of the sender.\nsession_id\nSession ID\nThe session ID of the chat. If empty, the current session ID parameter is used.\nfiles\nFiles\nThe files to be sent with the message.\nbackground_color\nBackground Color\nThe background color of the icon.\nchat_icon\nIcon\nThe icon of the message.\ntext_color\nText Color\nThe text color of the name.\n**Outputs**\nName\nDisplay Name\nInfo\nmessage\nMessage\nThe resulting chat message object with all specified properties.', 'Message method': 'The `ChatInput` class provides an asynchronous method to create and store a `Message` object based on the input parameters.\nThe `Message` object is created in the `message_response` method of the ChatInput class using the `Message.create()` factory method.', 'Text Input': 'The **Text Input** component accepts a text string input and returns a `Message` object containing only the input text.\nThe output does not appear in the **Playground**.\n**Inputs**\nName\nDisplay Name\nInfo\ninput_value\nText\nThe text/content to be passed as output.\n**Outputs**\nName\nDisplay Name\nInfo\ntext\nText\nThe resulting text message.', 'Chat Output': "The **Chat Output** component creates a [Message](/concepts-objects#message-object) object that includes the input text, sender information, session ID, and styling properties.\nThe component accepts the following input types.\n[Data](/concepts-objects#data-object)\n[DataFrame](/concepts-objects#dataframe-object)\n[Message](/concepts-objects#message-object)\n**Inputs**\nName\nDisplay Name\nInfo\ninput_value\nText\nThe message to be passed as output.\nshould_store_message\nStore Messages\nThe flag to store the message in the history.\nsender\nSender Type\nThe type of sender.\nsender_name\nSender Name\nThe name of the sender.\nsession_id\nSession ID\nThe session ID of the chat. If empty, the current session ID parameter is used.\ndata_template\nData Template\nThe template to convert Data to Text. If the option is left empty, it is dynamically set to the Data's text key.\nbackground_color\nBackground Color\nThe background color of the icon.\nchat_icon\nIcon\nThe icon of the message.\ntext_color\nText Color\nThe text color of the name.\nclean_data\nBasic Clean Data\nWhen enabled, `DataFrame` inputs are cleaned when converted to text. Cleaning removes empty rows, empty lines in cells, and multiple newlines.\n**Outputs**\nName\nDisplay Name\nInfo\nmessage\nMessage\nThe resulting chat message object with all specified properties.", 'Text Output': 'The **Text Output** takes a single input of text and returns a [Message](/concepts-objects#message-object) object containing that text.\nThe output does not appear in the **Playground**.\n**Inputs**\nName\nDisplay Name\nInfo\ninput_value\nText\nThe text to be passed as output.\n**Outputs**\nName\nDisplay Name\nInfo\ntext\nText\nThe resulting text message.', 'Chat components example flow': 'To use the **Chat Input** and **Chat Output** components in a flow, connect them to components that accept or send the [Message](/concepts-objects#message-object) type.\nFor this example, connect a **Chat Input** component to an **OpenAI** model component\'s **Input** port, and then connect the **OpenAI** model component\'s **Message** port to the **Chat Output** component.\nIn the **OpenAI** model component, in the **OpenAI API Key** field, add your **OpenAI API key**.\nThe flow looks like this:\n![Chat input and output components connected to an OpenAI model](/img/component-chat-io.png)\nTo send a message to your flow, open the **Playground**, and then enter a message.\nThe **OpenAI** model component responds.\nOptionally, in the **OpenAI** model component, enter a **System Message** to control the model\'s response.\nIn the Langflow UI, click your flow name, and then click **Logs**.\nThe **Logs** pane opens.\nHere, you can inspect your component logs.\n![Logs pane](/img/logs.png)\nYour first message was sent by the **Chat Input** component to the **OpenAI** model component.\nClick **Outputs** to view the sent message:\nYour second message was sent by the **OpenAI** model component to the **Chat Output** component.\nThis is the raw text output of the model\'s response.\nThe **Chat Output** component accepts this text as input and presents it as a formatted message.\nClick **Outputs** to view the sent message:\n:::tip\nOptionally, to view the outputs of each component in the flow, click <Icon name="TextSearch" aria-label="Inspect icon" />.\n:::', 'Send chat messages with the API': "The **Chat Input** component is often the entry point for passing messages to the Langflow API.\nTo send the same example messages programmatically to your Langflow server, do the following:\nTo get your Langflow endpoint, click **Publish**, and then click **API access**.\nCopy the command from the **cURL** tab, and then paste it in your terminal.\nIt looks similar to this:\nModify `input_value` so it contains the question, `What's the recommended way to install Docker on Mac M1?`.\nNote the `output_type` and `input_type` parameters that are passed with the message. The `chat` type provides additional configuration options, and the messages appear in the **Playground**. The `text` type returns only text strings, and does not appear in the **Playground**.\nAdd a custom `session_id` to the message's `data` object.\nThe custom `session_id` value starts a new chat session between your client and the Langflow server, and can be useful in keeping conversations and AI context separate.\nSend the POST request.\nYour request is answered.\nNavigate to the **Playground**.\nA new chat session called `docker-question-on-m1` has appeared, using your unique `session_id`.\nTo modify additional parameters with **Tweaks** for your **Chat Input** and **Chat Output** components, click **Publish**, and then click **API access**.\nClick **Tweaks** to modify parameters in the component's `data` object.\nFor example, disabling storing messages from the **Chat Input** component adds a **Tweak** to your command:\nTo confirm your command is using the tweak, navigate to the **Logs** pane and view the request from the **Chat Input** component.\nThe value for `should_store_message` is `false`."}
{'title: Processing\nslug: /components-processing': 'import Icon from "@site/src/components/icon";\nProcessing components process and transform data within a flow.', 'Use a processing component in a flow': 'The **Split Text** processing component in this flow splits the incoming [Data](/concepts-objects) into chunks to be embedded into the vector store component.\nThe component offers control over chunk size, overlap, and separator, which affect context and granularity in vector store retrieval results.\n![](/img/vector-store-document-ingestion.png)', 'Combine data': ":::important\nPrior to Langflow version 1.1.3, this component was named **Merge Data**.\n:::\nThis component combines multiple data sources into a single unified [Data](/concepts-objects#data-object) object.\nThe component iterates through the input list of data objects, merging them into a single data object. If the input list is empty, it returns an empty data object. If there's only one input data object, it returns that object unchanged. The merging process uses the addition operator to combine data objects.\n**Inputs**\nName\nDisplay Name\nInfo\ndata\nData\nA list of data objects to be merged.\n**Outputs**\nName\nDisplay Name\nInfo\nmerged_data\nMerged Data\nA single [Data](/concepts-objects#data-object) object containing the combined information from all input data objects.", 'DataFrame operations': 'This component performs operations on [DataFrame](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html) rows and columns.\nTo use this component in a flow, connect a component that outputs [DataFrame](/concepts-objects#dataframe-object) to the **DataFrame Operations** component.\nThis example fetches JSON data from an API. The **Lambda filter** component extracts and flattens the results into a tabular DataFrame. The **DataFrame Operations** component can then work with the retrieved data.\n![Dataframe operations with flattened dataframe](/img/component-dataframe-operations.png)\nThe **API Request** component retrieves data with only `source` and `result` fields.\nFor this example, the desired data is nested within the `result` field.\nConnect a **Lambda Filter** to the API request component, and a **Language model** to the **Lambda Filter**. This example connects a **Groq** model component.\nIn the **Groq** model component, add your **Groq** API key.\nTo filter the data, in the **Lambda filter** component, in the **Instructions** field, use natural language to describe how the data should be filtered.\nFor this example, enter:\n:::tip\nAvoid punctuation in the **Instructions** field, as it can cause errors.\n:::\n5. To run the flow, in the **Lambda Filter** component, click <Icon name="Play" aria-label="Play icon" />.\n6. To inspect the filtered data, in the **Lambda Filter** component, click <Icon name="TextSearch" aria-label="Inspect icon" />.\nThe result is a structured DataFrame.\nAdd the **DataFrame Operations** component, and a **Chat Output** component to the flow.\nIn the **DataFrame Operations** component, in the **Operation** field, select **Filter**.\nTo apply a filter, in the **Column Name** field, enter a column to filter on. This example filters by `name`.\nClick **Playground**, and then click **Run Flow**.\nThe flow extracts the values from the `name` column.', 'Operations': 'This component can perform the following operations on Pandas [DataFrame](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html).\nOperation\nDescription\nRequired Inputs\nAdd Column\nAdds a new column with a constant value\nnew_column_name, new_column_value\nDrop Column\nRemoves a specified column\ncolumn_name\nFilter\nFilters rows based on column value\ncolumn_name, filter_value\nHead\nReturns first n rows\nnum_rows\nRename Column\nRenames an existing column\ncolumn_name, new_column_name\nReplace Value\nReplaces values in a column\ncolumn_name, replace_value, replacement_value\nSelect Columns\nSelects specific columns\ncolumns_to_select\nSort\nSorts DataFrame by column\ncolumn_name, ascending\nTail\nReturns last n rows\nnum_rows\n**Inputs**\nName\nDisplay Name\nInfo\ndf\nDataFrame\nThe input DataFrame to operate on.\noperation\nOperation\nThe DataFrame operation to perform. Options include Add Column, Drop Column, Filter, Head, Rename Column, Replace Value, Select Columns, Sort, and Tail.\ncolumn_name\nColumn Name\nThe column name to use for the operation.\nfilter_value\nFilter Value\nThe value to filter rows by.\nascending\nSort Ascending\nWhether to sort in ascending order.\nnew_column_name\nNew Column Name\nThe new column name when renaming or adding a column.\nnew_column_value\nNew Column Value\nThe value to populate the new column with.\ncolumns_to_select\nColumns to Select\nA list of column names to select.\nnum_rows\nNumber of Rows\nThe number of rows to return for head/tail operations. The default is 5.\nreplace_value\nValue to Replace\nThe value to replace in the column.\nreplacement_value\nReplacement Value\nThe value to replace with.\n**Outputs**\nName\nDisplay Name\nInfo\noutput\nDataFrame\nThe resulting DataFrame after the operation.', 'Data to DataFrame': "This component converts one or multiple [Data](/concepts-objects#data-object) objects into a [DataFrame](/concepts-objects#dataframe-object). Each Data object corresponds to one row in the resulting DataFrame. Fields from the `.data` attribute become columns, and the `.text` field (if present) is placed in a 'text' column.\nTo use this component in a flow, connect a component that outputs [Data](/concepts-objects#data-object) to the **Data to Dataframe** component's input.\nThis example connects a **Webhook** component to convert `text` and `data` into a DataFrame.\nTo view the flow's output, connect a **Chat Output** component to the **Data to Dataframe** component.\n![A webhook and data to dataframe](/img/component-data-to-dataframe.png)\nSend a POST request to the **Webhook** containing your JSON data.\nReplace `YOUR_FLOW_ID` with your flow ID.\nThis example uses the default Langflow server address.\nIn the **Playground**, view the output of your flow.\nThe **Data to DataFrame** component converts the webhook request into a `DataFrame`, with `text` and `data` fields as columns.\nSend another employee data object.\nIn the **Playground**, this request is also converted to `DataFrame`.\n**Inputs**\nName\nDisplay Name\nInfo\ndata_list\nData or Data List\nOne or multiple Data objects to transform into a DataFrame.\n**Outputs**\nName\nDisplay Name\nInfo\ndataframe\nDataFrame\nA DataFrame built from each Data object's fields plus a text column.", 'Filter data': ':::important\nThis component is in **Beta** as of Langflow version 1.1.3, and is not yet fully supported.\n:::\nThis component filters a [Data](/concepts-objects#data-object) object based on a list of keys.\n**Inputs**\nName\nDisplay Name\nInfo\ndata\nData\nThe Data object to filter.\nfilter_criteria\nFilter Criteria\nA list of keys to filter by.\n**Outputs**\nName\nDisplay Name\nInfo\nfiltered_data\nFiltered Data\nA new Data object containing only the key-value pairs that match the filter criteria.', 'Filter values': ':::important\nThis component is in **Beta** as of Langflow version 1.1.3, and is not yet fully supported.\n:::\nThe Filter values component filters a list of data items based on a specified key, filter value, and comparison operator.\n**Inputs**\nName\nDisplay Name\nInfo\ninput_data\nInput data\nThe list of data items to filter.\nfilter_key\nFilter Key\nThe key to filter on.\nfilter_value\nFilter Value\nThe value to filter by.\noperator\nComparison Operator\nThe operator to apply for comparing the values.\n**Outputs**\nName\nDisplay Name\nInfo\nfiltered_data\nFiltered data\nThe resulting list of filtered data items.', 'Lambda filter': 'This component uses an LLM to generate a Lambda function for filtering or transforming structured data.\nTo use the **Lambda filter** component, you must connect it to a [Language Model](/components-models#language-model) component, which the component uses to generate a function based on the natural language instructions in the **Instructions** field.\nThis example gets JSON data from the `https://jsonplaceholder.typicode.com/users` API endpoint.\nThe **Instructions** field in the **Lambda filter** component specifies the task `extract emails`.\nThe connected LLM creates a filter based on the instructions, and successfully extracts a list of email addresses from the JSON data.\n![](/img/component-lambda-filter.png)\n**Inputs**\nName\nDisplay Name\nInfo\ndata\nData\nThe structured data to filter or transform using a Lambda function.\nllm\nLanguage Model\nThe connection port for a [Model](/components-models) component.\nfilter_instruction\nInstructions\nThe natural language instructions for how to filter or transform the data using a Lambda function, such as `Filter the data to only include items where the \'status\' is \'active\'`.\nsample_size\nSample Size\nFor large datasets, the number of characters to sample from the dataset head and tail.\nmax_size\nMax Size\nThe number of characters for the data to be considered "large", which triggers sampling by the `sample_size` value.\n**Outputs**\nName\nDisplay Name\nInfo\nfiltered_data\nFiltered Data\nThe filtered or transformed [Data object](/concepts-objects#data-object).\ndataframe\nDataFrame\nThe filtered data as a [DataFrame](/concepts-objects#dataframe-object).', 'LLM router': 'This component routes requests to the most appropriate LLM based on OpenRouter model specifications.\n**Inputs**\nName\nDisplay Name\nInfo\nmodels\nLanguage Models\nA list of LLMs to route between.\ninput_value\nInput\nThe input message to be routed.\njudge_llm\nJudge LLM\nThe LLM that evaluates and selects the most appropriate model.\noptimization\nOptimization\nThe optimization preference between quality, speed, cost, or balanced.\n**Outputs**\nName\nDisplay Name\nInfo\noutput\nOutput\nThe response from the selected model.\nselected_model\nSelected Model\nThe name of the chosen model.', 'Message to data': 'This component converts [Message](/concepts-objects#message-object) objects to [Data](/concepts-objects#data-object) objects.\n**Inputs**\nName\nDisplay Name\nInfo\nmessage\nMessage\nThe Message object to convert to a Data object.\n**Outputs**\nName\nDisplay Name\nInfo\ndata\nData\nThe converted Data object.', 'Parser': 'This component formats `DataFrame` or `Data` objects into text using templates, with an option to convert inputs directly to strings using `stringify`.\nTo use this component, create variables for values in the `template` the same way you would in a [Prompt](/components-prompts) component. For `DataFrames`, use column names, for example `Name: {Name}`. For `Data` objects, use `{text}`.\nTo use the **Parser** component with a **Structured Output** component, do the following:\nConnect a **Structured Output** component\'s **DataFrame** output to the **Parser** component\'s **DataFrame** input.\nConnect the **File** component to the **Structured Output** component\'s **Message** input.\nConnect the **OpenAI** model component\'s **Language Model** output to the **Structured Output** component\'s **Language Model** input.\nThe flow looks like this:\n![A parser component connected to OpenAI and structured output](/img/component-parser.png)\nIn the **Structured Output** component, click **Open Table**.\nThis opens a pane for structuring your table.\nThe table contains the rows **Name**, **Description**, **Type**, and **Multiple**.\nCreate a table that maps to the data you\'re loading from the **File** loader.\nFor example, to create a table for employees, you might have the rows `id`, `name`, and `email`, all of type `string`.\nIn the **Template** field of the **Parser** component, enter a template for parsing the **Structured Output** component\'s DataFrame output into structured text.\nCreate variables for values in the `template` the same way you would in a [Prompt](/components-prompts) component.\nFor example, to present a table of employees in Markdown:\nTo run the flow, in the **Parser** component, click <Icon name="Play" aria-label="Play icon" />.\nTo view your parsed text, in the **Parser** component, click <Icon name="TextSearch" aria-label="Inspect icon" />.\nOptionally, connect a **Chat Output** component, and open the **Playground** to see the output.\nFor an additional example of using the **Parser** component to format a DataFrame from a **Structured Output** component, see the **Market Research** template flow.\n**Inputs**\nName\nDisplay Name\nInfo\nmode\nMode\nThe tab selection between "Parser" and "Stringify" modes. "Stringify" converts input to a string instead of using a template.\npattern\nTemplate\nThe template for formatting using variables in curly brackets. For DataFrames, use column names, such as `Name: {Name}`. For Data objects, use `{text}`.\ninput_data\nData or DataFrame\nThe input to parse. Accepts either a DataFrame or Data object.\nsep\nSeparator\nThe string used to separate rows or items. The default is a newline.\nclean_data\nClean Data\nWhen stringify is enabled, this option cleans data by removing empty rows and lines.\n**Outputs**\nName\nDisplay Name\nInfo\nparsed_text\nParsed Text\nThe resulting formatted text as a [Message](/concepts-objects#message-object) object.', 'Regex extractor': 'This component extracts patterns from text using regular expressions. It can be used to find and extract specific patterns or information from text data.\nTo use this component in a flow:\nConnect the **Regex Extractor** to a **URL** component and a **Chat Output** component.\n![Regex extractor connected to url component](/img/component-url-regex.png)\nIn the **Regex Extractor** tool, enter a pattern to extract text from the **URL** component\'s raw output.\nThis example extracts the first paragraph from the "In the News" section of `https://en.wikipedia.org/wiki/Main_Page`:\nResult:', 'Save to File': "This component saves [DataFrames, Data, or Messages](/concepts-objects) to various file formats.\nTo use this component in a flow, connect a component that outputs [DataFrames, Data, or Messages](/concepts-objects) to the **Save to File** component's input.\nThe following example connects a **Webhook** component to two **Save to File** components to demonstrate the different outputs.\n![Two Save-to File components connected to a webhook](/img/component-save-to-file.png)\nIn the **Save to File** component's **Input Type** field, select the expected input type.\nThis example expects **Data** from the **Webhook**.\nIn the **File Format** field, select the file type for your saved file.\nThis example uses `.md` in one **Save to File** component, and `.xlsx` in another.\nIn the **File Path** field, enter the path for your saved file.\nThis example uses `./output/employees.xlsx` and `./output/employees.md` to save the files in a directory relative to where Langflow is running.\nThe component accepts both relative and absolute paths, and creates any necessary directories if they don't exist.\n:::tip\nIf you enter a format in the `file_path` that is not accepted, the component appends the proper format to the file.\nFor example, if the selected `file_format` is `csv`, and you enter `file_path` as `./output/test.txt`, the file is saved as `./output/test.txt.csv` so the file is not corrupted.\n:::\nSend a POST request to the **Webhook** containing your JSON data.\nReplace `YOUR_FLOW_ID` with your flow ID.\nThis example uses the default Langflow server address.\nIn your local filesystem, open the `outputs` directory.\nYou should see two files created from the data you've sent: one in `.xlsx` for structured spreadsheets, and one in Markdown.", 'File input format options': 'For `DataFrame` and `Data` inputs, the component can create:\n`csv`\n`excel`\n`json`\n`markdown`\n`pdf`\nFor `Message` inputs, the component can create:\n`txt`\n`json`\n`markdown`\n`pdf`\n**Inputs**\nName\nDisplay Name\nInfo\ninput_text\nInput Text\nThe text to analyze and extract patterns from.\npattern\nRegex Pattern\nThe regular expression pattern to match in the text.\ninput_type\nInput Type\nThe type of input to save.\ndf\nDataFrame\nThe DataFrame to save.\ndata\nData\nThe Data object to save.\nmessage\nMessage\nThe Message to save.\nfile_format\nFile Format\nThe file format to save the input in.\nfile_path\nFile Path\nThe full file path including filename and extension.\n**Outputs**\nName\nDisplay Name\nInfo\ndata\nData\nA list of extracted matches as Data objects.\ntext\nMessage\nThe extracted matches formatted as a Message object.\nconfirmation\nConfirmation\nThe confirmation message after saving the file.', 'Split text': "This component splits text into chunks based on specified criteria. It's ideal for chunking data to be tokenized and embedded into vector databases.\nThe **Split Text** component outputs **Chunks** or **DataFrame**.\nThe **Chunks** output returns a list of individual text chunks.\nThe **DataFrame** output returns a structured data format, with additional `text` and `metadata` columns applied.\nTo use this component in a flow, connect a component that outputs [Data or DataFrame](/concepts-objects) to the **Split Text** component's **Data** port.\nThis example uses the **URL** component, which is fetching JSON placeholder data.\n![Split text component and chroma-db](/img/component-split-text.png)\nIn the **Split Text** component, define your data splitting parameters.\nThis example splits incoming JSON data at the separator `},`, so each chunk contains one JSON object.\nThe order of precedence is **Separator**, then **Chunk Size**, and then **Chunk Overlap**.\nIf any segment after separator splitting is longer than `chunk_size`, it is split again to fit within `chunk_size`.\nAfter `chunk_size`, **Chunk Overlap** is applied between chunks to maintain context.\nConnect a **Chat Output** component to the **Split Text** component's **DataFrame** output to view its output.\nClick **Playground**, and then click **Run Flow**.\nThe output contains a table of JSON objects split at `},`.\nClear the **Separator** field, and then run the flow again.\nInstead of JSON objects, the output contains 50-character lines of text with 10 characters of overlap.\n**Inputs**\nName\nDisplay Name\nInfo\ndata_inputs\nInput Documents\nThe data to split. The component accepts [Data](/concepts-objects#data-object) or [DataFrame](/concepts-objects#dataframe-object) objects.\nchunk_overlap\nChunk Overlap\nThe number of characters to overlap between chunks. Default: `200`.\nchunk_size\nChunk Size\nThe maximum number of characters in each chunk. Default: `1000`.\nseparator\nSeparator\nThe character to split on. Default: `newline`.\ntext_key\nText Key\nThe key to use for the text column. Default: `text`.\n**Outputs**\nName\nDisplay Name\nInfo\nchunks\nChunks\nA list of split text chunks as [Data](/concepts-objects#data-object) objects.\ndataframe\nDataFrame\nA list of split text chunks as [DataFrame](/concepts-objects#dataframe-object) objects.", 'Update data': 'This component dynamically updates or appends data with specified fields.\n**Inputs**\nName\nDisplay Name\nInfo\nold_data\nData\nThe records to update.\nnumber_of_fields\nNumber of Fields\nThe number of fields to add. The maximum is 15.\ntext_key\nText Key\nThe key for text content.\ntext_key_validator\nText Key Validator\nValidates the text key presence.\n**Outputs**\nName\nDisplay Name\nInfo\ndata\nData\nThe updated Data objects.', 'Legacy components': '**Legacy** components are available for use but are no longer supported.', 'Alter metadata': "This component modifies metadata of input objects. It can add new metadata, update existing metadata, and remove specified metadata fields. The component works with both [Message](/concepts-objects#message-object) and [Data](/concepts-objects#data-object) objects, and can also create a new Data object from user-provided text.\n**Inputs**\nName\nDisplay Name\nInfo\ninput_value\nInput\nObjects to which Metadata should be added\ntext_in\nUser Text\nText input; the value is contained in the 'text' attribute of the [Data](/concepts-objects#data-object) object. Empty text entries are ignored.\nmetadata\nMetadata\nMetadata to add to each object\nremove_fields\nFields to Remove\nMetadata fields to remove\n**Outputs**\nName\nDisplay Name\nInfo\ndata\nData\nList of Input objects, each with added metadata", 'Combine text': ":::important\nThis component is in **Legacy**, which means it is no longer in active development.\nInstead, use the [Combine data](#combine-data) component.\n:::\nThis component concatenates two text sources into a single text chunk using a specified delimiter.\nTo use this component in a flow, connect two components that output [Messages](/concepts-objects#message-object) to the **Combine Text** component's **First Text** and **Second Text** inputs.\nThis example uses two **Text Input** components.\n![Combine text component](/img/component-combine-text.png)\nIn the **Combine Text** component, in the **Text** fields of both **Text Input** components, enter some text to combine.\nIn the **Combine Text** component, enter an optional **Delimiter** value.\nThe delimiter character separates the combined texts.\nThis example uses `\\n\\n **end first text** \\n\\n **start second text** \\n\\n` to label the texts and create newlines between them.\nConnect a **Chat Output** component to view the text combination.\nClick **Playground**, and then click **Run Flow**.\nThe combined text appears in the **Playground**.\n**Inputs**\nName\nDisplay Name\nInfo\nfirst_text\nFirst Text\nThe first text input to concatenate.\nsecond_text\nSecond Text\nThe second text input to concatenate.\ndelimiter\nDelimiter\nA string used to separate the two text inputs. The default is a space.\n**Outputs**\nName\nDisplay Name\nInfo\nmessage\nMessage\nA Message object containing the combined text.", 'Create data': ':::important\nThis component is in **Legacy**, which means it is no longer in active development as of Langflow version 1.1.3.\n:::\nThis component dynamically creates a [Data](/concepts-objects#data-object) object with a specified number of fields.\n**Inputs**\nName\nDisplay Name\nInfo\nnumber_of_fields\nNumber of Fields\nThe number of fields to be added to the record.\ntext_key\nText Key\nKey that identifies the field to be used as the text content.\ntext_key_validator\nText Key Validator\nIf enabled, checks if the given `Text Key` is present in the given `Data`.\n**Outputs**\nName\nDisplay Name\nInfo\ndata\nData\nA [Data](/concepts-objects#data-object) object created with the specified fields and text key.', 'JSON cleaner': 'The JSON cleaner component cleans JSON strings to ensure they are fully compliant with the JSON specification.\n**Inputs**\nName\nDisplay Name\nInfo\njson_str\nJSON String\nThe JSON string to be cleaned. This can be a raw, potentially malformed JSON string produced by language models or other sources that may not fully comply with JSON specifications.\nremove_control_chars\nRemove Control Characters\nIf set to True, this option removes control characters (ASCII characters 0-31 and 127) from the JSON string. This can help eliminate invisible characters that might cause parsing issues or make the JSON invalid.\nnormalize_unicode\nNormalize Unicode\nWhen enabled, this option normalizes Unicode characters in the JSON string to their canonical composition form (NFC). This ensures consistent representation of Unicode characters across different systems and prevents potential issues with character encoding.\nvalidate_json\nValidate JSON\nIf set to True, this option attempts to parse the JSON string to ensure it is well-formed before applying the final repair operation. It raises a ValueError if the JSON is invalid, allowing for early detection of major structural issues in the JSON.\n**Outputs**\nName\nDisplay Name\nInfo\noutput\nCleaned JSON String\nThe resulting cleaned, repaired, and validated JSON string that fully complies with the JSON specification.', 'Parse DataFrame': ':::important\nThis component is in **Legacy**, which means it is no longer in active development as of Langflow version 1.3.\nInstead, use the [Parser](#parser) component.\n:::\nThis component converts DataFrames into plain text using templates.\n**Inputs**\nName\nDisplay Name\nInfo\ndf\nDataFrame\nThe DataFrame to convert to text rows.\ntemplate\nTemplate\nTemplate for formatting (use `{column_name}` placeholders).\nsep\nSeparator\nString to join rows in output.\n**Outputs**\nName\nDisplay Name\nInfo\ntext\nText\nAll rows combined into single text.', 'Parse JSON': ':::important\nThis component is in **Legacy**, which means it is no longer in active development as of Langflow version 1.1.3.\n:::\nThis component converts and extracts JSON fields using JQ queries.\n**Inputs**\nName\nDisplay Name\nInfo\ninput_value\nInput\nData object to filter ([Message](/concepts-objects#message-object) or [Data](/concepts-objects#data-object)).\nquery\nJQ Query\nJQ Query to filter the data\n**Outputs**\nName\nDisplay Name\nInfo\nfiltered_data\nFiltered Data\nFiltered data as list of [Data](/concepts-objects#data-object) objects.', 'Select data': ':::important\nThis component is in **Legacy**, which means it is no longer in active development as of Langflow version 1.1.3.\n:::\nThis component selects a single [Data](/concepts-objects#data-object) item from a list.\n**Inputs**\nName\nDisplay Name\nInfo\ndata_list\nData List\nList of data to select from\ndata_index\nData Index\nIndex of the data to select\n**Outputs**\nName\nDisplay Name\nInfo\nselected_data\nSelected Data\nThe selected [Data](/concepts-objects#data-object) object.'}
{'title: Prompts\nslug: /components-prompts': '', 'Prompt components in Langflow': 'A prompt is a structured input to a language model that instructs the model how to handle user inputs and variables.\nPrompt components create prompt templates with custom fields and dynamic variables for providing your model structured, repeatable prompts.\nPrompts are a combination of natural language and variables created with curly braces.', 'Use a prompt component in a flow': 'An example of modifying a prompt can be found in the [Quickstart](/get-started-quickstart#run-the-chatbot-with-retrieved-context), where a basic chatbot flow is extended to include a full vector RAG pipeline.\n![](/img/quickstart-add-document-ingestion.png)\nThe default prompt in the **Prompt** component is `Answer the user as if you were a GenAI expert, enthusiastic about helping them get started building something fresh.`\nThis prompt creates a "personality" for your LLM\'s chat interactions, but it doesn\'t include variables that you may find useful when templating prompts.\nTo modify the prompt template, in the **Prompt** component, click the **Template** field. For example, the `{context}` variable gives the LLM model access to embedded vector data to return better answers.\nWhen variables are added to a prompt template, new fields are automatically created in the component. These fields can be connected to receive text input from other components to automate prompting, or to output instructions to other components. An example of prompts controlling agents behavior is available in the [sequential tasks agent starter flow](/sequential-agent).\n**Inputs**\nName\nDisplay Name\nInfo\ntemplate\nTemplate\nCreate a prompt template with dynamic variables.\n**Outputs**\nName\nDisplay Name\nInfo\nprompt\nPrompt Message\nThe built prompt message returned by the `build_prompt` method.', 'Langchain Hub Prompt Template': ':::important\nThis component is available in the **Components** menu under **Bundles**.\n:::\nThis component fetches prompts from the [Langchain Hub](https://docs.smith.langchain.com/old/category/prompt-hub).\nWhen a prompt is loaded, the component generates input fields for custom variables. For example, the default prompt "efriis/my-first-prompt" generates fields for `profession` and `question`.\n**Inputs**\nName\nDisplay Name\nInfo\nlangchain_api_key\nYour LangChain API Key\nThe LangChain API Key to use.\nlangchain_hub_prompt\nLangChain Hub Prompt\nThe LangChain Hub prompt to use.\n**Outputs**\nName\nDisplay Name\nInfo\nprompt\nBuild Prompt\nThe built prompt message returned by the `build_prompt` method.'}
{'title: Memories\nslug: /components-memories': '', 'Memory components in Langflow': 'Memory components store and retrieve chat messages by `session_id`.\nThey are distinct from vector store components, because they are built specifically for storing and retrieving chat messages from external databases.\nMemory components provide access to their respective external databases **as memory**. This allows Large Language Models (LLMs) or [agents](/components-agents) to access external memory for persistence and context retention.', 'Use a memory component in a flow': 'This example flow stores and retrieves chat history from an **Astra DB Chat Memory** component with **Store Message** and **Message history** components.\nThe **Store Message** helper component stores chat memories as [Data](/concepts-objects) objects, and the **Message History** helper component retrieves chat messages as [Data](/concepts-objects) objects or strings.\n![Sample Flow storing Message history in AstraDB](/img/astra_db_chat_memory_rounded.png)', 'AstraDBChatMemory Component': 'This component creates an `AstraDBChatMessageHistory` instance, which stores and retrieves chat messages using Astra DB, a cloud-native database service.\n**Inputs**\nName\nType\nDescription\ncollection_name\nString\nThe name of the Astra DB collection for storing messages. Required.\ntoken\nSecretString\nThe authentication token for Astra DB access. Required.\napi_endpoint\nSecretString\nThe API endpoint URL for the Astra DB service. Required.\nnamespace\nString\nThe optional namespace within Astra DB for the collection.\nsession_id\nMessageText\nThe chat session ID. Uses the current session ID if not provided.\n**Outputs**\nName\nType\nDescription\nmessage_history\nBaseChatMessageHistory\nAn instance of AstraDBChatMessageHistory for the session.', 'CassandraChatMemory Component': 'This component creates a `CassandraChatMessageHistory` instance, enabling storage and retrieval of chat messages using Apache Cassandra or DataStax Astra DB.\n**Inputs**\nName\nType\nDescription\ndatabase_ref\nMessageText\nThe contact points for the Cassandra database or Astra DB database ID. Required.\nusername\nMessageText\nThe username for Cassandra. Leave empty for Astra DB.\ntoken\nSecretString\nThe password for Cassandra or the token for Astra DB. Required.\nkeyspace\nMessageText\nThe keyspace in Cassandra or namespace in Astra DB. Required.\ntable_name\nMessageText\nThe name of the table or collection for storing messages. Required.\nsession_id\nMessageText\nThe unique identifier for the chat session. Optional.\ncluster_kwargs\nDictionary\nAdditional keyword arguments for the Cassandra cluster configuration. Optional.\n**Outputs**\nName\nType\nDescription\nmessage_history\nBaseChatMessageHistory\nAn instance of CassandraChatMessageHistory for the session.', 'Mem0 Chat Memory': 'The Mem0 Chat Memory component retrieves and stores chat messages using Mem0 memory storage.\n**Inputs**\nName\nDisplay Name\nInfo\nmem0_config\nMem0 Configuration\nThe configuration dictionary for initializing the Mem0 memory instance.\ningest_message\nMessage to Ingest\nThe message content to be ingested into Mem0 memory.\nexisting_memory\nExisting Memory Instance\nAn optional existing Mem0 memory instance.\nuser_id\nUser ID\nThe identifier for the user associated with the messages.\nsearch_query\nSearch Query\nThe input text for searching related memories in Mem0.\nmem0_api_key\nMem0 API Key\nThe API key for the Mem0 platform. Leave empty to use the local version.\nmetadata\nMetadata\nThe additional metadata to associate with the ingested message.\nopenai_api_key\nOpenAI API Key\nThe API key for OpenAI. Required when using OpenAI embeddings without a provided configuration.\n**Outputs**\nName\nDisplay Name\nInfo\nmemory\nMem0 Memory\nThe resulting Mem0 Memory object after ingesting data.\nsearch_results\nSearch Results\nThe search results from querying Mem0 memory.', 'Redis Chat Memory': 'This component retrieves and stores chat messages from Redis.\n**Inputs**\nName\nDisplay Name\nInfo\nhost\nhostname\nThe IP address or hostname.\nport\nport\nThe Redis Port Number.\ndatabase\ndatabase\nThe Redis database.\nusername\nUsername\nThe Redis username.\npassword\nPassword\nThe password for the username.\nkey_prefix\nKey prefix\nThe key prefix.\nsession_id\nSession ID\nThe session ID for the message.\n**Outputs**\nName\nDisplay Name\nInfo\nmemory\nMemory\nThe Redis chat message history object.', 'Legacy components': '**Legacy** components are available for use but are no longer supported.', 'ZepChatMemory Component': 'This component creates a `ZepChatMessageHistory` instance, enabling storage and retrieval of chat messages using Zep, a memory server for Large Language Models (LLMs).\n**Inputs**\nName\nType\nDescription\nurl\nMessageText\nThe URL of the Zep instance. Required.\napi_key\nSecretString\nThe API Key for authentication with the Zep instance.\napi_base_path\nDropdown\nThe API version to use. Options include api/v1 or api/v2.\nsession_id\nMessageText\nThe unique identifier for the chat session. Optional.\n**Outputs**\nName\nType\nDescription\nmessage_history\nBaseChatMessageHistory\nAn instance of ZepChatMessageHistory for the session.'}
{'title: Tools\nslug: /components-tools': 'import Icon from "@site/src/components/icon";', 'Tool components in Langflow': "Tools are typically connected to agent components at the **Tools** port. Agents use LLMs as a reasoning engine to decide which of the connected tool components to use to solve a problem.\nTools in agentic functions are, essentially, functions that the agent can call to perform tasks or access external resources.\nA function is wrapped as a `Tool` object, with a common interface the agent understands.\nAgents become aware of tools through tool registration, where the agent is provided a list of available tools, typically at agent initialization. The `Tool` object's description tells the agent what the tool can do.\nThe agent then uses a connected LLM to reason through the problem to decide which tool is best for the job.", 'Use a tool in a flow': "Tools are typically connected to agent components at the **Tools** port.\nThe [simple agent starter project](/starter-projects-simple-agent) uses URL and Calculator tools connected to an [agent component](/components-agents#agent-component) to answer a user's questions. The OpenAI LLM acts as a brain for the agent to decide which tool to use.\n![Simple agent starter flow](/img/starter-flow-simple-agent.png)\nTo make a component into a tool that an agent can use, enable **Tool mode** in the component. Enabling **Tool mode** modifies a component input to accept calls from an agent.\nIf the component you want to connect to an agent doesn't have a **Tool mode** option, you can modify the component's inputs to become a tool.\nFor an example, see [Make any component a tool](/agents-tool-calling-agent-component#make-any-component-a-tool).", 'arXiv': 'This component searches and retrieves papers from [arXiv.org](https://arXiv.org).\n**Inputs**\nName\nType\nDescription\nsearch_query\nString\nThe search query for arXiv papers. For example, `quantum computing`.\nsearch_type\nString\nThe field to search in.\nmax_results\nInteger\nThe maximum number of results to return.\n**Outputs**\nName\nType\nDescription\npapers\nList[Data]\nA list of retrieved arXiv papers.', 'Astra DB tool': "This component allows agents to query data from Astra DB collections.\nTo use this tool in a flow, connect it to an **Agent** component.\nThe flow looks like this:\n![Astra DB JSON tool connected to an Agent](/img/component-astra-db-json-tool.png)\nThe **Tool Name** and **Tool Description** fields are required for the Agent to decide when to use the tool.\n**Tool Name** cannot contain spaces.\nThe values for **Collection Name**, **Astra DB Application Token**, and **Astra DB API Endpoint** are found in your Astra DB deployment. For more information, see the [DataStax documentation](https://docs.datastax.com/en/astra-db-serverless/databases/create-database.html).\nIn this example, an **OpenAI** embeddings component is connected to use the Astra DB tool component's **Semantic Search** capability.\nTo use **Semantic Search**, you must have an embedding model or Astra DB Vectorize enabled.\nIf you try to run the flow without an embedding model, you will get an error.\nOpen the **Playground** and ask a question about your data.\nThe Agent uses the **Astra DB Tool** to return information about your collection.", 'Define Astra DB tool parameters': 'The **Tool Parameters** configuration pane allows you to define parameters for [filter conditions](https://docs.datastax.com/en/astra-db-serverless/api-reference/document-methods/find-many.html#parameters) for the component\'s **Find** command.\nThese filters become available as parameters that the LLM can use when calling the tool, with a better understanding of each parameter provided by the **Description** field.\nTo define a parameter for your query, in the **Tool Parameters** pane, click <Icon name="Plus" aria-label="Add"/>.\nComplete the fields based on your data. For example, with this filter, the LLM can filter by unique `customer_id` values.\nName: `customer_id`\nAttribute Name: Leave empty if the attribute matches the field name in the database.\nDescription: `"The unique identifier of the customer to filter by"`.\nIs Metadata: `False` unless the value stored in the metadata field.\nIs Mandatory: `True` to require this filter.\nIs Timestamp: `False` since the value is an ID, not a timestamp.\nOperator: `$eq` to look for an exact match.\nIf you want to apply filters regardless of the LLM\'s input, use the **Static Filters** option, which is available in the component\'s **Controls** pane.\nParameter\nDescription\nName\nThe name of the parameter that is exposed to the LLM. It can be the same as the underlying field name or a more descriptive label. The LLM uses this name, along with the description, to infer what value to provide during execution.\nAttribute Name\nWhen the parameter name shown to the LLM differs from the actual field or property in the database, use this setting to map the user-facing name to the correct attribute. For example, to apply a range filter to the timestamp field, define two separate parameters, such as `start_date` and `end_date`, that both reference the same timestamp attribute.\nDescription\nProvides instructions to the LLM on how the parameter should be used. Clear and specific guidance helps the LLM provide valid input. For example, if a field such as `specialty` is stored in lowercase, the description should indicate that the input must be lowercase.\nIs Metadata\nWhen loading data using LangChain or Langflow, additional attributes may be stored under a metadata object. If the target attribute is stored this way, enable this option. It adjusts the query by generating a filter in the format: `{"metadata.<attribute_name>": "<value>"}`\nIs Timestamp\nFor date or time-based filters, enable this option to automatically convert values to the timestamp format that the Astrapy client expects. This ensures compatibility with the underlying API without requiring manual formatting.\nOperator\nDefines the filtering logic applied to the attribute. You can use any valid [Data API filter operator](https://docs.datastax.com/en/astra-db-serverless/api-reference/filter-operator-collections.html). For example, to filter a time range on the timestamp attribute, use two parameters: one with the `$gt` operator for "greater than", and another with the `$lt` operator for "less than".\n**Inputs**\nName\nType\nDescription\nTool Name\nString\nThe name used to reference the tool in the agent\'s prompt.\nTool Description\nString\nA brief description of the tool. This helps the model decide when to use it.\nCollection Name\nString\nThe name of the Astra DB collection to query.\nToken\nSecretString\nThe authentication token for accessing Astra DB.\nAPI Endpoint\nString\nThe Astra DB API endpoint.\nProjection Fields\nString\nThe attributes to return, separated by commas. The default is `*`.\nTool Parameters\nDict\nParameters the model needs to fill to execute the tool. For required parameters, use an exclamation mark, for example `!customer_id`.\nStatic Filters\nDict\nAttribute-value pairs used to filter query results.\nLimit\nString\nThe number of documents to return.\n**Outputs**\nThe **Data** output is used when directly querying Astra DB, while the **Tool** output is used when integrating with agents.\nName\nType\nDescription\nData\nList[Data]\nA list of [Data](/concepts-objects) objects containing the query results from Astra DB. Each `Data` object contains the document fields specified by the projection attributes. Limited by the `number_of_results` parameter.\nTool\nStructuredTool\nA LangChain `StructuredTool` object that can be used in agent workflows. Contains the tool name, description, argument schema based on tool parameters, and the query function.', 'Astra DB CQL Tool': 'The `Astra DB CQL Tool` allows agents to query data from CQL tables in Astra DB.\n**Inputs**\nName\nType\nDescription\nTool Name\nString\nThe name used to reference the tool in the agent\'s prompt.\nTool Description\nString\nA brief description of the tool to guide the model in using it.\nKeyspace\nString\nThe name of the keyspace.\nTable Name\nString\nThe name of the Astra DB CQL table to query.\nToken\nSecretString\nThe authentication token for Astra DB.\nAPI Endpoint\nString\nThe Astra DB API endpoint.\nProjection Fields\nString\nThe attributes to return, separated by commas. Default: "*".\nPartition Keys\nDict\nRequired parameters that the model must fill to query the tool.\nClustering Keys\nDict\nOptional parameters the model can fill to refine the query. Required parameters should be marked with an exclamation mark, for example, `!customer_id`.\nStatic Filters\nDict\nAttribute-value pairs used to filter query results.\nLimit\nString\nThe number of records to return.\n**Outputs**\nName\nType\nDescription\nData\nList[Data]\nA list of [Data](/concepts-objects) objects containing the query results from the Astra DB CQL table. Each Data object contains the document fields specified by the projection fields. Limited by the `number_of_results` parameter.\nTool\nStructuredTool\nA LangChain StructuredTool object that can be used in agent workflows. Contains the tool name, description, argument schema based on partition and clustering keys, and the query function.', 'Bing Search API': 'This component allows you to call the Bing Search API.\n**Inputs**\nName\nType\nDescription\nbing_subscription_key\nSecretString\nA Bing API subscription key.\ninput_value\nString\nThe search query input.\nbing_search_url\nString\nA custom Bing Search URL.\nk\nInteger\nThe number of search results to return.\n**Outputs**\nName\nType\nDescription\nresults\nList[Data]\nA list of search results.\ntool\nTool\nA Bing Search tool for use in LangChain.', 'Combinatorial Reasoner': "This component runs Icosa's Combinatorial Reasoning (CR) pipeline on an input to create an optimized prompt with embedded reasons. For more information, see [Icosa computing](https://www.icosacomputing.com/).\n**Inputs**\nName\nType\nDescription\nprompt\nString\nThe input to run CR on.\nopenai_api_key\nSecretString\nAn OpenAI API key for authentication.\nusername\nString\nA username for Icosa API authentication.\npassword\nSecretString\nA password for Icosa API authentication.\nmodel_name\nString\nThe OpenAI LLM to use for reason generation.\n**Outputs**\nName\nType\nDescription\noptimized_prompt\nMessage\nA message object containing the optimized prompt.\nreasons\nList[String]\nA list of the selected reasons that are embedded in the optimized prompt.", 'DuckDuckGo search': 'This component performs web searches using the [DuckDuckGo](https://www.duckduckgo.com) search engine with result-limiting capabilities.\n**Inputs**\nName\nType\nDescription\ninput_value\nString\nThe search query to execute with DuckDuckGo.\nmax_results\nInteger\nThe maximum number of search results to return. Default: 5.\nmax_snippet_length\nInteger\nThe maximum length of each result snippet. Default: 100.\n**Outputs**\nName\nType\nDescription\ndata\nList[Data]\nA list of search results as Data objects containing snippets and full content.\ntext\nString\nThe search results formatted as a single text string.', 'Exa Search': 'This component provides an [Exa Search](https://exa.ai/) toolkit for search and content retrieval.\n**Inputs**\nName\nType\nDescription\nmetaphor_api_key\nSecretString\nAn API key for Exa Search.\nuse_autoprompt\nBoolean\nWhether to use the autoprompt feature. Default: true.\nsearch_num_results\nInteger\nThe number of results to return for search. Default: 5.\nsimilar_num_results\nInteger\nThe number of similar results to return. Default: 5.\n**Outputs**\nName\nType\nDescription\ntools\nList[Tool]\nA list of search tools provided by the toolkit.', 'Glean Search API': 'This component allows you to call the Glean Search API.\n**Inputs**\nName\nType\nDescription\nglean_api_url\nString\nThe URL of the Glean API.\nglean_access_token\nSecretString\nAn access token for Glean API authentication.\nquery\nString\nThe search query input.\npage_size\nInteger\nThe number of results per page. Default: 10.\nrequest_options\nDict\nAdditional options for the API request.\n**Outputs**\nName\nType\nDescription\nresults\nList[Data]\nA list of search results.\ntool\nTool\nA Glean Search tool for use in LangChain.', 'Google Serper API': 'This component allows you to call the Serper.dev Google Search API.\n**Inputs**\nName\nType\nDescription\nserper_api_key\nSecretString\nAn API key for Serper.dev authentication.\ninput_value\nString\nThe search query input.\nk\nInteger\nThe number of search results to return.\n**Outputs**\nName\nType\nDescription\nresults\nList[Data]\nA list of search results.\ntool\nTool\nA Google Serper search tool for use in LangChain.', 'MCP connection': 'The **MCP connection** component connects to a [Model Context Protocol (MCP)](https://modelcontextprotocol.io/introduction) server and exposes the MCP server\'s tools as tools for Langflow agents.\nIn addition to being an MCP client that can leverage MCP servers, the **MCP connection** component\'s [SSE mode](#mcp-sse-mode) allows you to connect your flow to the Langflow MCP server at the `/api/v1/mcp/sse` API endpoint, exposing all flows within your [project](/concepts-overview#projects) as tools within a flow.\nTo use the **MCP connection** component with an agent component, follow these steps:\nAdd the **MCP connection** component to your workflow.\nIn the **MCP connection** component, in the **MCP Command** field, enter the command to start your MCP server. For example, to start a [Fetch](https://github.com/modelcontextprotocol/servers/tree/main/src/fetch) server, the command is:\n`uvx` is included with `uv` in the Langflow package.\n To use `npx` server commands, you must first install an LTS release of [Node.js](https://docs.npmjs.com/downloading-and-installing-node-js-and-npm).\n For an example of starting `npx` MCP servers, see [Connect an Astra DB MCP server to Langflow](/mcp-component-astra).\nTo include environment variables with your server command, add them to the **Env** field like this:\n:::important\n Langflow passes environment variables from the `.env` file to MCP, but not global variables declared in the UI.\n To add a value for an environment variable as a global variable, add it to Langflow\'s `.env` file at startup.\n For more information, see [global variables](/configuration-global-variables).\n :::\nClick <Icon name="RefreshCw" aria-label="Refresh"/> to get the server\'s list of **Tools**.\nIn the **Tool** field, select the server tool you want the component to use.\nThe available fields change based on the selected tool.\nFor information on the parameters, see the MCP server\'s documentation.\nIn the **MCP connection** component, enable **Tool mode**.\nConnect the **MCP connection** component\'s **Toolset** port to an **Agent** component\'s **Tools** port.\nThe flow looks similar to this:\n ![MCP connection component](/img/component-mcp-stdio.png)\nOpen the **Playground**.\nAsk the agent to summarize recent tech news. The agent calls the MCP server function `fetch` and returns the summary.\nThis confirms the MCP server is connected, and its tools are being used in Langflow.\nFor more information, see [MCP server](/mcp-server).', 'MCP Server-Sent Events (SSE) mode {#mcp-sse-mode}': ':::important\nIf you\'re using **Langflow for Desktop**, the default address is `http://127.0.0.1:7868/`.\n:::\nThe MCP component\'s SSE mode connects your flow to the Langflow MCP server through the component.\nThis allows you to use all flows within your [project](/concepts-overview#projects) as tools within a flow.\nIn the **MCP connection** component, select **SSE**.\nA default address appears in the **MCP SSE URL** field.\nIn the **MCP SSE URL** field, modify the default address to point at the SSE endpoint of the Langflow server you\'re currently running.\nThe default value is `http://localhost:7860/api/v1/mcp/sse`.\nIn the **MCP connection** component, click <Icon name="RefreshCw" aria-label="Refresh"/> to retrieve the server\'s list of **Tools**.\nClick the **Tools** field.\nAll of your flows are listed as tools.\nEnable **Tool Mode**, and then connect the **MCP connection** component to an agent component\'s tool port.\nThe flow looks like this:\n![MCP component with SSE mode enabled](/img/component-mcp-sse-mode.png)\nOpen the **Playground** and chat with your tool.\nThe agent chooses the correct tool based on your query.\n**Inputs**\nName\nType\nDescription\ncommand\nString\nThe MCP command. Default: `uvx mcp-sse-shim@latest`.\n**Outputs**\nName\nType\nDescription\ntools\nList[Tool]\nA list of tools exposed by the MCP server.', 'Wikidata': 'This component performs a search using the Wikidata API.\n**Inputs**\nName\nType\nDescription\nquery\nString\nThe text query for similarity search on Wikidata.\n**Outputs**\nName\nType\nDescription\ndata\nList[Data]\nThe search results from Wikidata API as a list of Data objects.\ntext\nMessage\nThe search results formatted as a text message.', 'Legacy components': 'Legacy components are available for use but are no longer supported.', 'Calculator Tool': 'This component allows you to evaluate basic arithmetic expressions. It supports addition, subtraction, multiplication, division, and exponentiation.\n**Inputs**\nName\nType\nDescription\nexpression\nString\nThe arithmetic expression to evaluate. For example, `4*4*(33/22)+12-20`.\n**Outputs**\nName\nType\nDescription\nresult\nTool\nA calculator tool for use in LangChain.', 'Google Search API': 'This component allows you to call the Google Search API.\n**Inputs**\nName\nType\nDescription\ngoogle_api_key\nSecretString\nA Google API key for authentication.\ngoogle_cse_id\nSecretString\nA Google Custom Search Engine ID.\ninput_value\nString\nThe search query input.\nk\nInteger\nThe number of search results to return.\n**Outputs**\nName\nType\nDescription\nresults\nList[Data]\nA list of search results.\ntool\nTool\nA Google Search tool for use in LangChain.', 'Python Code Structured Tool': "This component creates a structured tool from Python code using a dataclass.\nThe component dynamically updates its configuration based on the provided Python code, allowing for custom function arguments and descriptions.\n**Inputs**\nName\nType\nDescription\ntool_code\nString\nThe Python code for the tool's dataclass.\ntool_name\nString\nThe name of the tool.\ntool_description\nString\nThe description of the tool.\nreturn_direct\nBoolean\nWhether to return the function output directly.\ntool_function\nString\nThe selected function for the tool.\nglobal_variables\nDict\nGlobal variables or data for the tool.\n**Outputs**\nName\nType\nDescription\nresult_tool\nTool\nA structured tool created from the Python code.", 'Python REPL Tool': "This component creates a Python REPL (Read-Eval-Print Loop) tool for executing Python code.\n**Inputs**\nName\nType\nDescription\nname\nString\nThe name of the tool. Default: `python_repl`.\ndescription\nString\nA description of the tool's functionality.\nglobal_imports\nList[String]\nA list of modules to import globally. Default: `math`.\n**Outputs**\nName\nType\nDescription\ntool\nTool\nA Python REPL tool for use in LangChain.", 'Retriever Tool': "This component creates a tool for interacting with a retriever in LangChain.\n**Inputs**\nName\nType\nDescription\nretriever\nBaseRetriever\nThe retriever to interact with.\nname\nString\nThe name of the tool.\ndescription\nString\nA description of the tool's functionality.\n**Outputs**\nName\nType\nDescription\ntool\nTool\nA retriever tool for use in LangChain.", 'Search API': 'This component calls the `searchapi.io` API. It can be used to search the web for information.\nFor more information, see the [SearchAPI documentation](https://www.searchapi.io/docs/google).\n**Inputs**\nName\nType\nDescription\nengine\nString\nThe search engine to use. Default: `google`.\napi_key\nSecretString\nThe API key for authenticating with SearchAPI.\ninput_value\nString\nThe search query or input for the API call.\nsearch_params\nDict\nAdditional parameters for customizing the search.\n**Outputs**\nName\nType\nDescription\ndata\nList[Data]\nA list of Data objects containing search results.\ntool\nTool\nA Tool object for use in LangChain workflows.', 'SearXNG Search Tool': 'This component creates a tool for searching using SearXNG, a metasearch engine.\n**Inputs**\nName\nType\nDescription\nurl\nString\nThe URL of the SearXNG instance.\nmax_results\nInteger\nThe maximum number of results to return.\ncategories\nList[String]\nThe categories to search in.\nlanguage\nString\nThe language for the search results.\n**Outputs**\nName\nType\nDescription\nresult_tool\nTool\nA SearXNG search tool for use in LangChain.', 'Wikipedia API': 'This component creates a tool for searching and retrieving information from Wikipedia.\n**Inputs**\nName\nType\nDescription\ninput_value\nString\nThe search query input.\nlang\nString\nThe language code for Wikipedia. Default: `en`.\nk\nInteger\nThe number of results to return.\nload_all_available_meta\nBoolean\nWhether to load all available metadata.\ndoc_content_chars_max\nInteger\nThe maximum number of characters for document content.\n**Outputs**\nName\nType\nDescription\nresults\nList[Data]\nA list of Wikipedia search results.\ntool\nTool\nA Wikipedia search tool for use in LangChain.', 'Deprecated components': 'Deprecated components have been replaced by newer alternatives and should not be used in new projects.', 'MCP Tools (stdio)': ':::important\nThis component is deprecated as of Langflow version 1.3.\nInstead, use the [MCP connection component](/components-tools#mcp-connection)\n:::', 'MCP Tools (SSE)': ':::important\nThis component is deprecated as of Langflow version 1.3.\nInstead, use the [MCP connection component](/components-tools#mcp-connection)\n:::'}
{'title: Agents\nslug: /components-agents': '', 'Agent components in Langflow': "Agent components define the behavior and capabilities of AI agents in your flow.\nAgents use LLMs as a reasoning engine to decide which of the connected tool components to use to solve a problem.\nTools in agentic functions are essentially functions that the agent can call to perform tasks or access external resources.\nA function is wrapped as a `Tool` object with a common interface the agent understands.\nAgents become aware of tools through tool registration where the agent is provided a list of available tools typically at agent initialization. The `Tool` object's description tells the agent what the tool can do.\nThe agent then uses a connected LLM to reason through the problem to decide which tool is best for the job.", 'Use an agent in a flow': "The [simple agent starter project](/starter-projects-simple-agent) uses an [agent component](#agent-component) connected to URL and Calculator tools to answer a user's questions. The OpenAI LLM acts as a brain for the agent to decide which tool to use. Tools are connected to agent components at the **Tools** port.\n![Simple agent starter flow](/img/starter-flow-simple-agent.png)\nFor a multi-agent example see, [Create a problem-solving agent](/agents-tool-calling-agent-component).", 'Agent component {#agent-component}': "This component creates an agent that can use tools to answer questions and perform tasks based on given instructions.\nThe component includes an LLM model integration, a system message prompt, and a **Tools** port to connect tools to extend its capabilities.\nFor more information on this component, see the [tool calling agent documentation](/agents-tool-calling-agent-component).\n**Inputs**\nName\nType\nDescription\nagent_llm\nDropdown\nThe provider of the language model that the agent uses to generate responses. Options include OpenAI and other providers or Custom.\nsystem_prompt\nString\nThe system prompt provides initial instructions and context to guide the agent's behavior.\ntools\nList\nThe list of tools available for the agent to use.\ninput_value\nString\nThe input task or question for the agent to process.\nadd_current_date_tool\nBoolean\nWhen true this adds a tool to the agent that returns the current date.\nmemory\nMemory\nAn optional memory configuration for maintaining conversation history.\nmax_iterations\nInteger\nThe maximum number of iterations the agent can perform.\nhandle_parsing_errors\nBoolean\nThis determines whether to handle parsing errors during agent execution.\nverbose\nBoolean\nThis enables verbose output for detailed logging.\n**Outputs**\nName\nType\nDescription\nresponse\nMessage\nThe agent's response to the given input task.", 'Legacy components': '**Legacy** components are available for use but are no longer supported.', 'JSON Agent': 'This component creates a JSON agent from a JSON or YAML file and an LLM.\n**Inputs**\nName\nType\nDescription\nllm\nLanguageModel\nThe language model to use for the agent.\npath\nFile\nThe path to the JSON or YAML file.\n**Outputs**\nName\nType\nDescription\nagent\nAgentExecutor\nThe JSON agent instance.', 'Vector Store Agent': 'This component creates a Vector Store Agent using LangChain.\n**Inputs**\nName\nType\nDescription\nllm\nLanguageModel\nThe language model to use for the agent.\nvectorstore\nVectorStoreInfo\nThe vector store information for the agent to use.\n**Outputs**\nName\nType\nDescription\nagent\nAgentExecutor\nThe Vector Store Agent instance.', 'Vector Store Router Agent': 'This component creates a Vector Store Router Agent using LangChain.\n**Inputs**\nName\nType\nDescription\nllm\nLanguageModel\nThe language model to use for the agent.\nvectorstores\nList[VectorStoreInfo]\nThe list of vector store information for the agent to route between.\n**Outputs**\nName\nType\nDescription\nagent\nAgentExecutor\nThe Vector Store Router Agent instance.', 'Moved components': 'The following components are available under **Bundles**.', 'CrewAI Agent': "This component represents an Agent of CrewAI allowing for the creation of specialized AI agents with defined roles goals and capabilities within a crew.\nFor more information, see the [CrewAI documentation](https://docs.crewai.com/core-concepts/Agents/).\n**Inputs**\nName\nDisplay Name\nInfo\nrole\nRole\nThe role of the agent.\ngoal\nGoal\nThe objective of the agent.\nbackstory\nBackstory\nThe backstory of the agent.\ntools\nTools\nThe tools at the agent's disposal.\nllm\nLanguage Model\nThe language model that runs the agent.\nmemory\nMemory\nThis determines whether the agent should have memory or not.\nverbose\nVerbose\nThis enables verbose output.\nallow_delegation\nAllow Delegation\nThis determines whether the agent is allowed to delegate tasks to other agents.\nallow_code_execution\nAllow Code Execution\nThis determines whether the agent is allowed to execute code.\nkwargs\nkwargs\nAdditional keyword arguments for the agent.\n**Outputs**\nName\nDisplay Name\nInfo\noutput\nAgent\nThe constructed CrewAI Agent object.", 'Hierarchical Crew': 'This component represents a group of agents managing how they should collaborate and the tasks they should perform in a hierarchical structure. This component allows for the creation of a crew with a manager overseeing the task execution.\nFor more information, see the [CrewAI documentation](https://docs.crewai.com/how-to/Hierarchical/).\n**Inputs**\nName\nDisplay Name\nInfo\nagents\nAgents\nThe list of Agent objects representing the crew members.\ntasks\nTasks\nThe list of HierarchicalTask objects representing the tasks to be executed.\nmanager_llm\nManager LLM\nThe language model for the manager agent.\nmanager_agent\nManager Agent\nThe specific agent to act as the manager.\nverbose\nVerbose\nThis enables verbose output for detailed logging.\nmemory\nMemory\nThe memory configuration for the crew.\nuse_cache\nUse Cache\nThis enables caching of results.\nmax_rpm\nMax RPM\nThis sets the maximum requests per minute.\nshare_crew\nShare Crew\nThis determines if the crew information is shared among agents.\nfunction_calling_llm\nFunction Calling LLM\nThe language model for function calling.\n**Outputs**\nName\nDisplay Name\nInfo\ncrew\nCrew\nThe constructed Crew object with hierarchical task execution.', 'CSV Agent': 'This component creates a CSV agent from a CSV file and LLM.\n**Inputs**\nName\nType\nDescription\nllm\nLanguageModel\nThe language model to use for the agent.\npath\nFile\nThe path to the CSV file.\nagent_type\nString\nThe type of agent to create.\n**Outputs**\nName\nType\nDescription\nagent\nAgentExecutor\nThe CSV agent instance.', 'OpenAI Tools Agent': "This component creates an OpenAI Tools Agent.\n**Inputs**\nName\nType\nDescription\nllm\nLanguageModel\nThe language model to use.\ntools\nList of Tools\nThe tools to give the agent access to.\nsystem_prompt\nString\nThe system prompt to provide context to the agent.\ninput_value\nString\nThe user's input to the agent.\nmemory\nMemory\nThe memory for the agent to use for context persistence.\nmax_iterations\nInteger\nThe maximum number of iterations to allow the agent to execute.\nverbose\nBoolean\nThis determines whether to print out the agent's intermediate steps.\nhandle_parsing_errors\nBoolean\nThis determines whether to handle parsing errors in the agent.\n**Outputs**\nName\nType\nDescription\nagent\nAgentExecutor\nThe OpenAI Tools agent instance.\noutput\nString\nThe output from executing the agent on the input.", 'OpenAPI Agent': 'This component creates an agent for interacting with OpenAPI services.\n**Inputs**\nName\nType\nDescription\nllm\nLanguageModel\nThe language model to use.\nopenapi_spec\nString\nThe OpenAPI specification for the service.\nbase_url\nString\nThe base URL for the API.\nheaders\nDict\nThe optional headers for API requests.\nagent_executor_kwargs\nDict\nThe optional parameters for the agent executor.\n**Outputs**\nName\nType\nDescription\nagent\nAgentExecutor\nThe OpenAPI agent instance.', 'Sequential Crew': 'This component represents a group of agents with tasks that are executed sequentially. This component allows for the creation of a crew that performs tasks in a specific order.\nFor more information, see the [CrewAI documentation](https://docs.crewai.com/how-to/Sequential/).\n**Inputs**\nName\nDisplay Name\nInfo\ntasks\nTasks\nThe list of SequentialTask objects representing the tasks to be executed.\nverbose\nVerbose\nThis enables verbose output for detailed logging.\nmemory\nMemory\nThe memory configuration for the crew.\nuse_cache\nUse Cache\nThis enables caching of results.\nmax_rpm\nMax RPM\nThis sets the maximum requests per minute.\nshare_crew\nShare Crew\nThis determines if the crew information is shared among agents.\nfunction_calling_llm\nFunction Calling LLM\nThe language model for function calling.\n**Outputs**\nName\nDisplay Name\nInfo\ncrew\nCrew\nThe constructed Crew object with sequential task execution.', 'Sequential task agent': "This component creates a CrewAI Task and its associated Agent allowing for the definition of sequential tasks with specific agent roles and capabilities.\nFor more information, see the [CrewAI documentation](https://docs.crewai.com/how-to/Sequential/).\n**Inputs**\nName\nDisplay Name\nInfo\nrole\nRole\nThe role of the agent.\ngoal\nGoal\nThe objective of the agent.\nbackstory\nBackstory\nThe backstory of the agent.\ntools\nTools\nThe tools at the agent's disposal.\nllm\nLanguage Model\nThe language model that runs the agent.\nmemory\nMemory\nThis determines whether the agent should have memory or not.\nverbose\nVerbose\nThis enables verbose output.\nallow_delegation\nAllow Delegation\nThis determines whether the agent is allowed to delegate tasks to other agents.\nallow_code_execution\nAllow Code Execution\nThis determines whether the agent is allowed to execute code.\nagent_kwargs\nAgent kwargs\nThe additional kwargs for the agent.\ntask_description\nTask Description\nThe descriptive text detailing the task's purpose and execution.\nexpected_output\nExpected Task Output\nThe clear definition of the expected task outcome.\nasync_execution\nAsync Execution\nThe boolean flag indicating asynchronous task execution.\nprevious_task\nPrevious Task\nThe previous task in the sequence for chaining.\n**Outputs**\nName\nDisplay Name\nInfo\ntask_output\nSequential Task\nThe list of SequentialTask objects representing the created tasks.", 'SQL Agent': "This component creates an agent for interacting with SQL databases.\n**Inputs**\nName\nType\nDescription\nllm\nLanguageModel\nThe language model to use.\ndatabase\nDatabase\nThe SQL database connection.\ntop_k\nInteger\nThe number of results to return from a SELECT query.\nuse_tools\nBoolean\nThis determines whether to use tools for query execution.\nreturn_intermediate_steps\nBoolean\nThis determines whether to return the agent's intermediate steps.\nmax_iterations\nInteger\nThe maximum number of iterations to run the agent.\nmax_execution_time\nInteger\nThe maximum execution time in seconds.\nearly_stopping_method\nString\nThe method to use for early stopping.\nverbose\nBoolean\nThis determines whether to print the agent's thoughts.\n**Outputs**\nName\nType\nDescription\nagent\nAgentExecutor\nThe SQL agent instance.", 'Tool Calling Agent': "This component creates an agent for structured tool calling with various language models.\n**Inputs**\nName\nType\nDescription\nllm\nLanguageModel\nThe language model to use.\ntools\nList[Tool]\nThe list of tools available to the agent.\nsystem_message\nString\nThe system message to use for the agent.\nreturn_intermediate_steps\nBoolean\nThis determines whether to return the agent's intermediate steps.\nmax_iterations\nInteger\nThe maximum number of iterations to run the agent.\nmax_execution_time\nInteger\nThe maximum execution time in seconds.\nearly_stopping_method\nString\nThe method to use for early stopping.\nverbose\nBoolean\nThis determines whether to print the agent's thoughts.\n**Outputs**\nName\nType\nDescription\nagent\nAgentExecutor\nThe tool calling agent instance.", 'XML Agent': 'This component creates an XML Agent using LangChain.\nThe agent uses XML formatting for tool instructions to the Language Model.\n**Inputs**\nName\nType\nDescription\nllm\nLanguageModel\nThe language model to use for the agent.\nuser_prompt\nString\nThe custom prompt template for the agent with XML formatting instructions.\ntools\nList[Tool]\nThe list of tools available to the agent.\n**Outputs**\nName\nType\nDescription\nagent\nAgentExecutor\nThe XML Agent instance.'}
{'title: Embeddings\nslug: /components-embedding-models': 'import Icon from "@site/src/components/icon";', 'Embeddings models in Langflow': "Embeddings models convert text into numerical vectors. These embeddings capture the semantic meaning of the input text, and allow LLMs to understand context.\nRefer to your specific component's documentation for more information on parameters.", 'Use an embeddings model component in a flow': "In this example of a document ingestion pipeline, the **OpenAI** embeddings model is connected to a vector database. The component converts the text chunks into vectors and stores them in the vector database. The vectorized data can be used to inform AI workloads like chatbots, similarity searches, and agents.\nThis embeddings component uses an OpenAI API key for authentication. Refer to your specific embeddings component's documentation for more information on authentication.\n![URL component in a data ingestion pipeline](/img/url-component.png)", 'AI/ML': 'This component generates embeddings using the [AI/ML API](https://docs.aimlapi.com/api-overview/embeddings).\n**Inputs**\nName\nType\nDescription\nmodel_name\nString\nThe name of the AI/ML embedding model to use.\naiml_api_key\nSecretString\nThe API key required for authenticating with the AI/ML service.\n**Outputs**\nName\nType\nDescription\nembeddings\nEmbeddings\nAn instance of `AIMLEmbeddingsImpl` for generating embeddings.', 'Amazon Bedrock Embeddings': 'This component is used to load embedding models from [Amazon Bedrock](https://aws.amazon.com/bedrock/).\n**Inputs**\nName\nType\nDescription\ncredentials_profile_name\nString\nThe name of the AWS credentials profile in `~/.aws/credentials` or `~/.aws/config`, which has access keys or role information.\nmodel_id\nString\nThe ID of the model to call, such as `amazon.titan-embed-text-v1`. This is equivalent to the `modelId` property in the `list-foundation-models` API.\nendpoint_url\nString\nThe URL to set a specific service endpoint other than the default AWS endpoint.\nregion_name\nString\nThe AWS region to use, such as `us-west-2`. Falls back to the `AWS_DEFAULT_REGION` environment variable or region specified in `~/.aws/config` if not provided.\n**Outputs**\nName\nType\nDescription\nembeddings\nEmbeddings\nAn instance for generating embeddings using Amazon Bedrock.', 'Astra DB vectorize': ':::important\nThis component is deprecated as of Langflow version 1.1.2.\nInstead, use the [Astra DB vector store component](/components-vector-stores#astra-db-vector-store).\n:::\nConnect this component to the **Embeddings** port of the [Astra DB vector store component](/components-vector-stores#astra-db-vector-store) to generate embeddings.\nThis component requires that your Astra DB database has a collection that uses a vectorize embedding provider integration.\nFor more information and instructions, see [Embedding Generation](https://docs.datastax.com/en/astra-db-serverless/databases/embedding-generation.html).\n**Inputs**\nName\nDisplay Name\nInfo\nprovider\nEmbedding Provider\nThe embedding provider to use.\nmodel_name\nModel Name\nThe embedding model to use.\nauthentication\nAuthentication\nThe name of the API key in Astra that stores your [vectorize embedding provider credentials](https://docs.datastax.com/en/astra-db-serverless/databases/embedding-generation.html#embedding-provider-authentication). (Not required if using an [Astra-hosted embedding provider](https://docs.datastax.com/en/astra-db-serverless/databases/embedding-generation.html#supported-embedding-providers).)\nprovider_api_key\nProvider API Key\nAs an alternative to `authentication`, directly provide your embedding provider credentials.\nmodel_parameters\nModel Parameters\nAdditional model parameters.\n**Outputs**\nName\nType\nDescription\nembeddings\nEmbeddings\nAn instance for generating embeddings using Astra vectorize.', 'Azure OpenAI Embeddings': 'This component generates embeddings using Azure OpenAI models.\n**Inputs**\nName\nType\nDescription\nModel\nString\nThe name of the model to use. Default: `text-embedding-3-small`.\nAzure Endpoint\nString\nYour Azure endpoint, including the resource, such as `https://example-resource.azure.openai.com/`.\nDeployment Name\nString\nThe name of the deployment.\nAPI Version\nString\nThe API version to use, with options including various dates.\nAPI Key\nString\nThe API key required to access the Azure OpenAI service.\n**Outputs**\nName\nType\nDescription\nembeddings\nEmbeddings\nAn instance for generating embeddings using Azure OpenAI.', 'Cloudflare Workers AI Embeddings': 'This component generates embeddings using [Cloudflare Workers AI models](https://developers.cloudflare.com/workers-ai/).\n**Inputs**\nName\nDisplay Name\nInfo\naccount_id\nCloudflare account ID\n[Find your Cloudflare account ID](https://developers.cloudflare.com/fundamentals/setup/find-account-and-zone-ids/#find-account-id-workers-and-pages).\napi_token\nCloudflare API token\n[Create an API token](https://developers.cloudflare.com/fundamentals/api/get-started/create-token/).\nmodel_name\nModel Name\n[List of supported models](https://developers.cloudflare.com/workers-ai/models/#text-embeddings).\nstrip_new_lines\nStrip New Lines\nWhether to strip new lines from the input text.\nbatch_size\nBatch Size\nThe number of texts to embed in each batch.\napi_base_url\nCloudflare API base URL\nThe base URL for the Cloudflare API.\nheaders\nHeaders\nAdditional request headers.\n**Outputs**\nName\nDisplay Name\nInfo\nembeddings\nEmbeddings\nAn instance for generating embeddings using Cloudflare Workers.', 'Cohere Embeddings': "This component is used to load embedding models from [Cohere](https://cohere.com/).\n**Inputs**\nName\nType\nDescription\ncohere_api_key\nString\nThe API key required to authenticate with the Cohere service.\nmodel\nString\nThe language model used for embedding text documents and performing queries. Default: `embed-english-v2.0`.\ntruncate\nBoolean\nWhether to truncate the input text to fit within the model's constraints. Default: `False`.\n**Outputs**\nName\nType\nDescription\nembeddings\nEmbeddings\nAn instance for generating embeddings using Cohere.", 'Embedding similarity': 'This component computes selected forms of similarity between two embedding vectors.\n**Inputs**\nName\nDisplay Name\nInfo\nembedding_vectors\nEmbedding Vectors\nA list containing exactly two data objects with embedding vectors to compare.\nsimilarity_metric\nSimilarity Metric\nSelect the similarity metric to use. Options: "Cosine Similarity", "Euclidean Distance", "Manhattan Distance".\n**Outputs**\nName\nDisplay Name\nInfo\nsimilarity_data\nSimilarity Data\nA data object containing the computed similarity score and additional information.', 'Google generative AI embeddings': 'This component connects to Google\'s generative AI embedding service using the GoogleGenerativeAIEmbeddings class from the `langchain-google-genai` package.\n**Inputs**\nName\nDisplay Name\nInfo\napi_key\nAPI Key\nThe secret API key for accessing Google\'s generative AI service. Required.\nmodel_name\nModel Name\nThe name of the embedding model to use. Default: "models/text-embedding-004".\n**Outputs**\nName\nDisplay Name\nInfo\nembeddings\nEmbeddings\nThe built GoogleGenerativeAIEmbeddings object.', 'Hugging Face Embeddings': ':::note\nThis component is deprecated as of Langflow version 1.0.18.\nInstead, use the [Hugging Face Embeddings Inference component](#hugging-face-embeddings-inference).\n:::\nThis component loads embedding models from HuggingFace.\nUse this component to generate embeddings using locally downloaded Hugging Face models. Ensure you have sufficient computational resources to run the models.\n**Inputs**\nName\nDisplay Name\nInfo\nCache Folder\nCache Folder\nThe folder path to cache HuggingFace models.\nEncode Kwargs\nEncoding Arguments\nAdditional arguments for the encoding process.\nModel Kwargs\nModel Arguments\nAdditional arguments for the model.\nModel Name\nModel Name\nThe name of the HuggingFace model to use.\nMulti Process\nMulti-Process\nWhether to use multiple processes.\n**Outputs**\nName\nDisplay Name\nInfo\nembeddings\nEmbeddings\nThe generated embeddings.', 'Hugging Face embeddings inference': "This component generates embeddings using [Hugging Face Inference API models](https://huggingface.co/) and requires a [Hugging Face API token](https://huggingface.co/docs/hub/security-tokens) to authenticate. Local inference models do not require an API key.\nUse this component to create embeddings with Hugging Face's hosted models, or to connect to your own locally hosted models.\n**Inputs**\nName\nDisplay Name\nInfo\nAPI Key\nAPI Key\nThe API key for accessing the Hugging Face Inference API.\nAPI URL\nAPI URL\nThe URL of the Hugging Face Inference API.\nModel Name\nModel Name\nThe name of the model to use for embeddings.\n**Outputs**\nName\nDisplay Name\nInfo\nembeddings\nEmbeddings\nThe generated embeddings.", 'Connect the Hugging Face component to a local embeddings model': 'To run an embeddings inference locally, see the [HuggingFace documentation](https://huggingface.co/docs/text-embeddings-inference/local_cpu).\nTo connect the local Hugging Face model to the **Hugging Face embeddings inference** component and use it in a flow, follow these steps:\nCreate a [Vector store RAG flow](/starter-projects-vector-store-rag).\nThere are two embeddings models in this flow that you can replace with **Hugging Face** embeddings inference components.\nReplace both **OpenAI** embeddings model components with **Hugging Face** model components.\nConnect both **Hugging Face** components to the **Embeddings** ports of the **Astra DB vector store** components.\nIn the **Hugging Face** components, set the **Inference Endpoint** field to the URL of your local inference model. **The **API Key** field is not required for local inference.**\nRun the flow. The local inference models generate embeddings for the input text.', 'IBM watsonx embeddings': 'This component generates text using [IBM watsonx.ai](https://www.ibm.com/watsonx) foundation models.\nTo use **IBM watsonx.ai** embeddings components, replace an embeddings component with the IBM watsonx.ai component in a flow.\nAn example document processing flow looks like the following:\n![IBM watsonx embeddings model loading a chroma-db with split text](/img/component-watsonx-embeddings-chroma.png)\nThis flow loads a PDF file from local storage and splits the text into chunks.\nThe **IBM watsonx** embeddings component converts the text chunks into embeddings, which are then stored in a Chroma DB vector store.\nThe values for **API endpoint**, **Project ID**, **API key**, and **Model Name** are found in your IBM watsonx.ai deployment.\nFor more information, see the [Langchain documentation](https://python.langchain.com/docs/integrations/text_embedding/ibm_watsonx/).', 'Default models': 'The component supports several default models with the following vector dimensions:\n`sentence-transformers/all-minilm-l12-v2`: 384-dimensional embeddings\n`ibm/slate-125m-english-rtrvr-v2`: 768-dimensional embeddings\n`ibm/slate-30m-english-rtrvr-v2`: 768-dimensional embeddings\n`intfloat/multilingual-e5-large`: 1024-dimensional embeddings\nThe component automatically fetches and updates the list of available models from your watsonx.ai instance when you provide your API endpoint and credentials.\n**Inputs**\nName\nDisplay Name\nInfo\nurl\nwatsonx API Endpoint\nThe base URL of the API.\nproject_id\nwatsonx project id\nThe project ID for your watsonx.ai instance.\napi_key\nAPI Key\nThe API Key to use for the model.\nmodel_name\nModel Name\nThe name of the embedding model to use.\ntruncate_input_tokens\nTruncate Input Tokens\nThe maximum number of tokens to process. Default: `200`.\ninput_text\nInclude the original text in the output\nDetermines if the original text is included in the output. Default: `True`.\n**Outputs**\nName\nDisplay Name\nInfo\nembeddings\nEmbeddings\nAn instance for generating embeddings using watsonx.ai.', 'LM Studio Embeddings': 'This component generates embeddings using [LM Studio](https://lmstudio.ai/docs) models.\n**Inputs**\nName\nDisplay Name\nInfo\nmodel\nModel\nThe LM Studio model to use for generating embeddings.\nbase_url\nLM Studio Base URL\nThe base URL for the LM Studio API.\napi_key\nLM Studio API Key\nThe API key for authentication with LM Studio.\ntemperature\nModel Temperature\nThe temperature setting for the model.\n**Outputs**\nName\nDisplay Name\nInfo\nembeddings\nEmbeddings\nThe generated embeddings.', 'MistralAI': 'This component generates embeddings using [MistralAI](https://docs.mistral.ai/) models.\n**Inputs**\nName\nType\nDescription\nmodel\nString\nThe MistralAI model to use. Default: "mistral-embed".\nmistral_api_key\nSecretString\nThe API key for authenticating with MistralAI.\nmax_concurrent_requests\nInteger\nThe maximum number of concurrent API requests. Default: 64.\nmax_retries\nInteger\nThe maximum number of retry attempts for failed requests. Default: 5.\ntimeout\nInteger\nThe request timeout in seconds. Default: 120.\nendpoint\nString\nThe custom API endpoint URL. Default: `https://api.mistral.ai/v1/`).\n**Outputs**\nName\nType\nDescription\nembeddings\nEmbeddings\nA MistralAIEmbeddings instance for generating embeddings.', 'NVIDIA': "This component generates embeddings using [NVIDIA models](https://docs.nvidia.com).\n**Inputs**\nName\nType\nDescription\nmodel\nString\nThe NVIDIA model to use for embeddings, such as `nvidia/nv-embed-v1`.\nbase_url\nString\nThe base URL for the NVIDIA API. Default: `https://integrate.api.nvidia.com/v1`.\nnvidia_api_key\nSecretString\nThe API key for authenticating with NVIDIA's service.\ntemperature\nFloat\nThe model temperature for embedding generation. Default: `0.1`.\n**Outputs**\nName\nType\nDescription\nembeddings\nEmbeddings\nA NVIDIAEmbeddings instance for generating embeddings.", 'Ollama embeddings': 'This component generates embeddings using [Ollama models](https://ollama.com/).\nFor a list of Ollama embeddings models, see the [Ollama documentation](https://ollama.com/search?c=embedding).\nTo use this component in a flow, connect Langflow to your locally running Ollama server and select an embeddings model.\nIn the Ollama component, in the **Ollama Base URL** field, enter the address for your locally running Ollama server.\nThis value is set as the `OLLAMA_HOST` environment variable in Ollama. The default base URL is `http://127.0.0.1:11434`.\nTo refresh the server\'s list of models, click <Icon name="RefreshCw" aria-label="Refresh"/>.\nIn the **Ollama Model** field, select an embeddings model. This example uses `all-minilm:latest`.\nConnect the **Ollama** embeddings component to a flow.\nFor example, this flow connects a local Ollama server running a `all-minilm:latest` embeddings model to a [Chroma DB](/components-vector-stores#chroma-db) vector store to generate embeddings for split text.\n![Ollama embeddings connected to Chroma DB](/img/component-ollama-embeddings-chromadb.png)\nFor more information, see the [Ollama documentation](https://ollama.com/).\n**Inputs**\nName\nType\nDescription\nOllama Model\nString\nThe name of the Ollama model to use. Default: `llama2`.\nOllama Base URL\nString\nThe base URL of the Ollama API. Default: `http://localhost:11434`.\nModel Temperature\nFloat\nThe temperature parameter for the model. Adjusts the randomness in the generated embeddings.\n**Outputs**\nName\nType\nDescription\nembeddings\nEmbeddings\nAn instance for generating embeddings using Ollama.', 'OpenAI Embeddings': 'This component is used to load embedding models from [OpenAI](https://openai.com/).\n**Inputs**\nName\nType\nDescription\nOpenAI API Key\nString\nThe API key to use for accessing the OpenAI API.\nDefault Headers\nDict\nThe default headers for the HTTP requests.\nDefault Query\nNestedDict\nThe default query parameters for the HTTP requests.\nAllowed Special\nList\nThe special tokens allowed for processing. Default: `[]`.\nDisallowed Special\nList\nThe special tokens disallowed for processing. Default: `["all"]`.\nChunk Size\nInteger\nThe chunk size for processing. Default: `1000`.\nClient\nAny\nThe HTTP client for making requests.\nDeployment\nString\nThe deployment name for the model. Default: `text-embedding-3-small`.\nEmbedding Context Length\nInteger\nThe length of embedding context. Default: `8191`.\nMax Retries\nInteger\nThe maximum number of retries for failed requests. Default: `6`.\nModel\nString\nThe name of the model to use. Default: `text-embedding-3-small`.\nModel Kwargs\nNestedDict\nAdditional keyword arguments for the model.\nOpenAI API Base\nString\nThe base URL of the OpenAI API.\nOpenAI API Type\nString\nThe type of the OpenAI API.\nOpenAI API Version\nString\nThe version of the OpenAI API.\nOpenAI Organization\nString\nThe organization associated with the API key.\nOpenAI Proxy\nString\nThe proxy server for the requests.\nRequest Timeout\nFloat\nThe timeout for the HTTP requests.\nShow Progress Bar\nBoolean\nWhether to show a progress bar for processing. Default: `False`.\nSkip Empty\nBoolean\nWhether to skip empty inputs. Default: `False`.\nTikToken Enable\nBoolean\nWhether to enable TikToken. Default: `True`.\nTikToken Model Name\nString\nThe name of the TikToken model.\n**Outputs**\nName\nType\nDescription\nembeddings\nEmbeddings\nAn instance for generating embeddings using OpenAI.', 'Text embedder': 'This component generates embeddings for a given message using a specified embedding model.\n**Inputs**\nName\nDisplay Name\nInfo\nembedding_model\nEmbedding Model\nThe embedding model to use for generating embeddings.\nmessage\nMessage\nThe message for which to generate embeddings.\n**Outputs**\nName\nDisplay Name\nInfo\nembeddings\nEmbedding Data\nA data object containing the original text and its embedding vector.', 'VertexAI Embeddings': 'This component is a wrapper around [Google Vertex AI](https://cloud.google.com/vertex-ai) [Embeddings API](https://cloud.google.com/vertex-ai/docs/generative-ai/embeddings/get-text-embeddings).\n**Inputs**\nName\nType\nDescription\ncredentials\nCredentials\nThe default custom credentials to use.\nlocation\nString\nThe default location to use when making API calls. Default: `us-central1`.\nmax_output_tokens\nInteger\nThe token limit determines the maximum amount of text output from one prompt. Default: `128`.\nmodel_name\nString\nThe name of the Vertex AI large language model. Default: `text-bison`.\nproject\nString\nThe default GCP project to use when making Vertex API calls.\nrequest_parallelism\nInteger\nThe amount of parallelism allowed for requests issued to VertexAI models. Default: `5`.\ntemperature\nFloat\nTunes the degree of randomness in text generations. Should be a non-negative value. Default: `0`.\ntop_k\nInteger\nHow the model selects tokens for output. The next token is selected from the top `k` tokens. Default: `40`.\ntop_p\nFloat\nTokens are selected from the most probable to least until the sum of their probabilities exceeds the top `p` value. Default: `0.95`.\ntuned_model_name\nString\nThe name of a tuned model. If provided, `model_name` is ignored.\nverbose\nBoolean\nThis parameter controls the level of detail in the output. When set to `True`, it prints internal states of the chain to help debug. Default: `False`.\n**Outputs**\nName\nType\nDescription\nembeddings\nEmbeddings\nAn instance for generating embeddings using VertexAI.'}
{'title: Logic\nslug: /components-logic': '', 'Logic components in Langflow': 'Logic components provide functionalities for routing, conditional processing, and flow management.', 'Use a logic component in a flow': 'This flow creates a summarizing "for each" loop with the [Loop](/components-logic#loop) component.\nThe component iterates over a list of [Data](/concepts-objects#data-object) objects until it\'s completed, and then the **Done** loop aggregates the results.\nThe **File** component loads text files from your local machine, and then the **Parser** component parses them into a list of structured `Data` objects.\nThe **Loop** component passes each `Data` object to a **Prompt** to be summarized.\nWhen the **Loop** component runs out of `Data`, the **Done** loop activates, which counts the number of pages and summarizes their tone with another **Prompt**.\nThis is represented in Langflow by connecting the Parser component\'s **Data List** output to the Loop component\'s `Data` loop input.\n![Sample Flow looping summarizer](/img/loop-text-summarizer.png)\nThe output is similar to this:', 'Conditional router (If-Else component)': "This component routes messages by comparing two strings.\nIt evaluates a condition by comparing two text inputs using the specified operator and routes the message to `true_result` or `false_result`.\nThe operator looks for single strings based on your defined [operator behavior](#operator-behavior), but it can also search for multiple words by regex matching.\nTo use the **Conditional router** component to check incoming messages with regex matching, do the following:\nConnect the **If-Else** component's **Text Input** port to a **Chat Input** component.\nIn the If-Else component, enter the following values.\nIn the **Match Text** field, enter `.*(urgent|warning|caution).*`. The component looks for these values. The regex match is case sensitive, so to look for all permutations of `warning`, enter `warning|Warning|WARNING`.\nIn the **Operator** field, enter `regex`. The component looks for the strings `urgent`, `warning`, and `caution`. For more operators, see [Operator behavior](#operator-behavior).\nIn the **Message** field, enter `New Message Detected`. This field is optional. The message is sent to both the **True** and **False** ports.\nThe component is now set up to send a `New Message Detected` message out of its **True** port if it matches any of the strings.\nIf no strings are detected, it sends a message out of the **False** port.\nCreate two identical flows to process the messages. Connect an **Open AI** component, a **Prompt**, and a **Chat Output** component together.\nConnect one chain to the **If-Else** component's **True** port, and one chain to the **False** port.\nThe flow looks like this:\n![A conditional router connected to two OpenAI components](/img/component-conditional-router.png)\nAdd your **OpenAI API key** to both **OpenAI** components.\nIn both **Prompt** components, enter the behavior you want each route to take.\nWhen a match is found:\nWhen a match is not found:\nOpen the **Playground**.\nSend the flow some messages. Your messages route differently based on the if-else component's evaluation.\n**Inputs**\nName\nType\nDescription\ninput_text\nString\nThe primary text input for the operation.\nmatch_text\nString\nThe text to compare against.\noperator\nDropdown\nThe operator used to compare texts. Options include equals, not equals, contains, starts with, ends with, and regex. The default is equals.\ncase_sensitive\nBoolean\nWhen set to true, the comparison is case sensitive. This setting does not apply to regex comparison. The default is false.\nmessage\nMessage\nThe message to pass through either route.\nmax_iterations\nInteger\nThe maximum number of iterations allowed for the conditional router. The default is 10.\ndefault_route\nDropdown\nThe route to take when max iterations are reached. Options include true_result or false_result. The default is false_result.\n**Outputs**\nName\nType\nDescription\ntrue_result\nMessage\nThe output produced when the condition is true.\nfalse_result\nMessage\nThe output produced when the condition is false.", 'Operator Behavior': 'The **If-else** component includes a comparison operator to compare the values in `input_text` and `match_text`.\nAll options respect the `case_sensitive` setting except **regex**.\n**equals**: Exact match comparison.\n**not equals**: Inverse of exact match.\n**contains**: Checks if match_text is found within input_text.\n**starts with**: Checks if input_text begins with match_text.\n**ends with**: Checks if input_text ends with match_text.\n**regex**: Performs regular expression matching. It is always case sensitive and ignores the case_sensitive setting.', 'Listen': 'This component listens for a notification and retrieves its associated state.\n**Inputs**\nName\nType\nDescription\nname\nString\nThe name of the notification to listen for.\n**Outputs**\nName\nType\nDescription\noutput\nData\nThe state associated with the notification.', 'Loop': ':::tip\nFor another **Loop** component example, see the **Research Translation Loop** template.\n:::\nThis component iterates over a list of [Data](/concepts-objects#data-object) objects, outputting one item at a time and aggregating results from loop inputs.\nIn this example, the **Loop** component iterates over a CSV file through the **Item** port until there are no rows left to process. Then, the **Loop** component performs the actions connected to the **Done** port, which in this case is loading the structured data into **Chroma DB**.\nThink of it this way: the **Item** port forms the "main" loop that repeats until a "complete" condition is reached.\nThe **Loop** component accepts **Data** from the **Load CSV** component, and outputs the data from the **Item** port.\nEach CSV row is converted to a **Message** and processed into structured data with the **Structured Output** component.\nThe dotted line connected from the **Structured Output** component\'s **Looping** port tells you where the loop begins again.\nThe **Loop** component repeatedly extracts rows by **Text Key** until there are no more rows to extract.\nOnce all items are processed, the action connected to the **Done** port is performed.\nIn this example, the data is loaded into **Chroma DB**.\n![Loop CSV parser](/img/component-loop-csv.png)\nFollow along with this step-by-step video guide for creating this flow and adding agentic RAG: [Mastering the Loop Component & Agentic RAG in Langflow](https://www.youtube.com/watch?v=9Wx7WODSKTo).\n**Inputs**\nName\nType\nDescription\ndata\nData/List\nThe initial list of Data objects to process.\n**Outputs**\nName\nType\nDescription\nitem\nData\nThe current item being processed from the data list.\ndone\nData\nThe aggregated results after all items are processed.', 'Notify': 'This component generates a notification for the Listen component to use.\n**Inputs**\nName\nType\nDescription\nname\nString\nThe name of the notification.\ndata\nData\nThe data to store in the notification.\nappend\nBoolean\nWhen set to true, the record is added to the existing notification.\n**Outputs**\nName\nType\nDescription\noutput\nData\nThe data stored in the notification.', 'Pass': 'This component forwards the input message, unchanged.\n**Inputs**\nName\nDisplay Name\nInfo\ninput_message\nInput Message\nThe message to forward.\nignored_message\nIgnored Message\nA second message that is ignored. Used as a workaround for continuity.\n**Outputs**\nName\nDisplay Name\nInfo\noutput_message\nOutput Message\nThe forwarded message from the input.', 'Run flow': "This component allows you to run any flow stored in your Langflow database without opening the flow editor.\nThe Run Flow component can also be used as a tool when connected to an [Agent](/components-agents). The `name` and `description` metadata that the Agent uses to register the tool are created automatically.\nWhen you select a flow, the component fetches the flow's graph structure and uses it to generate the inputs and outputs for the Run Flow component.\nTo use the Run Flow component as a tool, do the following:\nAdd the **Run Flow** component to the [Simple Agent](/starter-projects-simple-agent) flow.\nIn the **Flow Name** menu, select the sub-flow you want to run.\nThe appearance of the **Run Flow** component changes to reflect the inputs and outputs of the selected flow.\nOn the **Run Flow** component, enable **Tool Mode**.\nConnect the **Run Flow** component to the **Toolset** input of the Agent.\nYour flow should now look like this:\n![Run Flow component](/img/component-run-flow.png)\nRun the flow. The Agent uses the Run Flow component as a tool to run the selected sub-flow.\n**Inputs**\nName\nType\nDescription\nflow_name_selected\nDropdown\nThe name of the flow to run.\nflow_tweak_data\nDict\nDictionary of tweaks to customize the flow's behavior.\ndynamic inputs\nVarious\nAdditional inputs that are generated based on the selected flow.\n**Outputs**\nName\nType\nDescription\nrun_outputs\nA `List` of types `Data`, `Message,` or `DataFrame`\nAll outputs are generated from running the flow.", 'Legacy components': '**Legacy** components are available for use but are no longer supported.', 'Data Conditional Router': ':::important\nThis component is in **Legacy**, which means it is no longer in active development as of Langflow version 1.3.\n:::\nThis component routes `Data` objects based on a condition applied to a specified key, including boolean validation. It can process either a single Data object or a list of Data objects.\nThis component is particularly useful in workflows that require conditional routing of complex data structures, enabling dynamic decision-making based on data content.', 'Inputs': 'Name\nType\nDescription\nflow_name\nDropdown\nThe name of the flow to run.', 'Outputs': 'Name\nType\nDescription\nflow_outputs\nList[Data]\nThe outputs generated from the flow.', 'Operator behavior': '**equals**: Exact match comparison between the key\'s value and compare_value.\n**not equals**: Inverse of exact match.\n**contains**: Checks if compare_value is found within the key\'s value.\n**starts with**: Checks if the key\'s value begins with compare_value.\n**ends with**: Checks if the key\'s value ends with compare_value.\n**boolean validator**: Treats the key\'s value as a boolean. The following values are considered true:\nBoolean `true`.\nStrings: "true", "1", "yes", "y", "on" (case-insensitive).\nAny other value is converted using Python\'s `bool()` function.', 'List processing': 'The following actions occur when processing a list of Data objects:\nEach object in the list is evaluated individually\nObjects meeting the condition go to true_output\nObjects not meeting the condition go to false_output\nIf all objects go to one output, the other output is empty', 'Deprecated components': 'Deprecated components have been replaced by newer alternatives and should not be used in new projects.', 'Flow as tool {#flow-as-tool}': ':::important\nThis component is deprecated as of Langflow version 1.1.2.\nInstead, use the [Run flow component](/components-logic#run-flow)\n:::\nThis component constructs a tool from a function that runs a loaded flow.', 'Sub flow': ':::important\nThis component is deprecated as of Langflow version 1.1.2.\nInstead, use the [Run flow component](/components-logic#run-flow)\n:::\nThis `SubFlowComponent` generates a component from a flow with all of its inputs and outputs.\nThis component can integrate entire flows as components within a larger workflow. It dynamically generates inputs based on the selected flow and executes the flow with provided parameters.'}
{'title: Helpers\nslug: /components-helpers': 'import Icon from "@site/src/components/icon";', 'Helper components in Langflow': 'Helper components provide utility functions to help manage data, tasks, and other components in your flow.', 'Use a helper component in a flow': 'Chat memory in Langflow is stored either in local Langflow tables with `LCBufferMemory`, or connected to an external database.\nThe **Store Message** helper component stores chat memories as [Data](/concepts-objects) objects, and the **Message History** helper component retrieves chat messages as data objects or strings.\nThis example flow stores and retrieves chat history from an [AstraDBChatMemory](/components-memories#astradbchatmemory-component) component with **Store Message** and **Chat Memory** components.\n![Sample Flow storing Chat Memory in AstraDB](/img/astra_db_chat_memory_rounded.png)', 'Batch Run': 'The **Batch Run** component runs a language model over **each row** of a [DataFrame](/concepts-objects#dataframe-object) text column and returns a new DataFrame with the original text and an LLM response.\nThe response contains the following columns:\n`text_input`: The original text from the input DataFrame.\n`model_response`: The model\'s response for each input.\n`batch_index`: The processing order, with a `0`-based index.\n`metadata` (optional): Additional information about the processing.\nThese columns, when connected to a **Parser** component, can be used as variables within curly braces.\nTo use the Batch Run component with a **Parser** component, do the following:\nConnect a **Model** component to the **Batch Run** component\'s **Language model** port.\nConnect a component that outputs DataFrame, like **File** component, to the **Batch Run** component\'s **DataFrame** input.\nConnect the **Batch Run** component\'s **Batch Results** output to a **Parser** component\'s **DataFrame** input.\nThe flow looks like this:\n![A batch run component connected to OpenAI and a Parser](/img/component-batch-run.png)\nIn the **Column Name** field of the **Batch Run** component, enter a column name based on the data you\'re loading from the **File** loader. For example, to process a column of `name`, enter `name`.\nOptionally, in the **System Message** field of the **Batch Run** component, enter a **System Message** to instruct the connected LLM on how to process your file. For example, `Create a business card for each name.`\nIn the **Template** field of the **Parser** component, enter a template for using the **Batch Run** component\'s new DataFrame columns.\nTo use all three columns from the **Batch Run** component, include them like this:\nTo run the flow, in the **Parser** component, click <Icon name="Play" aria-label="Play icon" />.\nTo view your created DataFrame, in the **Parser** component, click <Icon name="TextSearch" aria-label="Inspect icon" />.\nOptionally, connect a **Chat Output** component, and open the **Playground** to see the output.\n**Inputs**\nName\nType\nDescription\nmodel\nHandleInput\nConnect the \'Language Model\' output from your LLM component here. Required.\nsystem_message\nMultilineInput\nA multi-line system instruction for all rows in the DataFrame.\ndf\nDataFrameInput\nThe DataFrame whose column is treated as text messages, as specified by \'column_name\'. Required.\ncolumn_name\nMessageTextInput\nThe name of the DataFrame column to treat as text messages. If empty, all columns are formatted in TOML.\noutput_column_name\nMessageTextInput\nName of the column where the model\'s response is stored. Default=`model_response`.\nenable_metadata\nBoolInput\nIf True, add metadata to the output DataFrame.\n**Outputs**\nName\nType\nDescription\nbatch_results\nDataFrame\nA DataFrame with all original columns plus the model\'s response column.', 'Current date': 'The Current Date component returns the current date and time in a selected timezone. This component provides a flexible way to obtain timezone-specific date and time information within a Langflow pipeline.\n**Inputs**\nName\nType\nDescription\ntimezone\nString\nThe timezone for the current date and time.\n**Outputs**\nName\nType\nDescription\ncurrent_date\nString\nThe resulting current date and time in the selected timezone.', 'ID Generator': 'This component generates a unique ID.\n**Inputs**\nName\nType\nDescription\nunique_id\nString\nThe generated unique ID.\n**Outputs**\nName\nType\nDescription\nid\nString\nThe generated unique ID.', 'Message history': ':::info\nPrior to Langflow 1.1, this component was known as the Chat Memory component.\n:::\nThis component retrieves chat messages from Langflow tables or external memory.\nIn this example, the **Message Store** component stores the complete chat history in a local Langflow table, which the **Message History** component retrieves as context for the LLM to answer each question.\n![Message store and history components](/img/component-message-history-message-store.png)\nFor more information on configuring memory in Langflow, see [Memory](/memory).\n**Inputs**\nName\nType\nDescription\nmemory\nMemory\nRetrieve messages from an external memory. If empty, the Langflow tables are used.\nsender\nString\nFilter by sender type.\nsender_name\nString\nFilter by sender name.\nn_messages\nInteger\nThe number of messages to retrieve.\nsession_id\nString\nThe session ID of the chat. If empty, the current session ID parameter is used.\norder\nString\nThe order of the messages.\ntemplate\nString\nThe template to use for formatting the data. It can contain the keys `{text}`, `{sender}` or any other key in the message data.\n**Outputs**\nName\nType\nDescription\nmessages\nData\nThe retrieved messages as Data objects.\nmessages_text\nMessage\nThe retrieved messages formatted as text.\ndataframe\nDataFrame\nA DataFrame containing the message data.', 'Message store': 'This component stores chat messages or text in Langflow tables or external memory.\nIn this example, the **Message Store** component stores the complete chat history in a local Langflow table, which the **Message History** component retrieves as context for the LLM to answer each question.\n![Message store and history components](/img/component-message-history-message-store.png)\nFor more information on configuring memory in Langflow, see [Memory](/memory).\n**Inputs**\nName\nType\nDescription\nmessage\nString\nThe chat message to be stored. (Required)\nmemory\nMemory\nThe external memory to store the message. If empty, the Langflow tables are used.\nsender\nString\nThe sender of the message. Can be Machine or User. If empty, the current sender parameter is used.\nsender_name\nString\nThe name of the sender. Can be AI or User. If empty, the current sender parameter is used.\nsession_id\nString\nThe session ID of the chat. If empty, the current session ID parameter is used.\n**Outputs**\nName\nType\nDescription\nstored_messages\nList[Data]\nThe list of stored messages after the current message has been added.', 'Structured output': 'This component transforms LLM responses into structured data formats.\nIn this example from the **Financial Support Parser** template, the **Structured Output** component transforms unstructured financial reports into structured data.\n![Structured output example](/img/component-structured-output.png)\nThe connected LLM model is prompted by the **Structured Output** component\'s `Format Instructions` parameter to extract structured output from the unstructured text. `Format Instructions` is utilized as the system prompt for the **Structured Output** component.\nIn the **Structured Output** component, click the **Open table** button to view the `Output Schema` table.\nThe `Output Schema` parameter defines the structure and data types for the model\'s output using a table with the following fields:\n**Name**: The name of the output field.\n**Description**: The purpose of the output field.\n**Type**: The data type of the output field. The available types are `str`, `int`, `float`, `bool`, `list`, or `dict`. The default is `text`.\n**Multiple**: This feature is deprecated. Currently, it is set to `True` by default if you expect multiple values for a single field. For example, a `list` of `features` is set to `True` to contain multiple values, such as `["waterproof", "durable", "lightweight"]`. Default: `True`.\nThe **Parse DataFrame** component parses the structured output into a template for orderly presentation in chat output. The template receives the values from the `output_schema` table with curly braces.\nFor example, the template `EBITDA: {EBITDA}  ,  Net Income: {NET_INCOME} , GROSS_PROFIT: {GROSS_PROFIT}` presents the extracted values in the **Playground** as `EBITDA: 900 million , Net Income: 500 million , GROSS_PROFIT: 1.2 billion`.\n**Inputs**\nName\nType\nDescription\nllm\nLanguageModel\nThe language model to use to generate the structured output.\ninput_value\nString\nThe input message to the language model.\nsystem_prompt\nString\nThe instructions to the language model for formatting the output.\nschema_name\nString\nThe name for the output data schema.\noutput_schema\nTable\nThe structure and data types for the model\'s output.\nmultiple\nBoolean\n[Deprecated] Always set to `True`.\n**Outputs**\nName\nType\nDescription\nstructured_output\nData\nThe structured output is a Data object based on the defined schema.', 'Legacy components': 'Legacy components are available for use but are no longer supported.', 'Create List': 'This component dynamically creates a record with a specified number of fields.\n**Inputs**\nName\nType\nDescription\nn_fields\nInteger\nThe number of fields to be added to the record.\ntext_key\nString\nThe key used as text.\n**Outputs**\nName\nType\nDescription\nlist\nList\nThe dynamically created list with the specified number of fields.', 'Output Parser': 'This component transforms the output of a language model into a specified format. It supports CSV format parsing, which converts LLM responses into comma-separated lists using Langchain\'s `CommaSeparatedListOutputParser`.\n:::note\nThis component only provides formatting instructions and parsing functionality. It does not include a prompt. You\'ll need to connect it to a separate Prompt component to create the actual prompt template for the LLM to use.\n:::\nBoth the **Output Parser** and **Structured Output** components format LLM responses, but they have different use cases.\nThe **Output Parser** is simpler and focused on converting responses into comma-separated lists. Use this when you just need a list of items, for example `["item1", "item2", "item3"]`.\nThe **Structured Output** is more complex and flexible, and allows you to define custom schemas with multiple fields of different types. Use this when you need to extract structured data with specific fields and types.\nTo use this component:\nCreate a Prompt component and connect the Output Parser\'s `format_instructions` output to it. This ensures the LLM knows how to format its response.\nWrite your actual prompt text in the Prompt component, including the `{format_instructions}` variable.\nFor example, in your Prompt component, the template might look like:\nConnect the `output_parser` output to your LLM model.\nThe output parser converts this into a Python list: `["apple", "banana", "orange"]`.\n**Inputs**\nName\nType\nDescription\nparser_type\nString\nThe parser type. Currently supports "CSV".\n**Outputs**\nName\nType\nDescription\nformat_instructions\nString\nPass to a prompt template to include formatting instructions for LLM responses.\noutput_parser\nParser\nThe constructed output parser that can be used to parse LLM responses.'}
{'title: Data\nslug: /components-data': 'import Icon from "@site/src/components/icon";', 'Data components in Langflow': 'Data components load data from a source into your flow.\nThey may perform some processing or type checking, like converting raw HTML data into text, or ensuring your loaded file is of an acceptable type.', 'Use a data component in a flow': 'The **URL** data component loads content from a list of URLs.\nIn the component\'s **URLs** field, enter the URL you want to load. To add multiple URL fields, click <Icon name="Plus" aria-label="Add"/>.\nAlternatively, connect a component that outputs the `Message` type, like the **Chat Input** component, to supply your URLs from a component.\nIn this example of a document ingestion pipeline, the URL component outputs raw HTML to a text splitter, which splits the raw content into chunks for a vector database to ingest.\n![URL component in a data ingestion pipeline](/img/url-component.png)', 'API Request': "This component makes HTTP requests using URLs or cURL commands.\nTo use this component in a flow, connect the **Data** output to a component that accepts the input.\nFor example, connect the **API Request** component to a **Chat Output** component.\n![API request into a chat output component](/img/component-api-request-chat-output.png)\nIn the API component's **URLs** field, enter the endpoint for your request.\nThis example uses `https://dummy-json.mock.beeceptor.com/posts`, which is a list of technology blog posts.\nIn the **Method** field, enter the type of request.\nThis example uses GET to retrieve a list of blog posts.\nThe component also supports POST, PATCH, PUT, and DELETE.\nOptionally, enable the **Use cURL** button to create a field for pasting curl requests.\nThe equivalent call in this example is `curl -v https://dummy-json.mock.beeceptor.com/posts`.\nClick **Playground**, and then click **Run Flow**.\nYour request returns a list of blog posts in the `result` field.\n**Inputs**\nName\nDisplay Name\nInfo\nurls\nURLs\nEnter one or more URLs, separated by commas.\ncurl\ncURL\nPaste a curl command to populate the dictionary fields for headers and body.\nmethod\nMethod\nThe HTTP method to use.\nuse_curl\nUse cURL\nEnable cURL mode to populate fields from a cURL command.\nquery_params\nQuery Parameters\nThe query parameters to append to the URL.\nbody\nBody\nThe body to send with the request as a dictionary (for `POST`, `PATCH`, `PUT`).\nheaders\nHeaders\nThe headers to send with the request as a dictionary.\ntimeout\nTimeout\nThe timeout to use for the request.\nfollow_redirects\nFollow Redirects\nWhether to follow http redirects.\nsave_to_file\nSave to File\nSave the API response to a temporary file.\ninclude_httpx_metadata\nInclude HTTPx Metadata\nInclude properties such as `headers`, `status_code`, `response_headers`, and `redirection_history` in the output.\n**Outputs**\nName\nDisplay Name\nInfo\ndata\nData\nThe result of the API requests. Returns a Data object containing source URL and results.\ndataframe\nDataFrame\nConverts the API response data into a tabular DataFrame format.", 'Directory': 'This component recursively loads files from a directory, with options for file types, depth, and concurrency.\n**Inputs**\nInput\nType\nDescription\npath\nMessageTextInput\nThe path to the directory to load files from.\ntypes\nMessageTextInput\nThe file types to load (leave empty to load all types).\ndepth\nIntInput\nThe depth to search for files.\nmax_concurrency\nIntInput\nThe maximum concurrency for loading files.\nload_hidden\nBoolInput\nIf true, hidden files are loaded.\nrecursive\nBoolInput\nIf true, the search is recursive.\nsilent_errors\nBoolInput\nIf true, errors do not raise an exception.\nuse_multithreading\nBoolInput\nIf true, multithreading is used.\n**Outputs**\nOutput\nType\nDescription\ndata\nList[Data]\nThe loaded file data from the directory.\ndataframe\nDataFrame\nThe loaded file data in tabular DataFrame format.', 'File': "This component loads and parses files of various supported formats and converts the content into a [Data](/concepts-objects) object. It supports multiple file types and provides options for parallel processing and error handling.\nTo load a document, follow these steps:\nClick the **Select files** button.\nSelect a local file or a file loaded with [File management](/concepts-file-management), and then click **Select file**.\nThe loaded file name appears in the component.\nThe default maximum supported file size is 100 MB.\nTo modify this value, see [--max-file-size-upload](/environment-variables#LANGFLOW_MAX_FILE_SIZE_UPLOAD).\n**Inputs**\nName\nDisplay Name\nInfo\npath\nFiles\nThe path to files to load. Supports individual files or bundled archives.\nfile_path\nServer File Path\nA Data object with a `file_path` property pointing to the server file or a Message object with a path to the file. Supersedes 'Path' but supports the same file types.\nseparator\nSeparator\nThe separator to use between multiple outputs in Message format.\nsilent_errors\nSilent Errors\nIf true, errors do not raise an exception.\ndelete_server_file_after_processing\nDelete Server File After Processing\nIf true, the Server File Path is deleted after processing.\nignore_unsupported_extensions\nIgnore Unsupported Extensions\nIf true, files with unsupported extensions are not processed.\nignore_unspecified_files\nIgnore Unspecified Files\nIf true, `Data` with no `file_path` property is ignored.\nuse_multithreading\n[Deprecated] Use Multithreading\nSet 'Processing Concurrency' greater than `1` to enable multithreading. This option is deprecated.\nconcurrency_multithreading\nProcessing Concurrency\nWhen multiple files are being processed, the number of files to process concurrently. Default is 1. Values greater than 1 enable parallel processing for 2 or more files.\n**Outputs**\nName\nDisplay Name\nInfo\ndata\nData\nThe parsed content of the file as a [Data](/concepts-objects) object.\ndataframe\nDataFrame\nThe file content as a [DataFrame](/concepts-objects#dataframe-object) object.\nmessage\nMessage\nThe file content as a [Message](/concepts-objects#message-object) object.", 'Supported File Types': 'Text files:\n`.txt` - Text files\n`.md`, `.mdx` - Markdown files\n`.csv` - CSV files\n`.json` - JSON files\n`.yaml`, `.yml` - YAML files\n`.xml` - XML files\n`.html`, `.htm` - HTML files\n`.pdf` - PDF files\n`.docx` - Word documents\n`.py` - Python files\n`.sh` - Shell scripts\n`.sql` - SQL files\n`.js` - JavaScript files\n`.ts`, `.tsx` - TypeScript files\nArchive formats (for bundling multiple files):\n`.zip` - ZIP archives\n`.tar` - TAR archives\n`.tgz` - Gzipped TAR archives\n`.bz2` - Bzip2 compressed files\n`.gz` - Gzip compressed files', 'SQL Query': 'This component executes SQL queries on a specified database.\n**Inputs**\nName\nDisplay Name\nInfo\nquery\nQuery\nThe SQL query to execute.\ndatabase_url\nDatabase URL\nThe URL of the database.\ninclude_columns\nInclude Columns\nInclude columns in the result.\npassthrough\nPassthrough\nIf an error occurs, return the query instead of raising an exception.\nadd_error\nAdd Error\nAdd the error to the result.\n**Outputs**\nName\nDisplay Name\nInfo\nresult\nResult\nThe result of the SQL query execution.', 'URL': 'This component fetches content from one or more URLs, processes the content, and returns it in various formats. It supports output in plain text or raw HTML.\nIn the component\'s **URLs** field, enter the URL you want to load. To add multiple URL fields, click <Icon name="Plus" aria-label="Add"/>.\nTo use this component in a flow, connect the **DataFrame** output to a component that accepts the input.\nFor example, connect the **URL** component to a **Chat Output** component.\n![URL request into a chat output component](/img/component-url.png)\nIn the URL component\'s **URLs** field, enter the URL for your request.\nThis example uses `langflow.org`.\nOptionally, in the **Max Depth** field, enter how many pages away from the initial URL you want to crawl.\nSelect `1` to crawl only the page specified in the **URLs** field.\nSelect `2` to crawl all pages linked from that page.\nThe component crawls by link traversal, not by URL path depth.\nClick **Playground**, and then click **Run Flow**.\nThe text contents of the URL are returned to the Playground as a structured DataFrame.\nIn the **URL** component, change the output port to **Message**, and then run the flow again.\nThe text contents of the URL are returned as unstructured raw text, which you can extract patterns from with the **Regex Extractor** tool.\nConnect the **URL** component to a **Regex Extractor** and **Chat Output**.\n![Regex extractor connected to url component](/img/component-url-regex.png)\nIn the **Regex Extractor** tool, enter a pattern to extract text from the **URL** component\'s raw output.\nThis example extracts the first paragraph from the "In the News" section of `https://en.wikipedia.org/wiki/Main_Page`.\nResult:\n**Inputs**\nName\nDisplay Name\nInfo\nurls\nURLs\nClick the \'+\' button to enter one or more URLs to crawl recursively.\nmax_depth\nMax Depth\nControls how many \'clicks\' away from the initial page the crawler will go.\nprevent_outside\nPrevent Outside\nIf enabled, only crawls URLs within the same domain as the root URL.\nuse_async\nUse Async\nIf enabled, uses asynchronous loading which can be significantly faster but might use more system resources.\nformat\nOutput Format\nOutput Format. Use `Text` to extract the text from the HTML or `HTML` for the raw HTML content.\ntimeout\nTimeout\nTimeout for the request in seconds.\nheaders\nHeaders\nThe headers to send with the request.\n**Outputs**\nName\nDisplay Name\nInfo\ndata\nData\nA list of [Data](/concepts-objects) objects containing fetched content and metadata.\ntext\nMessage\nThe fetched content as formatted text.\ndataframe\nDataFrame\nThe content formatted as a [DataFrame](/concepts-objects#dataframe-object) object.', 'Webhook': "This component defines a webhook trigger that runs a flow when it receives an HTTP POST request.\nIf the input is not valid JSON, the component wraps it in a `payload` object so that it can be processed and still trigger the flow. The component does not require an API key.\nWhen a **Webhook** component is added to the workspace, a new **Webhook cURL** tab becomes available in the **API** pane that contains an HTTP POST request for triggering the webhook component. For example:\nTo test the webhook component:\nAdd a **Webhook** component to the flow.\nConnect the **Webhook** component's **Data** output to the **Data** input of a [Parser](/components-processing#parser) component.\nConnect the **Parser** component's **Parsed Text** output to the **Text** input of a [Chat Output](/components-io#chat-output) component.\nIn the **Parser** component, under **Mode**, select **Stringify**.\nThis mode passes the webhook's data as a string for the **Chat Output** component to print.\nTo send a POST request, copy the code from the **Webhook cURL** tab in the **API** pane and paste it into a terminal.\nSend the POST request.\nOpen the **Playground**.\nYour JSON data is posted to the **Chat Output** component, which indicates that the webhook component is correctly triggering the flow.\n**Inputs**\nName\nDisplay Name\nDescription\ndata\nPayload\nReceives a payload from external systems through HTTP POST requests.\ncurl\ncURL\nThe cURL command template for making requests to this webhook.\nendpoint\nEndpoint\nThe endpoint URL where this webhook receives requests.\n**Outputs**\nName\nDisplay Name\nDescription\noutput_data\nData\nOutputs processed data from the webhook input, and returns an empty [Data](/concepts-objects) object if no input is provided. If the input is not valid JSON, the component wraps it in a `payload` object.", 'Legacy components': 'Legacy components are available for use but are no longer supported.', 'Gmail Loader': 'This component loads emails from Gmail using provided credentials and filters.\nFor more information about creating a service account JSON, see [Service Account JSON](https://developers.google.com/identity/protocols/oauth2/service-account).\n**Inputs**\nInput\nType\nDescription\njson_string\nSecretStrInput\nA JSON string containing OAuth 2.0 access token information for service account access.\nlabel_ids\nMessageTextInput\nA comma-separated list of label IDs to filter emails.\nmax_results\nMessageTextInput\nThe maximum number of emails to load.\n**Outputs**\nOutput\nType\nDescription\ndata\nData\nThe loaded email data.', 'Google Drive Loader': 'This component loads documents from Google Drive using provided credentials and a single document ID.\nFor more information about creating a service account JSON, see [Service Account JSON](https://developers.google.com/identity/protocols/oauth2/service-account).\n**Inputs**\nInput\nType\nDescription\njson_string\nSecretStrInput\nA JSON string containing OAuth 2.0 access token information for service account access.\ndocument_id\nMessageTextInput\nA single Google Drive document ID.\n**Outputs**\nOutput\nType\nDescription\ndocs\nData\nThe loaded document data.', 'Google Drive Search': 'This component searches Google Drive files using provided credentials and query parameters.\nFor more information about creating a service account JSON, see [Service Account JSON](https://developers.google.com/identity/protocols/oauth2/service-account).\n**Inputs**\nInput\nType\nDescription\ntoken_string\nSecretStrInput\nA JSON string containing OAuth 2.0 access token information for service account access.\nquery_item\nDropdownInput\nThe field to query.\nvalid_operator\nDropdownInput\nThe operator to use in the query.\nsearch_term\nMessageTextInput\nThe value to search for in the specified query item.\nquery_string\nMessageTextInput\nThe query string used for searching.\n**Outputs**\nOutput\nType\nDescription\ndoc_urls\nList[str]\nThe URLs of the found documents.\ndoc_ids\nList[str]\nThe IDs of the found documents.\ndoc_titles\nList[str]\nThe titles of the found documents.\nData\nData\nThe document titles and URLs in a structured format.'}
{'title: Vector stores\nslug: /components-vector-stores': 'import Icon from "@site/src/components/icon";', 'Vector store components in Langflow': 'Vector databases store vector data, which backs AI workloads like chatbots and Retrieval Augmented Generation.\nVector database components establish connections to existing vector databases or create in-memory vector stores for storing and retrieving vector data.\nVector database components are distinct from [memory components](/components-memories), which are built specifically for storing and retrieving chat messages from external databases.', 'Use a vector store component in a flow': "This example uses the **Astra DB vector store** component. Your vector store component's parameters and authentication may be different, but the document ingestion workflow is the same. A document is loaded from a local machine and chunked. The Astra DB vector store generates embeddings with the connected [model](/components-models) component, and stores them in the connected Astra DB database.\nThis vector data can then be retrieved for workloads like Retrieval Augmented Generation.\n![](/img/vector-store-retrieval.png)\nThe user's chat input is embedded and compared to the vectors embedded during document ingestion for a similarity search.\nThe results are output from the vector database component as a [Data](/concepts-objects) object and parsed into text.\nThis text fills the `{context}` variable in the **Prompt** component, which informs the **Open AI model** component's responses.\nAlternatively, connect the vector database component's **Retriever** port to a [retriever tool](components-tools#retriever-tool), and then to an [agent](/components-agents) component. This enables the agent to use your vector database as a tool and make decisions based on the available data.\n![](/img/vector-store-agent-retrieval-tool.png)", 'Astra DB Vector Store': 'This component implements a Vector Store using Astra DB with search capabilities.\nFor more information, see the [DataStax documentation](https://docs.datastax.com/en/astra-db-serverless/databases/create-database.html).\n**Inputs**\nName\nDisplay Name\nInfo\ntoken\nAstra DB Application Token\nThe authentication token for accessing Astra DB.\nenvironment\nEnvironment\nThe environment for the Astra DB API Endpoint. For example, `dev` or `prod`.\ndatabase_name\nDatabase\nThe database name for the Astra DB instance.\napi_endpoint\nAstra DB API Endpoint\nThe API endpoint for the Astra DB instance. This supersedes the database selection.\ncollection_name\nCollection\nThe name of the collection within Astra DB where the vectors are stored.\nkeyspace\nKeyspace\nAn optional keyspace within Astra DB to use for the collection.\nembedding_choice\nEmbedding Model or Astra Vectorize\nChoose an embedding model or use Astra vectorize.\nembedding_model\nEmbedding Model\nSpecify the embedding model. Not required for Astra vectorize collections.\nnumber_of_results\nNumber of Search Results\nThe number of search results to return. Default:`4`.\nsearch_type\nSearch Type\nThe search type to use. The options are `Similarity`, `Similarity with score threshold`, and `MMR (Max Marginal Relevance)`.\nsearch_score_threshold\nSearch Score Threshold\nThe minimum similarity score threshold for search results when using the `Similarity with score threshold` option.\nadvanced_search_filter\nSearch Metadata Filter\nAn optional dictionary of filters to apply to the search query.\nautodetect_collection\nAutodetect Collection\nA boolean flag to determine whether to autodetect the collection.\ncontent_field\nContent Field\nA field to use as the text content field for the vector store.\ndeletion_field\nDeletion Based On Field\nWhen provided, documents in the target collection with metadata field values matching the input metadata field value are deleted before new data is loaded.\nignore_invalid_documents\nIgnore Invalid Documents\nA boolean flag to determine whether to ignore invalid documents at runtime.\nastradb_vectorstore_kwargs\nAstraDBVectorStore Parameters\nAn optional dictionary of additional parameters for the AstraDBVectorStore.\n**Outputs**\nName\nDisplay Name\nInfo\nvector_store\nVector Store\nThe Astra DB vector store instance configured with the specified parameters.\nsearch_results\nSearch Results\nThe results of the similarity search as a list of [Data](/concepts-objects#data-object) objects.', 'Generate embeddings': "The **Astra DB Vector Store** component offers two methods for generating embeddings.\n**Embedding Model**: Use your own embedding model by connecting an [Embeddings](/components-embedding-models) component in Langflow.\n**Astra Vectorize**: Use Astra DB's built-in embedding generation service. When creating a new collection, choose the embeddings provider and models, including NVIDIA's `NV-Embed-QA` model hosted by Datastax.\n:::important\nThe embedding model selection is made when creating a new collection and cannot be changed later.\n:::\nFor an example of using the **Astra DB Vector Store** component with an embedding model, see the [Vector Store RAG starter project](/starter-projects-vector-store-rag).\nFor more information, see the [Astra DB Serverless documentation](https://docs.datastax.com/en/astra-db-serverless/databases/embedding-generation.html).", 'Hybrid search': 'The **Astra DB** component includes **hybrid search**, which is enabled by default.\nThe component fields related to hybrid search are **Search Query**, **Lexical Terms**, and **Reranker**.\n**Search Query** finds results by vector similarity.\n**Lexical Terms** is a comma-separated string of keywords, like `features, data, attributes, characteristics`.\n**Reranker** is the re-ranker model used in the hybrid search.\nThe re-ranker model is `nvidia/llama-3.2-nv.reranker`.\n[Hybrid search](https://docs.datastax.com/en/astra-db-serverless/databases/hybrid-search.html) performs a vector similarity search and a lexical search, compares the results of both searches, and then returns the most relevant results overall.\n:::important\nTo use hybrid search, your collection must be created with vector, lexical, and rerank capabilities enabled. These capabilities are enabled by default when you create a collection in a database in the AWS us-east-2 region.\nFor more information, see the [DataStax documentation](https://docs.datastax.com/en/astra-db-serverless/api-reference/collection-methods/create-collection.html#example-hybrid).\n:::\nTo use **Hybrid search** in the **Astra DB** component, do the following:\nClick **New Flow** > **RAG** > **Hybrid Search RAG**.\nIn the **OpenAI** model component, add your **OpenAI API key**.\nIn the **Astra DB** vector store component, add your **Astra DB Application Token**.\nIn the **Database** field, select your database.\nIn the **Collection** field, select or create a collection with hybrid search capabilities enabled.\nIn the **Playground**, enter a question about your data, such as `What are the features of my data?`\nYour query is sent to two components: an **OpenAI** model component and the **Astra DB** vector database component.\nThe **OpenAI** component contains a prompt for creating the lexical query from your input:\nTo view the keywords and questions the **OpenAI** component generates from your collection, in the **OpenAI** component, click <Icon name="TextSearch" aria-label="Inspect icon" />.\nTo view the [DataFrame](/concepts-objects#dataframe-object) generated from the **OpenAI** component\'s response, in the **Structured Output** component, click <Icon name="TextSearch" aria-label="Inspect icon" />.\nThe DataFrame is passed to a **Parser** component, which parses the contents of the **Keywords** column into a string.\nThis string of comma-separated words is passed to the **Lexical Terms** port of the **Astra DB** component.\n Note that the **Search Query** port of the Astra DB port is connected to the **Chat Input** component from step 6.\n This **Search Query** is vectorized, and both the **Search Query** and **Lexical Terms** content are sent to the reranker at the `find_and_rerank` endpoint.\nThe reranker compares the vector search results against the string of terms from the lexical search.\n The highest-ranked results of your hybrid search are returned to the **Playground**.\nFor more information, see the [DataStax documentation](https://docs.datastax.com/en/astra-db-serverless/databases/hybrid-search.html).', 'AstraDB Graph vector store': 'This component implements a Vector Store using AstraDB with graph capabilities.\nFor more information, see the [Astra DB Serverless documentation](https://docs.datastax.com/en/astra-db-serverless/tutorials/graph-rag.html).\n**Inputs**\nName\nDisplay Name\nInfo\ncollection_name\nCollection Name\nThe name of the collection within AstraDB where the vectors are stored. Required.\ntoken\nAstra DB Application Token\nAuthentication token for accessing AstraDB. Required.\napi_endpoint\nAPI Endpoint\nAPI endpoint URL for the AstraDB service. Required.\nsearch_input\nSearch Input\nQuery string for similarity search.\ningest_data\nIngest Data\nData to be ingested into the vector store.\nnamespace\nNamespace\nOptional namespace within AstraDB to use for the collection.\nembedding\nEmbedding Model\nEmbedding model to use.\nmetric\nMetric\nDistance metric for vector comparisons. The options are "cosine", "euclidean", "dot_product".\nsetup_mode\nSetup Mode\nConfiguration mode for setting up the vector store. The options are "Sync", "Async", "Off".\npre_delete_collection\nPre Delete Collection\nBoolean flag to determine whether to delete the collection before creating a new one.\nnumber_of_results\nNumber of Results\nNumber of results to return in similarity search. Default: 4.\nsearch_type\nSearch Type\nSearch type to use. The options are "Similarity", "Graph Traversal", "Hybrid".\ntraversal_depth\nTraversal Depth\nMaximum depth for graph traversal searches. Default: 1.\nsearch_score_threshold\nSearch Score Threshold\nMinimum similarity score threshold for search results.\nsearch_filter\nSearch Metadata Filter\nOptional dictionary of filters to apply to the search query.\n**Outputs**\nName\nDisplay Name\nInfo\nvector_store\nVector Store\nThe Graph RAG vector store instance configured with the specified parameters.\nsearch_results\nSearch Results\nThe results of the similarity search as a list of [Data](/concepts-objects#data-object) objects.', 'Cassandra': 'This component creates a Cassandra Vector Store with search capabilities.\nFor more information, see the [Cassandra documentation](https://cassandra.apache.org/doc/latest/cassandra/vector-search/overview.html).\n**Inputs**\nName\nType\nDescription\ndatabase_ref\nString\nContact points for the database or AstraDB database ID.\nusername\nString\nUsername for the database (leave empty for AstraDB).\ntoken\nSecretString\nUser password for the database or AstraDB token.\nkeyspace\nString\nTable Keyspace or AstraDB namespace.\ntable_name\nString\nName of the table or AstraDB collection.\nttl_seconds\nInteger\nTime-to-live for added texts.\nbatch_size\nInteger\nNumber of data to process in a single batch.\nsetup_mode\nString\nConfiguration mode for setting up the Cassandra table.\ncluster_kwargs\nDict\nAdditional keyword arguments for the Cassandra cluster.\nsearch_query\nString\nQuery for similarity search.\ningest_data\nData\nData to be ingested into the vector store.\nembedding\nEmbeddings\nEmbedding function to use.\nnumber_of_results\nInteger\nNumber of results to return in search.\nsearch_type\nString\nType of search to perform.\nsearch_score_threshold\nFloat\nMinimum similarity score for search results.\nsearch_filter\nDict\nMetadata filters for search query.\nbody_search\nString\nDocument textual search terms.\nenable_body_search\nBoolean\nFlag to enable body search.\n**Outputs**\nName\nType\nDescription\nvector_store\nCassandra\nThe Cassandra vector store instance configured with the specified parameters.\nsearch_results\nList[Data]\nThe results of the similarity search as a list of `Data` objects.', 'Cassandra Graph Vector Store': 'This component implements a Cassandra Graph Vector Store with search capabilities.\n**Inputs**\nName\nDisplay Name\nInfo\ndatabase_ref\nContact Points / Astra Database ID\nThe contact points for the database or AstraDB database ID. Required.\nusername\nUsername\nThe username for the database. Leave this field empty for AstraDB.\ntoken\nPassword / AstraDB Token\nThe user password for the database or AstraDB token. Required.\nkeyspace\nKeyspace\nThe table Keyspace or AstraDB namespace. Required.\ntable_name\nTable Name\nThe name of the table or AstraDB collection where vectors are stored. Required.\nsetup_mode\nSetup Mode\nThe configuration mode for setting up the Cassandra table. The options are "Sync" or "Off". Default: "Sync".\ncluster_kwargs\nCluster arguments\nAn optional dictionary of additional keyword arguments for the Cassandra cluster.\nsearch_query\nSearch Query\nThe query string for similarity search.\ningest_data\nIngest Data\nThe list of data to be ingested into the vector store.\nembedding\nEmbedding\nThe embedding model to use.\nnumber_of_results\nNumber of Results\nThe number of results to return in similarity search. Default: 4.\nsearch_type\nSearch Type\nThe search type to use. The options are "Traversal", "MMR traversal", "Similarity", "Similarity with score threshold", or "MMR (Max Marginal Relevance)". Default: "Traversal".\ndepth\nDepth of traversal\nThe maximum depth of edges to traverse. Used for "Traversal" or "MMR traversal" search types. Default: 1.\nsearch_score_threshold\nSearch Score Threshold\nThe minimum similarity score threshold for search results. Used for "Similarity with score threshold" search types.\nsearch_filter\nSearch Metadata Filter\nAn optional dictionary of filters to apply to the search query.\n**Outputs**\nName\nDisplay Name\nInfo\nvector_store\nVector Store\nThe Cassandra Graph vector store instance configured with the specified parameters.\nsearch_results\nSearch Results\nThe results of the similarity search as a list of [Data](/concepts-objects#data-object) objects.', 'Chroma DB': 'This component creates a Chroma Vector Store with search capabilities.\nThe Chroma DB component creates an ephemeral vector database for experimentation and vector storage.\nTo use this component in a flow, connect it to a component that outputs **Data** or **DataFrame**.\nThis example splits text from a [URL](/components-data#url) component, and computes embeddings with the connected **OpenAI Embeddings** component. Chroma DB computes embeddings by default, but you can connect your own embeddings model, as seen in this example.\n![ChromaDB receiving split text](/img/component-chroma-db.png)\nIn the **Chroma DB** component, in the **Collection** field, enter a name for your embeddings collection.\nOptionally, to persist the Chroma database, in the **Persist** field, enter a directory to store the `chroma.sqlite3` file.\nThis example uses `./chroma-db` to create a directory relative to where Langflow is running.\nTo load data and embeddings into your Chroma database, in the **Chroma DB** component, click <Icon name="Play" aria-label="Play icon" />.\n:::tip\nWhen loading duplicate documents, enable the **Allow Duplicates** option in Chroma DB if you want to store multiple copies of the same content, or disable it to automatically deduplicate your data.\n:::\nTo view the split data, in the **Split Text** component, click <Icon name="TextSearch" aria-label="Inspect icon" />.\nTo query your loaded data, open the **Playground** and query your database.\nYour input is converted to vector data and compared to the stored vectors in a vector similarity search.\nFor more information, see the [Chroma documentation](https://docs.trychroma.com/).\n**Inputs**\nName\nType\nDescription\ncollection_name\nString\nThe name of the Chroma collection. Default: "langflow".\npersist_directory\nString\nThe directory to persist the Chroma database.\nsearch_query\nString\nThe query to search for in the vector store.\ningest_data\nData\nThe data to ingest into the vector store (list of `Data` objects).\nembedding\nEmbeddings\nThe embedding function to use for the vector store.\nchroma_server_cors_allow_origins\nString\nThe CORS allow origins for the Chroma server.\nchroma_server_host\nString\nThe host for the Chroma server.\nchroma_server_http_port\nInteger\nThe HTTP port for the Chroma server.\nchroma_server_grpc_port\nInteger\nThe gRPC port for the Chroma server.\nchroma_server_ssl_enabled\nBoolean\nEnable SSL for the Chroma server.\nallow_duplicates\nBoolean\nAllow duplicate documents in the vector store.\nsearch_type\nString\nThe type of search to perform: "Similarity" or "MMR".\nnumber_of_results\nInteger\nThe number of results to return from the search. Default: `10`.\nlimit\nInteger\nThe limit of the number of records to compare when `Allow Duplicates` is `False`.\n**Outputs**\nName\nType\nDescription\nvector_store\nChroma\nThe Chroma vector store instance.\nsearch_results\nList[Data]\nThe results of the similarity search as a list of [Data](/concepts-objects#data-object) objects.', 'Clickhouse': 'This component implements a Clickhouse Vector Store with search capabilities.\nFor more information, see the [Clickhouse Documentation](https://clickhouse.com/docs/en/intro).\n**Inputs**\nName\nDisplay Name\nInfo\nhost\nhostname\nThe Clickhouse server hostname. Required. Default: "localhost".\nport\nport\nThe Clickhouse server port. Required. Default: 8123.\ndatabase\ndatabase\nThe Clickhouse database name. Required.\ntable\nTable name\nThe Clickhouse table name. Required.\nusername\nThe ClickHouse user name.\nUsername for authentication. Required.\npassword\nThe password for username.\nPassword for authentication. Required.\nindex_type\nindex_type\nType of the index. The options are "annoy" and "vector_similarity". Default: "annoy".\nmetric\nmetric\nMetric to compute distance. The options are "angular", "euclidean", "manhattan", "hamming", "dot". Default: "angular".\nsecure\nUse https/TLS\nOverrides inferred values from the interface or port arguments. Default: false.\nindex_param\nParam of the index\nIndex parameters. Default: "\'L2Distance\',100".\nindex_query_params\nindex query params\nAdditional index query parameters.\nsearch_query\nSearch Query\nThe query string for similarity search.\ningest_data\nIngest Data\nThe data to be ingested into the vector store.\nembedding\nEmbedding\nThe embedding model to use.\nnumber_of_results\nNumber of Results\nThe number of results to return in similarity search. Default: 4.\nscore_threshold\nScore threshold\nThe threshold for similarity scores.\n**Outputs**\nName\nDisplay Name\nInfo\nvector_store\nVector Store\nThe Clickhouse vector store.\nsearch_results\nSearch Results\nThe results of the similarity search as a list of Data objects.', 'Couchbase': 'This component creates a Couchbase Vector Store with search capabilities.\nFor more information, see the [Couchbase documentation](https://docs.couchbase.com/home/index.html).\n**Inputs**\nName\nType\nDescription\ncouchbase_connection_string\nSecretString\nCouchbase Cluster connection string. Required.\ncouchbase_username\nString\nCouchbase username. Required.\ncouchbase_password\nSecretString\nCouchbase password. Required.\nbucket_name\nString\nName of the Couchbase bucket. Required.\nscope_name\nString\nName of the Couchbase scope. Required.\ncollection_name\nString\nName of the Couchbase collection. Required.\nindex_name\nString\nName of the Couchbase index. Required.\nsearch_query\nString\nThe query to search for in the vector store.\ningest_data\nData\nThe list of data to ingest into the vector store.\nembedding\nEmbeddings\nThe embedding function to use for the vector store.\nnumber_of_results\nInteger\nNumber of results to return from the search. Default: 4.\n**Outputs**\nName\nType\nDescription\nvector_store\nCouchbaseVectorStore\nA Couchbase vector store instance configured with the specified parameters.', 'Local DB': 'The **Local DB** component is Langflow\'s enhanced version of Chroma DB.\nThe component adds a user-friendly interface with two modes (Ingest and Retrieve), automatic collection management, and built-in persistence in Langflow\'s cache directory.\nLocal DB includes **Ingest** and **Retrieve** modes.\nThe **Ingest** mode works similarly to [ChromaDB](#chroma-db), and persists your database to the Langflow cache directory. The Langflow cache directory location is specified in `LANGFLOW_CONFIG_DIR`. For more information, see [Environment variables](/environment-variables).\nThe **Retrieve** mode can query your **Chroma DB** collections.\n![Local DB retrieving vectors](/img/component-local-db.png)\nFor more information, see the [Chroma documentation](https://docs.trychroma.com/).\n**Inputs**\nName\nType\nDescription\ncollection_name\nString\nThe name of the Chroma collection. Default: "langflow".\npersist_directory\nString\nCustom base directory to save the vector store. Collections are stored under `{directory}/vector_stores/{collection_name}`. If not specified, it will use your system\'s cache folder.\nexisting_collections\nString\nSelect a previously created collection to search through its stored data.\nembedding\nEmbeddings\nThe embedding function to use for the vector store.\nallow_duplicates\nBoolean\nIf false, will not add documents that are already in the Vector Store.\nsearch_type\nString\nType of search to perform: "Similarity" or "MMR".\ningest_data\nData/DataFrame\nData to store. It is embedded and indexed for semantic search.\nsearch_query\nString\nEnter text to search for similar content in the selected collection.\nnumber_of_results\nInteger\nNumber of results to return. Default: 10.\nlimit\nInteger\nLimit the number of records to compare when Allow Duplicates is False.\n**Outputs**\nName\nType\nDescription\nvector_store\nChroma\nA local Chroma vector store instance configured with the specified parameters.\nsearch_results\nList[Data](/concepts-objects#data-object)\nThe results of the similarity search as a list of [Data](/concepts-objects#data-object) objects.', 'Elasticsearch': 'This component creates an Elasticsearch Vector Store with search capabilities.\nFor more information, see the [Elasticsearch documentation](https://www.elastic.co/guide/en/elasticsearch/reference/current/dense-vector.html).\n**Inputs**\nName\nType\nDescription\nes_url\nString\nElasticsearch server URL.\nes_user\nString\nUsername for Elasticsearch authentication.\nes_password\nSecretString\nPassword for Elasticsearch authentication.\nindex_name\nString\nName of the Elasticsearch index.\nstrategy\nString\nStrategy for vector search. The options are "approximate_k_nearest_neighbors" or "script_scoring".\ndistance_strategy\nString\nStrategy for distance calculation. The options are "COSINE", "EUCLIDEAN_DISTANCE", or "DOT_PRODUCT".\nsearch_query\nString\nQuery for similarity search.\ningest_data\nData\nData to be ingested into the vector store.\nembedding\nEmbeddings\nEmbedding function to use.\nnumber_of_results\nInteger\nNumber of results to return in search. Default: `4`.\n**Outputs**\nName\nType\nDescription\nvector_store\nElasticsearchStore\nThe Elasticsearch vector store instance.\nsearch_results\nList[Data]\nThe results of the similarity search as a list of [Data](/concepts-objects#data-object) objects.', 'FAISS': 'This component creates a FAISS Vector Store with search capabilities.\nFor more information, see the [FAISS documentation](https://faiss.ai/index.html).\n**Inputs**\nName\nType\nDescription\nindex_name\nString\nThe name of the FAISS index. Default: "langflow_index".\npersist_directory\nString\nPath to save the FAISS index. It is relative to where Langflow is running.\nsearch_query\nString\nThe query to search for in the vector store.\ningest_data\nData\nThe list of data to ingest into the vector store.\nallow_dangerous_deserialization\nBoolean\nSet to True to allow loading pickle files from untrusted sources. Default: True.\nembedding\nEmbeddings\nThe embedding function to use for the vector store.\nnumber_of_results\nInteger\nNumber of results to return from the search. Default: 4.\n**Outputs**\nName\nDisplay Name\nInfo\nvector_store\nVector Store\nThe FAISS vector store instance configured with the specified parameters.\nsearch_results\nSearch Results\nThe results of the similarity search as a list of [Data](/concepts-objects#data-object) objects.', 'Graph RAG': 'This component performs Graph RAG (Retrieval Augmented Generation) traversal in a vector store, enabling graph-based document retrieval.\nFor more information, see the [Graph RAG documentation](https://datastax.github.io/graph-rag/).\nFor an example flow, see the **Graph RAG** template.\n**Inputs**\nName\nDisplay Name\nInfo\nembedding_model\nEmbedding Model\nSpecify the embedding model. This is not required for collections embedded with [Astra vectorize](https://docs.datastax.com/en/astra-db-serverless/databases/embedding-generation.html).\nvector_store\nVector Store Connection\nConnection to the vector store.\nedge_definition\nEdge Definition\nEdge definition for the graph traversal. For more information, see the [GraphRAG documentation](https://datastax.github.io/graph-rag/reference/graph_retriever/edges/).\nstrategy\nTraversal Strategies\nThe strategy to use for graph traversal. Strategy options are dynamically loaded from available strategies.\nsearch_query\nSearch Query\nThe query to search for in the vector store.\ngraphrag_strategy_kwargs\nStrategy Parameters\nOptional dictionary of additional parameters for the retrieval strategy. For more information, see the [strategy documentation](https://datastax.github.io/graph-rag/reference/graph_retriever/strategies/).\n**Outputs**\nName\nType\nDescription\nsearch_results\nList[Data]\nResults of the graph-based document retrieval as a list of [Data](/concepts-objects#data-object) objects.', 'Hyper-Converged Database (HCD)': 'This component implements a Vector Store using HCD.\nTo use the HCD vector store, add your deployment\'s collection name, username, password, and HCD Data API endpoint.\nThe endpoint must be formatted like `http[s]://**DOMAIN_NAME** or **IP_ADDRESS**[:port]`, for example, `http://192.0.2.250:8181`.\nReplace **DOMAIN_NAME** or **IP_ADDRESS** with the domain name or IP address of your HCD Data API connection.\nTo use the HCD vector store for embeddings ingestion, connect it to an embeddings model and a file loader:\n![HCD vector store embeddings ingestion](/img/component-hcd-example-flow.png)\n**Inputs**\nName\nDisplay Name\nInfo\ncollection_name\nCollection Name\nThe name of the collection within HCD where the vectors will be stored. Required.\nusername\nHCD Username\nAuthentication username for accessing HCD. Default is "hcd-superuser". Required.\npassword\nHCD Password\nAuthentication password for accessing HCD. Required.\napi_endpoint\nHCD API Endpoint\nAPI endpoint URL for the HCD service. Required.\nsearch_input\nSearch Input\nQuery string for similarity search.\ningest_data\nIngest Data\nData to be ingested into the vector store.\nnamespace\nNamespace\nOptional namespace within HCD to use for the collection. Default is "default_namespace".\nca_certificate\nCA Certificate\nOptional CA certificate for TLS connections to HCD.\nmetric\nMetric\nOptional distance metric for vector comparisons. Options are "cosine", "dot_product", "euclidean".\nbatch_size\nBatch Size\nOptional number of data to process in a single batch.\nbulk_insert_batch_concurrency\nBulk Insert Batch Concurrency\nOptional concurrency level for bulk insert operations.\nbulk_insert_overwrite_concurrency\nBulk Insert Overwrite Concurrency\nOptional concurrency level for bulk insert operations that overwrite existing data.\nbulk_delete_concurrency\nBulk Delete Concurrency\nOptional concurrency level for bulk delete operations.\nsetup_mode\nSetup Mode\nConfiguration mode for setting up the vector store. Options are "Sync", "Async", "Off". Default is "Sync".\npre_delete_collection\nPre Delete Collection\nBoolean flag to determine whether to delete the collection before creating a new one.\nmetadata_indexing_include\nMetadata Indexing Include\nOptional list of metadata fields to include in the indexing.\nembedding\nEmbedding or Astra Vectorize\nAllows either an embedding model or an Astra Vectorize configuration.\nmetadata_indexing_exclude\nMetadata Indexing Exclude\nOptional list of metadata fields to exclude from the indexing.\ncollection_indexing_policy\nCollection Indexing Policy\nOptional dictionary defining the indexing policy for the collection.\nnumber_of_results\nNumber of Results\nNumber of results to return in similarity search. Default is 4.\nsearch_type\nSearch Type\nSearch type to use. Options are "Similarity", "Similarity with score threshold", "MMR (Max Marginal Relevance)". Default is "Similarity".\nsearch_score_threshold\nSearch Score Threshold\nMinimum similarity score threshold for search results. Default is 0.\nsearch_filter\nSearch Metadata Filter\nOptional dictionary of filters to apply to the search query.\n**Outputs**\nName\nType\nDescription\nvector_store\nHyperConvergedDatabaseVectorStore\nThe HCD vector store instance.\nsearch_results\nList[Data]\nThe results of the similarity search as a list of [Data](/concepts-objects#data-object) objects.', 'Milvus': 'This component creates a Milvus Vector Store with search capabilities.\nFor more information, see the [Milvus documentation](https://milvus.io/docs).\n**Inputs**\nName\nType\nDescription\ncollection_name\nString\nName of the Milvus collection.\ncollection_description\nString\nDescription of the Milvus collection.\nuri\nString\nConnection URI for Milvus.\npassword\nSecretString\nPassword for Milvus.\nusername\nSecretString\nUsername for Milvus.\nbatch_size\nInteger\nNumber of data to process in a single batch.\nsearch_query\nString\nQuery for similarity search.\ningest_data\nData\nData to be ingested into the vector store.\nembedding\nEmbeddings\nEmbedding function to use.\nnumber_of_results\nInteger\nNumber of results to return in search.\nsearch_type\nString\nType of search to perform.\nsearch_score_threshold\nFloat\nMinimum similarity score for search results.\nsearch_filter\nDict\nMetadata filters for search query.\nsetup_mode\nString\nConfiguration mode for setting up the vector store.\nvector_dimensions\nInteger\nNumber of dimensions of the vectors.\npre_delete_collection\nBoolean\nWhether to delete the collection before creating a new one.\n**Outputs**\nName\nType\nDescription\nvector_store\nMilvus\nA Milvus vector store instance configured with the specified parameters.', 'MongoDB Atlas': 'This component creates a MongoDB Atlas Vector Store with search capabilities.\nFor more information, see the [MongoDB Atlas documentation](https://www.mongodb.com/docs/atlas/atlas-vector-search/tutorials/vector-search-quick-start/).\n**Inputs**\nName\nType\nDescription\nmongodb_atlas_cluster_uri\nSecretString\nThe connection URI for your MongoDB Atlas cluster. Required.\nenable_mtls\nBoolean\nEnable mutual TLS authentication. Default: false.\nmongodb_atlas_client_cert\nSecretString\nClient certificate combined with private key for mTLS authentication. Required if mTLS is enabled.\ndb_name\nString\nThe name of the database to use. Required.\ncollection_name\nString\nThe name of the collection to use. Required.\nindex_name\nString\nThe name of the Atlas Search index, it should be a Vector Search. Required.\ninsert_mode\nString\nHow to insert new documents into the collection. The options are "append" or "overwrite". Default: "append".\nembedding\nEmbeddings\nThe embedding model to use.\nnumber_of_results\nInteger\nNumber of results to return in similarity search. Default: 4.\nindex_field\nString\nThe field to index. Default: "embedding".\nfilter_field\nString\nThe field to filter the index.\nnumber_dimensions\nInteger\nEmbedding context length. Default: 1536.\nsimilarity\nString\nThe method used to measure similarity between vectors. The options are "cosine", "euclidean", or "dotProduct". Default: "cosine".\nquantization\nString\nQuantization reduces memory costs by converting 32-bit floats to smaller data types. The options are "scalar" or "binary".\n**Outputs**\nName\nType\nDescription\nvector_store\nMongoDBAtlasVectorSearch\nThe MongoDB Atlas vector store instance.\nsearch_results\nList[Data]\nThe results of the similarity search as a list of [Data](/concepts-objects#data-object) objects.', 'Opensearch': 'This component creates an Opensearch vector store with search capabilities\nFor more information, see [Opensearch documentation](https://opensearch.org/platform/search/vector-database.html).\n**Inputs**\nName\nType\nDescription\nopensearch_url\nString\nURL for OpenSearch cluster, such as `https://192.168.1.1:9200`.\nindex_name\nString\nThe index name where the vectors are stored in OpenSearch cluster.\nsearch_input\nString\nEnter a search query. Leave empty to retrieve all documents or if hybrid search is being used.\ningest_data\nData\nThe data to be ingested into the vector store.\nembedding\nEmbeddings\nThe embedding function to use.\nsearch_type\nString\nThe options are "similarity", "similarity_score_threshold", "mmr".\nnumber_of_results\nInteger\nThe number of results to return in search.\nsearch_score_threshold\nFloat\nThe minimum similarity score threshold for search results.\nusername\nString\nThe username for the opensource cluster.\npassword\nSecretString\nThe password for the opensource cluster.\nuse_ssl\nBoolean\nUse SSL.\nverify_certs\nBoolean\nVerify certificates.\nhybrid_search_query\nString\nProvide a custom hybrid search query in JSON format. This allows you to combine vector similarity and keyword matching.\n**Outputs**\nName\nType\nDescription\nvector_store\nOpenSearchVectorSearch\nOpenSearch vector store instance\nsearch_results\nList[Data]\nThe results of the similarity search as a list of [Data](/concepts-objects#data-object) objects.', 'PGVector': 'This component creates a PGVector Vector Store with search capabilities.\nFor more information, see the [PGVector documentation](https://github.com/pgvector/pgvector).\n**Inputs**\nName\nType\nDescription\npg_server_url\nSecretString\nThe PostgreSQL server connection string.\ncollection_name\nString\nThe table name for the vector store.\nsearch_query\nString\nThe query for similarity search.\ningest_data\nData\nThe data to be ingested into the vector store.\nembedding\nEmbeddings\nThe embedding function to use.\nnumber_of_results\nInteger\nThe number of results to return in search.\n**Outputs**\nName\nDisplay Name\nInfo\nvector_store\nVector Store\nThe PGVector vector store instance configured with the specified parameters.\nsearch_results\nSearch Results\nThe results of the similarity search as a list of [Data](/concepts-objects#data-object) objects.', 'Pinecone': 'This component creates a Pinecone Vector Store with search capabilities.\nFor more information, see the [Pinecone documentation](https://docs.pinecone.io/home).\n**Inputs**\nName\nType\nDescription\nindex_name\nString\nThe name of the Pinecone index.\nnamespace\nString\nThe namespace for the index.\ndistance_strategy\nString\nThe strategy for calculating distance between vectors.\npinecone_api_key\nSecretString\nThe API key for Pinecone.\ntext_key\nString\nThe key in the record to use as text.\nsearch_query\nString\nThe query for similarity search.\ningest_data\nData\nThe data to be ingested into the vector store.\nembedding\nEmbeddings\nThe embedding function to use.\nnumber_of_results\nInteger\nThe number of results to return in search.\n**Outputs**\nName\nDisplay Name\nInfo\nvector_store\nVector Store\nThe Pinecone vector store instance configured with the specified parameters.\nsearch_results\nSearch Results\nThe results of the similarity search as a list of [Data](/concepts-objects#data-object) objects.', 'Qdrant': 'This component creates a Qdrant Vector Store with search capabilities.\nFor more information, see the [Qdrant documentation](https://qdrant.tech/documentation/).\n**Inputs**\nName\nType\nDescription\ncollection_name\nString\nThe name of the Qdrant collection.\nhost\nString\nThe Qdrant server host.\nport\nInteger\nThe Qdrant server port.\ngrpc_port\nInteger\nThe Qdrant gRPC port.\napi_key\nSecretString\nThe API key for Qdrant.\nprefix\nString\nThe prefix for Qdrant.\ntimeout\nInteger\nThe timeout for Qdrant operations.\npath\nString\nThe path for Qdrant.\nurl\nString\nThe URL for Qdrant.\ndistance_func\nString\nThe distance function for vector similarity.\ncontent_payload_key\nString\nThe content payload key.\nmetadata_payload_key\nString\nThe metadata payload key.\nsearch_query\nString\nThe query for similarity search.\ningest_data\nData\nThe data to be ingested into the vector store.\nembedding\nEmbeddings\nThe embedding function to use.\nnumber_of_results\nInteger\nThe number of results to return in search.\n**Outputs**\nName\nType\nDescription\nvector_store\nQdrant\nA Qdrant vector store instance.\nsearch_results\nList[Data]\nThe results of the similarity search as a list of [Data](/concepts-objects#data-object) objects.', 'Redis': 'This component creates a Redis Vector Store with search capabilities.\nFor more information, see the [Redis documentation](https://redis.io/docs/latest/develop/interact/search-and-query/advanced-concepts/vectors/).\n**Inputs**\nName\nType\nDescription\nredis_server_url\nSecretString\nThe Redis server connection string.\nredis_index_name\nString\nThe name of the Redis index.\ncode\nString\nThe custom code for Redis (advanced).\nschema\nString\nThe schema for Redis index.\nsearch_query\nString\nThe query for similarity search.\ningest_data\nData\nThe data to be ingested into the vector store.\nnumber_of_results\nInteger\nThe number of results to return in search.\nembedding\nEmbeddings\nThe embedding function to use.\n**Outputs**\nName\nType\nDescription\nvector_store\nRedis\nRedis vector store instance\nsearch_results\nList[Data]\nThe results of the similarity search as a list of [Data](/concepts-objects#data-object) objects.', 'Supabase': 'This component creates a connection to a Supabase Vector Store with search capabilities.\nFor more information, see the [Supabase documentation](https://supabase.com/docs/guides/ai).\n**Inputs**\nName\nType\nDescription\nsupabase_url\nString\nThe URL of the Supabase instance.\nsupabase_service_key\nSecretString\nThe service key for Supabase authentication.\ntable_name\nString\nThe name of the table in Supabase.\nquery_name\nString\nThe name of the query to use.\nsearch_query\nString\nThe query for similarity search.\ningest_data\nData\nThe data to be ingested into the vector store.\nembedding\nEmbeddings\nThe embedding function to use.\nnumber_of_results\nInteger\nThe number of results to return in search.\n**Outputs**\nName\nType\nDescription\nvector_store\nSupabaseVectorStore\nA Supabase vector store instance.\nsearch_results\nList[Data]\nThe results of the similarity search as a list of [Data](/concepts-objects#data-object) objects.', 'Upstash': 'This component creates an Upstash Vector Store with search capabilities.\nFor more information, see the [Upstash documentation](https://upstash.com/docs/introduction).\n**Inputs**\nName\nType\nDescription\nindex_url\nString\nThe URL of the Upstash index.\nindex_token\nSecretString\nThe token for the Upstash index.\ntext_key\nString\nThe key in the record to use as text.\nnamespace\nString\nThe namespace for the index.\nsearch_query\nString\nThe query for similarity search.\nmetadata_filter\nString\nFilter documents by metadata.\ningest_data\nData\nThe data to be ingested into the vector store.\nembedding\nEmbeddings\nThe embedding function to use.\nnumber_of_results\nInteger\nThe number of results to return in search.\n**Outputs**\nName\nType\nDescription\nvector_store\nUpstashVectorStore\nAn Upstash vector store instance.\nsearch_results\nList[Data]\nThe results of the similarity search as a list of [Data](/concepts-objects#data-object) objects.', 'Vectara': 'This component creates a Vectara Vector Store with search capabilities.\nFor more information, see the [Vectara documentation](https://docs.vectara.com/docs/).\n**Inputs**\nName\nType\nDescription\nvectara_customer_id\nString\nThe Vectara customer ID.\nvectara_corpus_id\nString\nThe Vectara corpus ID.\nvectara_api_key\nSecretString\nThe Vectara API key.\nembedding\nEmbeddings\nThe embedding function to use (optional).\ningest_data\nList[Document/Data]\nThe data to be ingested into the vector store.\nsearch_query\nString\nThe query for similarity search.\nnumber_of_results\nInteger\nThe number of results to return in search.\n**Outputs**\nName\nType\nDescription\nvector_store\nVectaraVectorStore\nVectara vector store instance.\nsearch_results\nList[Data]\nThe results of the similarity search as a list of [Data](/concepts-objects#data-object) objects.', 'Vectara Search': 'This component searches a Vectara Vector Store for documents based on the provided input.\nFor more information, see the [Vectara documentation](https://docs.vectara.com/docs/).\n**Inputs**\nName\nType\nDescription\nsearch_type\nString\nThe type of search, such as "Similarity" or "MMR".\ninput_value\nString\nThe search query.\nvectara_customer_id\nString\nThe Vectara customer ID.\nvectara_corpus_id\nString\nThe Vectara corpus ID.\nvectara_api_key\nSecretString\nThe Vectara API key.\nfiles_url\nList[String]\nOptional URLs for file initialization.\n**Outputs**\nName\nType\nDescription\nsearch_results\nList[Data]\nThe results of the similarity search as a list of [Data](/concepts-objects#data-object) objects.', 'Weaviate': 'This component facilitates a Weaviate Vector Store setup, optimizing text and document indexing and retrieval.\nFor more information, see the [Weaviate Documentation](https://weaviate.io/developers/weaviate).\n**Inputs**\nName\nType\nDescription\nweaviate_url\nString\nThe default instance URL.\nsearch_by_text\nBoolean\nIndicates whether to search by text.\napi_key\nSecretString\nThe optional API key for authentication.\nindex_name\nString\nThe optional index name.\ntext_key\nString\nThe default text extraction key.\ninput\nDocument\nThe document or record.\nembedding\nEmbeddings\nThe embedding model used.\nattributes\nList[String]\nOptional additional attributes.\n**Outputs**\nName\nType\nDescription\nvector_store\nWeaviateVectorStore\nThe Weaviate vector store instance.', 'Weaviate Search': 'This component searches a Weaviate Vector Store for documents similar to the input.\nFor more information, see the [Weaviate Documentation](https://weaviate.io/developers/weaviate).\n**Inputs**\nName\nType\nDescription\nsearch_type\nString\nThe type of search, such as "Similarity" or "MMR"\ninput_value\nString\nThe search query.\nweaviate_url\nString\nThe default instance URL.\nsearch_by_text\nBoolean\nA boolean value that indicates whether to search by text.\napi_key\nSecretString\nThe optional API key for authentication.\nindex_name\nString\nThe optional index name.\ntext_key\nString\nThe default text extraction key.\nembedding\nEmbeddings\nThe embeddings model used.\nattributes\nList[String]\nOptional additional attributes.\n**Outputs**\nName\nType\nDescription\nsearch_results\nList[Data]\nThe results of the similarity search as a list of [Data](/concepts-objects#data-object) objects.'}
{'title: Models\nslug: /components-models': 'import Icon from "@site/src/components/icon";', 'Model components in Langflow': "Model components generate text using large language models.\nRefer to your specific component's documentation for more information on parameters.", 'Use a model component in a flow': 'Model components receive inputs and prompts for generating text, and the generated text is sent to an output component.\nThe model output can also be sent to the **Language Model** port and on to a **Parse Data** component, where the output can be parsed into structured [Data](/concepts-objects) objects.\nThis example has the OpenAI model in a chatbot flow. For more information, see the [Basic prompting flow](/starter-projects-basic-prompting).\n![](/img/starter-flow-basic-prompting.png)', 'AIML': 'This component creates a ChatOpenAI model instance using the AIML API.\nFor more information, see [AIML documentation](https://docs.aimlapi.com/).\n**Inputs**\nName\nType\nDescription\nmax_tokens\nInteger\nThe maximum number of tokens to generate. Set to 0 for unlimited tokens. Range: 0-128000.\nmodel_kwargs\nDictionary\nAdditional keyword arguments for the model.\nmodel_name\nString\nThe name of the AIML model to use. Options are predefined in `AIML_CHAT_MODELS`.\naiml_api_base\nString\nThe base URL of the AIML API. Defaults to `https://api.aimlapi.com`.\napi_key\nSecretString\nThe AIML API Key to use for the model.\ntemperature\nFloat\nControls randomness in the output. Default: `0.1`.\n**Outputs**\nName\nType\nDescription\nmodel\nLanguageModel\nAn instance of ChatOpenAI configured with the specified parameters.', 'Amazon Bedrock': 'This component generates text using Amazon Bedrock LLMs.\nFor more information, see [Amazon Bedrock documentation](https://docs.aws.amazon.com/bedrock).\n**Inputs**\nName\nType\nDescription\nmodel_id\nString\nThe ID of the Amazon Bedrock model to use. Options include various models.\naws_access_key\nSecretString\nAWS Access Key for authentication.\naws_secret_key\nSecretString\nAWS Secret Key for authentication.\naws_session_token\nSecretString\nThe session key for your AWS account.\ncredentials_profile_name\nString\nName of the AWS credentials profile to use.\nregion_name\nString\nAWS region name. Default: `us-east-1`.\nmodel_kwargs\nDictionary\nAdditional keyword arguments for the model.\nendpoint_url\nString\nCustom endpoint URL for the Bedrock service.\n**Outputs**\nName\nType\nDescription\nmodel\nLanguageModel\nAn instance of ChatBedrock configured with the specified parameters.', 'Anthropic': "This component allows the generation of text using Anthropic Chat and Language models.\nFor more information, see the [Anthropic documentation](https://docs.anthropic.com/en/docs/welcome).\n**Inputs**\nName\nType\nDescription\nmax_tokens\nInteger\nThe maximum number of tokens to generate. Set to 0 for unlimited tokens. Default: `4096`.\nmodel\nString\nThe name of the Anthropic model to use. Options include various Claude 3 models.\nanthropic_api_key\nSecretString\nYour Anthropic API key for authentication.\ntemperature\nFloat\nControls randomness in the output. Default: `0.1`.\nanthropic_api_url\nString\nEndpoint of the Anthropic API. Defaults to `https://api.anthropic.com` if not specified (advanced).\nprefill\nString\nPrefill text to guide the model's response (advanced).\n**Outputs**\nName\nType\nDescription\nmodel\nLanguageModel\nAn instance of ChatAnthropic configured with the specified parameters.", 'Azure OpenAI': 'This component generates text using Azure OpenAI LLM.\nFor more information, see the [Azure OpenAI documentation](https://learn.microsoft.com/en-us/azure/ai-services/openai/).\n**Inputs**\nName\nType\nDescription\nModel Name\nString\nSpecifies the name of the Azure OpenAI model to be used for text generation.\nAzure Endpoint\nString\nYour Azure endpoint, including the resource.\nDeployment Name\nString\nSpecifies the name of the deployment.\nAPI Version\nString\nSpecifies the version of the Azure OpenAI API to be used.\nAPI Key\nSecretString\nYour Azure OpenAI API key.\nTemperature\nFloat\nSpecifies the sampling temperature. Defaults to `0.7`.\nMax Tokens\nInteger\nSpecifies the maximum number of tokens to generate. Defaults to `1000`.\nInput Value\nString\nSpecifies the input text for text generation.\nStream\nBoolean\nSpecifies whether to stream the response from the model. Defaults to `False`.\n**Outputs**\nName\nType\nDescription\nmodel\nLanguageModel\nAn instance of AzureOpenAI configured with the specified parameters.', 'Cohere': "This component generates text using Cohere's language models.\nFor more information, see the [Cohere documentation](https://cohere.ai/).\n**Inputs**\nName\nType\nDescription\nCohere API Key\nSecretString\nYour Cohere API key.\nMax Tokens\nInteger\nSpecifies the maximum number of tokens to generate. Defaults to `256`.\nTemperature\nFloat\nSpecifies the sampling temperature. Defaults to `0.75`.\nInput Value\nString\nSpecifies the input text for text generation.\n**Outputs**\nName\nType\nDescription\nmodel\nLanguageModel\nAn instance of the Cohere model configured with the specified parameters.", 'DeepSeek': "This component generates text using DeepSeek's language models.\nFor more information, see the [DeepSeek documentation](https://api-docs.deepseek.com/).\n**Inputs**\nName\nType\nDescription\nmax_tokens\nInteger\nMaximum number of tokens to generate. Set to `0` for unlimited. Range: `0-128000`.\nmodel_kwargs\nDictionary\nAdditional keyword arguments for the model.\njson_mode\nBoolean\nIf `True`, outputs JSON regardless of passing a schema.\nmodel_name\nString\nThe DeepSeek model to use. Default: `deepseek-chat`.\napi_base\nString\nBase URL for API requests. Default: `https://api.deepseek.com`.\napi_key\nSecretString\nYour DeepSeek API key for authentication.\ntemperature\nFloat\nControls randomness in responses. Range: `[0.0, 2.0]`. Default: `1.0`.\nseed\nInteger\nNumber initialized for random number generation. Use the same seed integer for more reproducible results, and use a different seed number for more random results.\n**Outputs**\nName\nType\nDescription\nmodel\nLanguageModel\nAn instance of ChatOpenAI configured with the specified parameters.", 'Google Generative AI': 'This component generates text using Google\'s Generative AI models.\nFor more information, see the [Google Generative AI documentation](https://cloud.google.com/vertex-ai/docs/).\n**Inputs**\nName\nType\nDescription\nGoogle API Key\nSecretString\nYour Google API key to use for the Google Generative AI.\nModel\nString\nThe name of the model to use, such as `"gemini-pro"`.\nMax Output Tokens\nInteger\nThe maximum number of tokens to generate.\nTemperature\nFloat\nRun inference with this temperature.\nTop K\nInteger\nConsider the set of top K most probable tokens.\nTop P\nFloat\nThe maximum cumulative probability of tokens to consider when sampling.\nN\nInteger\nNumber of chat completions to generate for each prompt.\n**Outputs**\nName\nType\nDescription\nmodel\nLanguageModel\nAn instance of ChatGoogleGenerativeAI configured with the specified parameters.', 'Groq': 'This component generates text using Groq\'s language models.\nTo use this component in a flow, connect it as a **Model** in a flow like the [Basic prompting flow](/starter-projects-basic-prompting), or select it as the **Model Provider** if you\'re using an **Agent** component.\n![Groq component in a basic prompting flow](/img/component-groq.png)\nIn the **Groq API Key** field, paste your Groq API key.\nThe Groq model component automatically retrieves a list of the latest models.\nTo refresh your list of models, click <Icon name="RefreshCw" aria-label="Refresh"/>.\nIn the **Model** field, select the model you want to use for your LLM.\nThis example uses [llama-3.1-8b-instant](https://console.groq.com/docs/model/llama-3.1-8b-instant), which Groq recommends for real-time conversational interfaces.\nIn the **Prompt** component, enter:\nClick **Playground** and ask your Groq LLM a question.\nThe responses include a list of sources.\nFor more information, see the [Groq documentation](https://groq.com/).\n**Inputs**\nName\nType\nDescription\ngroq_api_key\nSecretString\nAPI key for the Groq API.\ngroq_api_base\nString\nBase URL path for API requests. Default: `https://api.groq.com`.\nmax_tokens\nInteger\nThe maximum number of tokens to generate.\ntemperature\nFloat\nControls randomness in the output. Range: `[0.0, 1.0]`. Default: `0.1`.\nn\nInteger\nNumber of chat completions to generate for each prompt.\nmodel_name\nString\nThe name of the Groq model to use. Options are dynamically fetched from the Groq API.\ntool_mode_enabled\nBool\nIf enabled, the component only displays models that work with tools.\n**Outputs**\nName\nType\nDescription\nmodel\nLanguageModel\nAn instance of ChatGroq configured with the specified parameters.', 'Hugging Face API': 'This component sends requests to the Hugging Face API to generate text using the model specified in the **Model ID** field.\nThe Hugging Face API is a hosted inference API for models hosted on Hugging Face, and requires a [Hugging Face API token](https://huggingface.co/docs/hub/security-tokens) to authenticate.\nIn this example based on the [Basic prompting flow](/starter-projects-basic-prompting), the **Hugging Face API** model component replaces the **Open AI** model. By selecting different hosted models, you can see how different models return different results.\nCreate a [Basic prompting flow](/starter-projects-basic-prompting).\nReplace the **OpenAI** model component with a **Hugging Face API** model component.\nIn the **Hugging Face API** component, add your Hugging Face API token to the **API Token** field.\nOpen the **Playground** and ask a question to the model, and see how it responds.\nTry different models, and see how they perform differently.\nFor more information, see the [Hugging Face documentation](https://huggingface.co/).\n**Inputs**\nName\nType\nDescription\nmodel_id\nString\nThe model ID from Hugging Face Hub. For example, "gpt2", "facebook/bart-large".\nhuggingfacehub_api_token\nSecretString\nYour Hugging Face API token for authentication.\ntemperature\nFloat\nControls randomness in the output. Range: [0.0, 1.0]. Default: 0.7.\nmax_new_tokens\nInteger\nMaximum number of tokens to generate. Default: 512.\ntop_p\nFloat\nNucleus sampling parameter. Range: [0.0, 1.0]. Default: 0.95.\ntop_k\nInteger\nTop-k sampling parameter. Default: 50.\nmodel_kwargs\nDictionary\nAdditional keyword arguments to pass to the model.\n**Outputs**\nName\nType\nDescription\nmodel\nLanguageModel\nAn instance of HuggingFaceHub configured with the specified parameters.', 'IBM watsonx.ai': 'This component generates text using [IBM watsonx.ai](https://www.ibm.com/watsonx) foundation models.\nTo use **IBM watsonx.ai** model components, replace a model component with the IBM watsonx.ai component in a flow.\nAn example flow looks like the following:\n![IBM watsonx model component in a basic prompting flow](/img/component-watsonx-model.png)\nThe values for **API endpoint**, **Project ID**, **API key**, and **Model Name** are found in your IBM watsonx.ai deployment.\nFor more information, see the [Langchain documentation](https://python.langchain.com/docs/integrations/chat/ibm_watsonx/).\n**Inputs**\nName\nType\nDescription\nurl\nString\nThe base URL of the watsonx API.\nproject_id\nString\nYour watsonx Project ID.\napi_key\nSecretString\nYour IBM watsonx API Key.\nmodel_name\nString\nThe name of the watsonx model to use. Options are dynamically fetched from the API.\nmax_tokens\nInteger\nThe maximum number of tokens to generate. Default: `1000`.\nstop_sequence\nString\nThe sequence where generation should stop.\ntemperature\nFloat\nControls randomness in the output. Default: `0.1`.\ntop_p\nFloat\nControls nucleus sampling, which limits the model to tokens whose probability is below the `top_p` value. Range: Default: `0.9`.\nfrequency_penalty\nFloat\nControls frequency penalty. A positive value decreases the probability of repeating tokens, and a negative value increases the probability. Range: Default: `0.5`.\npresence_penalty\nFloat\nControls presence penalty. A positive value increases the likelihood of new topics being introduced. Default: `0.3`.\nseed\nInteger\nA random seed for the model. Default: `8`.\nlogprobs\nBoolean\nWhether to return log probabilities of output tokens or not. Default: `True`.\ntop_logprobs\nInteger\nThe number of most likely tokens to return at each position. Default: `3`.\nlogit_bias\nString\nA JSON string of token IDs to bias or suppress.\n**Outputs**\nName\nType\nDescription\nmodel\nLanguageModel\nAn instance of [ChatWatsonx](https://python.langchain.com/docs/integrations/chat/ibm_watsonx/) configured with the specified parameters.', 'Language model': 'This component generates text using either OpenAI or Anthropic language models.\nUse this component as a drop-in replacement for LLM models to switch between different model providers and models.\nInstead of swapping out model components when you want to try a different provider, like switching between OpenAI and Anthropic components, change the provider dropdown in this single component. This makes it easier to experiment with and compare different models while keeping the rest of your flow intact.\nFor more information, see the [OpenAI documentation](https://platform.openai.com/docs) and [Anthropic documentation](https://docs.anthropic.com/).\n**Inputs**\nName\nType\nDescription\nprovider\nString\nThe model provider to use. Options: "OpenAI", "Anthropic". Default: "OpenAI".\nmodel_name\nString\nThe name of the model to use. Options depend on the selected provider.\napi_key\nSecretString\nThe API Key for authentication with the selected provider.\ninput_value\nString\nThe input text to send to the model.\nsystem_message\nString\nA system message that helps set the behavior of the assistant (advanced).\nstream\nBoolean\nWhether to stream the response. Default: `False` (advanced).\ntemperature\nFloat\nControls randomness in responses. Range: `[0.0, 1.0]`. Default: `0.1` (advanced).\n**Outputs**\nName\nType\nDescription\nmodel\nLanguageModel\nAn instance of ChatOpenAI or ChatAnthropic configured with the specified parameters.', 'LMStudio': 'This component generates text using LM Studio\'s local language models.\nFor more information, see [LM Studio documentation](https://lmstudio.ai/).\n**Inputs**\nName\nType\nDescription\nbase_url\nString\nThe URL where LM Studio is running. Default: `"http://localhost:1234"`.\nmax_tokens\nInteger\nMaximum number of tokens to generate in the response. Default: `512`.\ntemperature\nFloat\nControls randomness in the output. Range: `[0.0, 2.0]`. Default: `0.7`.\ntop_p\nFloat\nControls diversity via nucleus sampling. Range: `[0.0, 1.0]`. Default: `1.0`.\nstop\nList[String]\nList of strings that stop generation when encountered.\nstream\nBoolean\nWhether to stream the response. Default: `False`.\npresence_penalty\nFloat\nPenalizes repeated tokens. Range: `[-2.0, 2.0]`. Default: `0.0`.\nfrequency_penalty\nFloat\nPenalizes frequent tokens. Range: `[-2.0, 2.0]`. Default: `0.0`.\n**Outputs**\nName\nType\nDescription\nmodel\nLanguageModel\nAn instance of LMStudio configured with the specified parameters.', 'Maritalk': 'This component generates text using Maritalk LLMs.\nFor more information, see [Maritalk documentation](https://www.maritalk.com/).\n**Inputs**\nName\nType\nDescription\nmax_tokens\nInteger\nThe maximum number of tokens to generate. Set to `0` for unlimited tokens. Default: `512`.\nmodel_name\nString\nThe name of the Maritalk model to use. Options: `sabia-2-small`, `sabia-2-medium`. Default: `sabia-2-small`.\napi_key\nSecretString\nThe Maritalk API Key to use for authentication.\ntemperature\nFloat\nControls randomness in the output. Range: `[0.0, 1.0]`. Default: `0.5`.\nendpoint_url\nString\nThe Maritalk API endpoint. Default: `https://api.maritalk.com`.\n**Outputs**\nName\nType\nDescription\nmodel\nLanguageModel\nAn instance of ChatMaritalk configured with the specified parameters.', 'Mistral': 'This component generates text using MistralAI LLMs.\nFor more information, see [Mistral AI documentation](https://docs.mistral.ai/).\n**Inputs**\nName\nType\nDescription\nmax_tokens\nInteger\nThe maximum number of tokens to generate. Set to 0 for unlimited tokens (advanced).\nmodel_name\nString\nThe name of the Mistral AI model to use. Options include `open-mixtral-8x7b`, `open-mixtral-8x22b`, `mistral-small-latest`, `mistral-medium-latest`, `mistral-large-latest`, and `codestral-latest`. Default: `codestral-latest`.\nmistral_api_base\nString\nThe base URL of the Mistral API. Defaults to `https://api.mistral.ai/v1` (advanced).\napi_key\nSecretString\nThe Mistral API Key to use for authentication.\ntemperature\nFloat\nControls randomness in the output. Default: 0.5.\nmax_retries\nInteger\nMaximum number of retries for API calls. Default: 5 (advanced).\ntimeout\nInteger\nTimeout for API calls in seconds. Default: 60 (advanced).\nmax_concurrent_requests\nInteger\nMaximum number of concurrent API requests. Default: 3 (advanced).\ntop_p\nFloat\nNucleus sampling parameter. Default: 1 (advanced).\nrandom_seed\nInteger\nSeed for random number generation. Default: 1 (advanced).\nsafe_mode\nBoolean\nEnables safe mode for content generation (advanced).\n**Outputs**\nName\nType\nDescription\nmodel\nLanguageModel\nAn instance of ChatMistralAI configured with the specified parameters.', 'Novita AI': "This component generates text using Novita AI's language models.\nFor more information, see [Novita AI documentation](https://novita.ai/docs/model-api/reference/llm/llm.html?utm_source=github_langflow&utm_medium=github_readme&utm_campaign=link).\n**Inputs**\nName\nType\nDescription\napi_key\nSecretString\nYour Novita AI API Key.\nmodel\nString\nThe id of the Novita AI model to use.\nmax_tokens\nInteger\nThe maximum number of tokens to generate. Set to 0 for unlimited tokens.\ntemperature\nFloat\nControls randomness in the output. Range: [0.0, 1.0]. Default: 0.7.\ntop_p\nFloat\nControls the nucleus sampling. Range: [0.0, 1.0]. Default: 1.0.\nfrequency_penalty\nFloat\nControls the frequency penalty. Range: [0.0, 2.0]. Default: 0.0.\npresence_penalty\nFloat\nControls the presence penalty. Range: [0.0, 2.0]. Default: 0.0.\n**Outputs**\nName\nType\nDescription\nmodel\nLanguageModel\nAn instance of Novita AI model configured with the specified parameters.", 'NVIDIA': 'This component generates text using NVIDIA LLMs.\nFor more information, see [NVIDIA AI documentation](https://developer.nvidia.com/generative-ai).\n**Inputs**\nName\nType\nDescription\nmax_tokens\nInteger\nThe maximum number of tokens to generate. Set to `0` for unlimited tokens (advanced).\nmodel_name\nString\nThe name of the NVIDIA model to use. Default: `mistralai/mixtral-8x7b-instruct-v0.1`.\nbase_url\nString\nThe base URL of the NVIDIA API. Default: `https://integrate.api.nvidia.com/v1`.\nnvidia_api_key\nSecretString\nThe NVIDIA API Key for authentication.\ntemperature\nFloat\nControls randomness in the output. Default: `0.1`.\nseed\nInteger\nThe seed controls the reproducibility of the job (advanced). Default: `1`.\n**Outputs**\nName\nType\nDescription\nmodel\nLanguageModel\nAn instance of ChatNVIDIA configured with the specified parameters.', 'Ollama': 'This component generates text using Ollama\'s language models.\nTo use this component in a flow, connect Langflow to your locally running Ollama server and select a model.\nIn the Ollama component, in the **Base URL** field, enter the address for your locally running Ollama server.\nThis value is set as the `OLLAMA_HOST` environment variable in Ollama.\nThe default base URL is `http://127.0.0.1:11434`.\nTo refresh the server\'s list of models, click <Icon name="RefreshCw" aria-label="Refresh"/>.\nIn the **Model Name** field, select a model. This example uses `llama3.2:latest`.\nConnect the **Ollama** model component to a flow. For example, this flow connects a local Ollama server running a Llama 3.2 model as the custom model for an [Agent](/components-agents) component.\n![Ollama model as Agent custom model](/img/component-ollama-model.png)\nFor more information, see the [Ollama documentation](https://ollama.com/).\n**Inputs**\nName\nType\nDescription\nBase URL\nString\nEndpoint of the Ollama API.\nModel Name\nString\nThe model name to use.\nTemperature\nFloat\nControls the creativity of model responses.\n**Outputs**\nName\nType\nDescription\nmodel\nLanguageModel\nAn instance of an Ollama model configured with the specified parameters.', 'OpenAI': 'This component generates text using OpenAI\'s language models.\nFor more information, see [OpenAI documentation](https://beta.openai.com/docs/).\n**Inputs**\nName\nType\nDescription\napi_key\nSecretString\nYour OpenAI API Key.\nmodel\nString\nThe name of the OpenAI model to use. Options include "gpt-3.5-turbo" and "gpt-4".\nmax_tokens\nInteger\nThe maximum number of tokens to generate. Set to 0 for unlimited tokens.\ntemperature\nFloat\nControls randomness in the output. Range: [0.0, 1.0]. Default: 0.7.\ntop_p\nFloat\nControls the nucleus sampling. Range: [0.0, 1.0]. Default: 1.0.\nfrequency_penalty\nFloat\nControls the frequency penalty. Range: [0.0, 2.0]. Default: 0.0.\npresence_penalty\nFloat\nControls the presence penalty. Range: [0.0, 2.0]. Default: 0.0.\n**Outputs**\nName\nType\nDescription\nmodel\nLanguageModel\nAn instance of OpenAI model configured with the specified parameters.', 'OpenRouter': "This component generates text using OpenRouter's unified API for multiple AI models from different providers.\nFor more information, see [OpenRouter documentation](https://openrouter.ai/docs).\n**Inputs**\nName\nType\nDescription\napi_key\nSecretString\nYour OpenRouter API key for authentication.\nsite_url\nString\nYour site URL for OpenRouter rankings (advanced).\napp_name\nString\nYour app name for OpenRouter rankings (advanced).\nprovider\nString\nThe AI model provider to use.\nmodel_name\nString\nThe specific model to use for chat completion.\ntemperature\nFloat\nControls randomness in the output. Range: [0.0, 2.0]. Default: 0.7.\nmax_tokens\nInteger\nThe maximum number of tokens to generate (advanced).\n**Outputs**\nName\nType\nDescription\nmodel\nLanguageModel\nAn instance of ChatOpenAI configured with the specified parameters.", 'Perplexity': "This component generates text using Perplexity's language models.\nFor more information, see [Perplexity documentation](https://perplexity.ai/).\n**Inputs**\nName\nType\nDescription\nmodel_name\nString\nThe name of the Perplexity model to use. Options include various Llama 3.1 models.\nmax_output_tokens\nInteger\nThe maximum number of tokens to generate.\napi_key\nSecretString\nThe Perplexity API Key for authentication.\ntemperature\nFloat\nControls randomness in the output. Default: 0.75.\ntop_p\nFloat\nThe maximum cumulative probability of tokens to consider when sampling (advanced).\nn\nInteger\nNumber of chat completions to generate for each prompt (advanced).\ntop_k\nInteger\nNumber of top tokens to consider for top-k sampling. Must be positive (advanced).\n**Outputs**\nName\nType\nDescription\nmodel\nLanguageModel\nAn instance of ChatPerplexity configured with the specified parameters.", 'Qianfan': "This component generates text using Qianfan's language models.\nFor more information, see [Qianfan documentation](https://github.com/baidubce/bce-qianfan-sdk).", 'SambaNova': 'This component generates text using SambaNova LLMs.\nFor more information, see [Sambanova Cloud documentation](https://cloud.sambanova.ai/).\n**Inputs**\nName\nType\nDescription\nsambanova_url\nString\nBase URL path for API requests. Default: `https://api.sambanova.ai/v1/chat/completions`.\nsambanova_api_key\nSecretString\nYour SambaNova API Key.\nmodel_name\nString\nThe name of the Sambanova model to use. Options include various Llama models.\nmax_tokens\nInteger\nThe maximum number of tokens to generate. Set to 0 for unlimited tokens.\ntemperature\nFloat\nControls randomness in the output. Range: [0.0, 1.0]. Default: 0.07.\n**Outputs**\nName\nType\nDescription\nmodel\nLanguageModel\nAn instance of SambaNova model configured with the specified parameters.', 'VertexAI': 'This component generates text using Vertex AI LLMs.\nFor more information, see [Google Vertex AI documentation](https://cloud.google.com/vertex-ai).\n**Inputs**\nName\nType\nDescription\ncredentials\nFile\nJSON credentials file. Leave empty to fall back to environment variables. File type: JSON.\nmodel_name\nString\nThe name of the Vertex AI model to use. Default: "gemini-1.5-pro".\nproject\nString\nThe project ID (advanced).\nlocation\nString\nThe location for the Vertex AI API. Default: "us-central1" (advanced).\nmax_output_tokens\nInteger\nThe maximum number of tokens to generate (advanced).\nmax_retries\nInteger\nMaximum number of retries for API calls. Default: 1 (advanced).\ntemperature\nFloat\nControls randomness in the output. Default: 0.0.\ntop_k\nInteger\nThe number of highest probability vocabulary tokens to keep for top-k-filtering (advanced).\ntop_p\nFloat\nThe cumulative probability of parameter highest probability vocabulary tokens to keep for nucleus sampling. Default: 0.95 (advanced).\nverbose\nBoolean\nWhether to print verbose output. Default: False (advanced).\n**Outputs**\nName\nType\nDescription\nmodel\nLanguageModel\nAn instance of ChatVertexAI configured with the specified parameters.', 'xAI': 'This component generates text using xAI models like [Grok](https://x.ai/grok).\nFor more information, see the [xAI documentation](https://x.ai/).\n**Inputs**\nName\nType\nDescription\nmax_tokens\nInteger\nMaximum number of tokens to generate. Set to `0` for unlimited. Range: `0-128000`.\nmodel_kwargs\nDictionary\nAdditional keyword arguments for the model.\njson_mode\nBoolean\nIf `True`, outputs JSON regardless of passing a schema.\nmodel_name\nString\nThe xAI model to use. Default: `grok-2-latest`.\nbase_url\nString\nBase URL for API requests. Default: `https://api.x.ai/v1`.\napi_key\nSecretString\nYour xAI API key for authentication.\ntemperature\nFloat\nControls randomness in the output. Range: `[0.0, 2.0]`. Default: `0.1`.\nseed\nInteger\nControls reproducibility of the job.\n**Outputs**\nName\nType\nDescription\nmodel\nLanguageModel\nAn instance of ChatOpenAI configured with the specified parameters.'}
